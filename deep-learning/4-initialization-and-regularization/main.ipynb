{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c70a62a-3f57-40e7-b97e-323aed30192e",
   "metadata": {},
   "source": [
    "Code from the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfab1412-04d1-4963-87e6-96b7b8a79347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T16:58:54.117552Z",
     "iopub.status.busy": "2023-04-19T16:58:54.116599Z",
     "iopub.status.idle": "2023-04-19T16:58:55.395493Z",
     "shell.execute_reply": "2023-04-19T16:58:55.394610Z",
     "shell.execute_reply.started": "2023-04-19T16:58:54.117552Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CircleDataGenerator():\n",
    "    def one_class_generate(self, radius, y, n):\n",
    "        angle = np.random.uniform(0, 2 * np.pi, n)\n",
    "        noise = np.random.uniform(-1, 1, n)\n",
    "        r = radius + noise\n",
    "        x1 = np.cos(angle) * r\n",
    "        x2 = np.sin(angle) * r\n",
    "        x = np.stack([x1, x2], axis=1)\n",
    "        t = np.ones((n,), dtype=np.int64) * int(y)\n",
    "        return x, t\n",
    "\n",
    "    \n",
    "    def generate_sample(self, n):\n",
    "        x1, t1 = self.one_class_generate(4, 1, n//2)\n",
    "        x0, t0 = self.one_class_generate(1, 0, n//2)\n",
    "        \n",
    "        x = np.concatenate((x1, x0), axis=0)\n",
    "        t = np.concatenate((t1, t0), axis=0)\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        t = torch.tensor(t, dtype=torch.long)\n",
    "\n",
    "        return x, t\n",
    "\n",
    "\n",
    "def plot_decision_boundary(gt_data, gt_target, model):\n",
    "    step_size = 0.1\n",
    "    xmin = -5\n",
    "    xmax = 5\n",
    "    ymin = -5\n",
    "    ymax = 5\n",
    "    xx, yy = torch.meshgrid(torch.arange(xmin, xmax+step_size, step_size), \n",
    "                            torch.arange(ymin, ymax+step_size, step_size))\n",
    "    grid_data = torch.stack([xx.flatten(), yy.flatten()], dim=1)\n",
    "\n",
    "    model.eval()\n",
    "    y = model.forward(grid_data.to('cuda'))\n",
    "    y = torch.softmax(y, dim=1)\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    prob = y[:, 0].reshape(xx.shape)\n",
    "\n",
    "    data = gt_data.detach().cpu().numpy()\n",
    "    t = gt_target.detach().cpu().numpy()\n",
    "\n",
    "    plt.imshow(prob.T, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='RdBu')\n",
    "    plt.contour(xx, yy, prob, [0.5], origin='lower', colors='k')\n",
    "    plt.plot(data[t == 0, 0], data[t == 0, 1], 'o', color='orange')\n",
    "    plt.plot(data[t == 1, 0], data[t == 1, 1], 'o', color='lightgreen')\n",
    "    \n",
    "\n",
    "class MNISTData():\n",
    "    def __init__(self, batch_size):\n",
    "        # transforms\n",
    "        transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                                        # transforms.Lambda(torch.flatten)])        \n",
    "        transform = transforms.ToTensor()\n",
    "        self.train_set = torchvision.datasets.MNIST('./data', download=True, train=True, transform=transform)\n",
    "        self.test_set = torchvision.datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "\n",
    "        # split train_set into train_subset and val_subset\n",
    "        self.train_subset = Subset(self.train_set, list(range(5000)))\n",
    "        self.val_subset = Subset(self.train_set, list(range(5000, 15000)))\n",
    "\n",
    "        # dataloaders\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.train_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        self.val_loader = torch.utils.data.DataLoader(self.val_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        self.test_loader = torch.utils.data.DataLoader(self.test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d5792-fcfd-4c31-bb61-af611b51ad21",
   "metadata": {},
   "source": [
    "# Part 1: Initialization - Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85601cfc-1330-4350-bbee-e8ac87361590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T16:58:55.398860Z",
     "iopub.status.busy": "2023-04-19T16:58:55.398158Z",
     "iopub.status.idle": "2023-04-19T16:58:55.458452Z",
     "shell.execute_reply": "2023-04-19T16:58:55.457527Z",
     "shell.execute_reply.started": "2023-04-19T16:58:55.398831Z"
    }
   },
   "outputs": [],
   "source": [
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbfc4b6e-3ad8-43a7-9ffe-5cf3e74fc343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:10:44.313011Z",
     "iopub.status.busy": "2023-04-19T18:10:44.312320Z",
     "iopub.status.idle": "2023-04-19T18:10:44.318982Z",
     "shell.execute_reply": "2023-04-19T18:10:44.318365Z",
     "shell.execute_reply.started": "2023-04-19T18:10:44.312983Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "batch_size = n\n",
    "\n",
    "cdg = CircleDataGenerator()\n",
    "train_data = cdg.generate_sample(n)\n",
    "train_loader = torch.utils.data.DataLoader(list(zip(train_data[0], train_data[1])), batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_data = cdg.generate_sample(n)\n",
    "val_loader = torch.utils.data.DataLoader(list(zip(val_data[0], val_data[1])), batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e792376-01c1-48df-8c14-7834c86df49a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T16:58:55.467208Z",
     "iopub.status.busy": "2023-04-19T16:58:55.466730Z",
     "iopub.status.idle": "2023-04-19T16:58:55.470872Z",
     "shell.execute_reply": "2023-04-19T16:58:55.470043Z",
     "shell.execute_reply.started": "2023-04-19T16:58:55.467183Z"
    }
   },
   "outputs": [],
   "source": [
    "a = list(zip(train_data[0], train_data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df13d9-6dbc-4012-8506-9379eaad880e",
   "metadata": {},
   "source": [
    "Network and training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2799b9a5-320c-4e27-a2e0-fbea0060ff60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:57:42.617687Z",
     "iopub.status.busy": "2023-04-19T19:57:42.616937Z",
     "iopub.status.idle": "2023-04-19T19:57:42.624804Z",
     "shell.execute_reply": "2023-04-19T19:57:42.624165Z",
     "shell.execute_reply.started": "2023-04-19T19:57:42.617659Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Shallow(nn.Module):\n",
    "    def __init__(self, sigma):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight.data, 0, self.sigma)\n",
    "            nn.init.zeros_(m.bias.data)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "def accuracy(y, target):\n",
    "    return (torch.argmax(y, 1) == target).float().mean().item()\n",
    "    \n",
    "def evaluate(net, loss_fun, loader):\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    for x, target in loader:\n",
    "        x, target = x.to(dev), target.to(dev)\n",
    "        y = net.forward(x)\n",
    "        loss += loss_fun(y, target).mean().item()\n",
    "        acc += accuracy(y, target)\n",
    "\n",
    "    return loss / len(loader), acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b300983d-884c-4211-8003-b9de90d699f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:58:26.385482Z",
     "iopub.status.busy": "2023-04-19T19:58:26.384604Z",
     "iopub.status.idle": "2023-04-19T19:58:26.392344Z",
     "shell.execute_reply": "2023-04-19T19:58:26.391469Z",
     "shell.execute_reply.started": "2023-04-19T19:58:26.385452Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, train_loader, val_loader, lr=1e-1, epochs=1, verbose=True):\n",
    "    loss_fun = nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        for x, target in train_loader:\n",
    "            x = x.to(dev)\n",
    "            target = target.to(dev)\n",
    "            y = net.forward(x)\n",
    "            l = loss_fun(y, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.mean().backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_loss += l.mean().item()\n",
    "                train_acc += accuracy(y, target)\n",
    "\n",
    "        if verbose:\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                train_loss /= len(train_loader)\n",
    "                train_acc /= len(train_loader)\n",
    "            \n",
    "            val_loss, val_acc = evaluate(net, loss_fun, val_loader)\n",
    "            print(f\"{epoch}: Training / validation acc/loss: {train_acc:.3f}/{train_loss:.3f} / {val_acc:.3f}/{val_loss:.3f}\")\n",
    "        \n",
    "# train(Shallow(1).to(dev), train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f014955f-c6ed-4f2f-b81c-965a0b79b1e7",
   "metadata": {},
   "source": [
    "Playing with different sigma (initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d2205-da32-4b8f-80f2-de3f06c70d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(gt_data, gt_target, model):\n",
    "    step_size = 0.1\n",
    "    xmin = -5\n",
    "    xmax = 5\n",
    "    ymin = -5\n",
    "    ymax = 5\n",
    "    xx, yy = torch.meshgrid(torch.arange(xmin, xmax+step_size, step_size), \n",
    "                            torch.arange(ymin, ymax+step_size, step_size))\n",
    "    grid_data = torch.stack([xx.flatten(), yy.flatten()], dim=1)\n",
    "\n",
    "    model.eval()\n",
    "    y = model.forward(grid_data.to('cuda'))\n",
    "    y = torch.softmax(y, dim=1)\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    prob = y[:, 0].reshape(xx.shape)\n",
    "\n",
    "    data = gt_data.detach().cpu().numpy()\n",
    "    t = gt_target.detach().cpu().numpy()\n",
    "\n",
    "    plt.imshow(prob.T, origin='lower', extent=(xmin, xmax, ymin, ymax), cmap='RdBu')\n",
    "    plt.contour(xx, yy, prob, [0.5], origin='lower', colors='k')\n",
    "    plt.plot(data[t == 0, 0], data[t == 0, 1], 'o', color='orange')\n",
    "    plt.plot(data[t == 1, 0], data[t == 1, 1], 'o', color='lightgreen')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c9bdf-49fc-4b24-ada3-cf3ffcb9e7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:28:38.973532Z",
     "iopub.status.busy": "2023-04-19T18:28:38.972785Z",
     "iopub.status.idle": "2023-04-19T18:28:38.977993Z",
     "shell.execute_reply": "2023-04-19T18:28:38.977194Z",
     "shell.execute_reply.started": "2023-04-19T18:28:38.973504Z"
    }
   },
   "source": [
    "Good initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96585853-b2b2-41b5-a37e-2acfdd91324c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:36:38.362908Z",
     "iopub.status.busy": "2023-04-19T18:36:38.362339Z",
     "iopub.status.idle": "2023-04-19T18:36:40.550240Z",
     "shell.execute_reply": "2023-04-19T18:36:40.549146Z",
     "shell.execute_reply.started": "2023-04-19T18:36:38.362876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.500/0.684 / 0.540/0.685\n",
      "1: Training / validation acc/loss: 0.540/0.683 / 0.570/0.685\n",
      "2: Training / validation acc/loss: 0.600/0.683 / 0.620/0.684\n",
      "3: Training / validation acc/loss: 0.650/0.682 / 0.650/0.684\n",
      "4: Training / validation acc/loss: 0.670/0.681 / 0.690/0.683\n",
      "5: Training / validation acc/loss: 0.670/0.680 / 0.680/0.682\n",
      "6: Training / validation acc/loss: 0.700/0.680 / 0.690/0.682\n",
      "7: Training / validation acc/loss: 0.700/0.679 / 0.690/0.681\n",
      "8: Training / validation acc/loss: 0.710/0.678 / 0.650/0.680\n",
      "9: Training / validation acc/loss: 0.710/0.677 / 0.650/0.679\n",
      "10: Training / validation acc/loss: 0.700/0.676 / 0.650/0.678\n",
      "11: Training / validation acc/loss: 0.720/0.675 / 0.670/0.678\n",
      "12: Training / validation acc/loss: 0.720/0.674 / 0.670/0.676\n",
      "13: Training / validation acc/loss: 0.730/0.672 / 0.680/0.675\n",
      "14: Training / validation acc/loss: 0.730/0.671 / 0.700/0.674\n",
      "15: Training / validation acc/loss: 0.730/0.670 / 0.700/0.673\n",
      "16: Training / validation acc/loss: 0.740/0.668 / 0.710/0.672\n",
      "17: Training / validation acc/loss: 0.740/0.667 / 0.710/0.670\n",
      "18: Training / validation acc/loss: 0.750/0.665 / 0.710/0.669\n",
      "19: Training / validation acc/loss: 0.750/0.664 / 0.720/0.668\n",
      "20: Training / validation acc/loss: 0.750/0.662 / 0.720/0.666\n",
      "21: Training / validation acc/loss: 0.760/0.660 / 0.720/0.664\n",
      "22: Training / validation acc/loss: 0.760/0.658 / 0.720/0.662\n",
      "23: Training / validation acc/loss: 0.760/0.656 / 0.720/0.661\n",
      "24: Training / validation acc/loss: 0.760/0.654 / 0.730/0.659\n",
      "25: Training / validation acc/loss: 0.770/0.651 / 0.740/0.657\n",
      "26: Training / validation acc/loss: 0.770/0.649 / 0.740/0.654\n",
      "27: Training / validation acc/loss: 0.770/0.646 / 0.740/0.652\n",
      "28: Training / validation acc/loss: 0.770/0.644 / 0.750/0.650\n",
      "29: Training / validation acc/loss: 0.770/0.641 / 0.760/0.647\n",
      "30: Training / validation acc/loss: 0.770/0.638 / 0.760/0.644\n",
      "31: Training / validation acc/loss: 0.770/0.635 / 0.760/0.642\n",
      "32: Training / validation acc/loss: 0.770/0.632 / 0.760/0.639\n",
      "33: Training / validation acc/loss: 0.780/0.628 / 0.760/0.636\n",
      "34: Training / validation acc/loss: 0.780/0.625 / 0.760/0.633\n",
      "35: Training / validation acc/loss: 0.790/0.621 / 0.770/0.630\n",
      "36: Training / validation acc/loss: 0.790/0.618 / 0.780/0.626\n",
      "37: Training / validation acc/loss: 0.800/0.614 / 0.780/0.623\n",
      "38: Training / validation acc/loss: 0.800/0.610 / 0.780/0.619\n",
      "39: Training / validation acc/loss: 0.800/0.606 / 0.780/0.616\n",
      "40: Training / validation acc/loss: 0.810/0.602 / 0.780/0.612\n",
      "41: Training / validation acc/loss: 0.810/0.598 / 0.780/0.608\n",
      "42: Training / validation acc/loss: 0.810/0.594 / 0.780/0.605\n",
      "43: Training / validation acc/loss: 0.810/0.590 / 0.780/0.601\n",
      "44: Training / validation acc/loss: 0.810/0.585 / 0.780/0.597\n",
      "45: Training / validation acc/loss: 0.810/0.581 / 0.780/0.593\n",
      "46: Training / validation acc/loss: 0.830/0.576 / 0.780/0.589\n",
      "47: Training / validation acc/loss: 0.830/0.572 / 0.780/0.584\n",
      "48: Training / validation acc/loss: 0.830/0.567 / 0.790/0.580\n",
      "49: Training / validation acc/loss: 0.830/0.563 / 0.790/0.576\n",
      "50: Training / validation acc/loss: 0.830/0.558 / 0.790/0.571\n",
      "51: Training / validation acc/loss: 0.830/0.553 / 0.800/0.567\n",
      "52: Training / validation acc/loss: 0.830/0.549 / 0.800/0.563\n",
      "53: Training / validation acc/loss: 0.830/0.544 / 0.800/0.558\n",
      "54: Training / validation acc/loss: 0.830/0.539 / 0.810/0.553\n",
      "55: Training / validation acc/loss: 0.830/0.534 / 0.810/0.549\n",
      "56: Training / validation acc/loss: 0.840/0.529 / 0.810/0.544\n",
      "57: Training / validation acc/loss: 0.850/0.524 / 0.820/0.539\n",
      "58: Training / validation acc/loss: 0.850/0.519 / 0.830/0.534\n",
      "59: Training / validation acc/loss: 0.850/0.514 / 0.830/0.529\n",
      "60: Training / validation acc/loss: 0.860/0.509 / 0.830/0.524\n",
      "61: Training / validation acc/loss: 0.870/0.504 / 0.860/0.519\n",
      "62: Training / validation acc/loss: 0.880/0.498 / 0.860/0.514\n",
      "63: Training / validation acc/loss: 0.880/0.493 / 0.860/0.509\n",
      "64: Training / validation acc/loss: 0.880/0.488 / 0.860/0.504\n",
      "65: Training / validation acc/loss: 0.880/0.482 / 0.870/0.499\n",
      "66: Training / validation acc/loss: 0.880/0.477 / 0.890/0.493\n",
      "67: Training / validation acc/loss: 0.880/0.471 / 0.900/0.488\n",
      "68: Training / validation acc/loss: 0.880/0.466 / 0.900/0.482\n",
      "69: Training / validation acc/loss: 0.880/0.460 / 0.900/0.477\n",
      "70: Training / validation acc/loss: 0.890/0.454 / 0.900/0.471\n",
      "71: Training / validation acc/loss: 0.890/0.448 / 0.900/0.465\n",
      "72: Training / validation acc/loss: 0.900/0.443 / 0.900/0.459\n",
      "73: Training / validation acc/loss: 0.900/0.437 / 0.900/0.454\n",
      "74: Training / validation acc/loss: 0.900/0.431 / 0.910/0.448\n",
      "75: Training / validation acc/loss: 0.900/0.425 / 0.910/0.442\n",
      "76: Training / validation acc/loss: 0.900/0.419 / 0.900/0.436\n",
      "77: Training / validation acc/loss: 0.900/0.413 / 0.900/0.430\n",
      "78: Training / validation acc/loss: 0.910/0.406 / 0.910/0.424\n",
      "79: Training / validation acc/loss: 0.910/0.400 / 0.910/0.418\n",
      "80: Training / validation acc/loss: 0.910/0.394 / 0.910/0.412\n",
      "81: Training / validation acc/loss: 0.910/0.388 / 0.910/0.406\n",
      "82: Training / validation acc/loss: 0.910/0.382 / 0.910/0.400\n",
      "83: Training / validation acc/loss: 0.920/0.376 / 0.910/0.394\n",
      "84: Training / validation acc/loss: 0.920/0.370 / 0.910/0.388\n",
      "85: Training / validation acc/loss: 0.950/0.364 / 0.910/0.383\n",
      "86: Training / validation acc/loss: 0.950/0.357 / 0.910/0.377\n",
      "87: Training / validation acc/loss: 0.950/0.351 / 0.910/0.371\n",
      "88: Training / validation acc/loss: 0.960/0.346 / 0.920/0.365\n",
      "89: Training / validation acc/loss: 0.970/0.340 / 0.920/0.360\n",
      "90: Training / validation acc/loss: 0.970/0.334 / 0.920/0.354\n",
      "91: Training / validation acc/loss: 0.970/0.328 / 0.920/0.349\n",
      "92: Training / validation acc/loss: 0.970/0.323 / 0.920/0.344\n",
      "93: Training / validation acc/loss: 0.980/0.317 / 0.920/0.338\n",
      "94: Training / validation acc/loss: 0.980/0.312 / 0.920/0.333\n",
      "95: Training / validation acc/loss: 0.980/0.306 / 0.920/0.328\n",
      "96: Training / validation acc/loss: 0.980/0.301 / 0.920/0.323\n",
      "97: Training / validation acc/loss: 0.980/0.296 / 0.920/0.318\n",
      "98: Training / validation acc/loss: 0.980/0.291 / 0.930/0.313\n",
      "99: Training / validation acc/loss: 0.980/0.286 / 0.930/0.309\n",
      "100: Training / validation acc/loss: 0.980/0.281 / 0.940/0.304\n",
      "101: Training / validation acc/loss: 0.980/0.276 / 0.950/0.299\n",
      "102: Training / validation acc/loss: 0.980/0.272 / 0.950/0.295\n",
      "103: Training / validation acc/loss: 0.980/0.267 / 0.950/0.291\n",
      "104: Training / validation acc/loss: 0.980/0.263 / 0.950/0.286\n",
      "105: Training / validation acc/loss: 0.980/0.258 / 0.950/0.282\n",
      "106: Training / validation acc/loss: 0.980/0.254 / 0.950/0.278\n",
      "107: Training / validation acc/loss: 0.980/0.250 / 0.960/0.274\n",
      "108: Training / validation acc/loss: 0.980/0.246 / 0.960/0.270\n",
      "109: Training / validation acc/loss: 0.980/0.242 / 0.960/0.266\n",
      "110: Training / validation acc/loss: 0.980/0.238 / 0.960/0.263\n",
      "111: Training / validation acc/loss: 0.980/0.234 / 0.970/0.259\n",
      "112: Training / validation acc/loss: 0.990/0.230 / 0.970/0.255\n",
      "113: Training / validation acc/loss: 0.990/0.227 / 0.970/0.252\n",
      "114: Training / validation acc/loss: 0.990/0.223 / 0.980/0.248\n",
      "115: Training / validation acc/loss: 0.990/0.220 / 0.980/0.245\n",
      "116: Training / validation acc/loss: 0.990/0.216 / 0.990/0.242\n",
      "117: Training / validation acc/loss: 0.990/0.213 / 0.990/0.239\n",
      "118: Training / validation acc/loss: 0.990/0.210 / 0.990/0.236\n",
      "119: Training / validation acc/loss: 0.990/0.206 / 0.990/0.232\n",
      "120: Training / validation acc/loss: 0.990/0.203 / 0.990/0.230\n",
      "121: Training / validation acc/loss: 0.990/0.200 / 0.990/0.227\n",
      "122: Training / validation acc/loss: 0.990/0.197 / 1.000/0.224\n",
      "123: Training / validation acc/loss: 0.990/0.194 / 1.000/0.221\n",
      "124: Training / validation acc/loss: 0.990/0.192 / 1.000/0.218\n",
      "125: Training / validation acc/loss: 0.990/0.189 / 1.000/0.215\n",
      "126: Training / validation acc/loss: 0.990/0.186 / 1.000/0.213\n",
      "127: Training / validation acc/loss: 0.990/0.183 / 1.000/0.210\n",
      "128: Training / validation acc/loss: 0.990/0.181 / 1.000/0.208\n",
      "129: Training / validation acc/loss: 0.990/0.178 / 1.000/0.205\n",
      "130: Training / validation acc/loss: 0.990/0.176 / 1.000/0.203\n",
      "131: Training / validation acc/loss: 0.990/0.173 / 1.000/0.200\n",
      "132: Training / validation acc/loss: 0.990/0.171 / 1.000/0.198\n",
      "133: Training / validation acc/loss: 0.990/0.169 / 1.000/0.196\n",
      "134: Training / validation acc/loss: 0.990/0.166 / 1.000/0.194\n",
      "135: Training / validation acc/loss: 0.990/0.164 / 1.000/0.191\n",
      "136: Training / validation acc/loss: 0.990/0.162 / 1.000/0.189\n",
      "137: Training / validation acc/loss: 0.990/0.160 / 1.000/0.187\n",
      "138: Training / validation acc/loss: 0.990/0.158 / 1.000/0.185\n",
      "139: Training / validation acc/loss: 0.990/0.156 / 1.000/0.183\n",
      "140: Training / validation acc/loss: 0.990/0.154 / 1.000/0.181\n",
      "141: Training / validation acc/loss: 0.990/0.152 / 1.000/0.179\n",
      "142: Training / validation acc/loss: 0.990/0.150 / 1.000/0.177\n",
      "143: Training / validation acc/loss: 0.990/0.148 / 1.000/0.175\n",
      "144: Training / validation acc/loss: 0.990/0.146 / 1.000/0.174\n",
      "145: Training / validation acc/loss: 0.990/0.144 / 1.000/0.172\n",
      "146: Training / validation acc/loss: 0.990/0.143 / 1.000/0.170\n",
      "147: Training / validation acc/loss: 0.990/0.141 / 1.000/0.168\n",
      "148: Training / validation acc/loss: 0.990/0.139 / 1.000/0.167\n",
      "149: Training / validation acc/loss: 1.000/0.137 / 1.000/0.165\n",
      "150: Training / validation acc/loss: 1.000/0.136 / 1.000/0.163\n",
      "151: Training / validation acc/loss: 1.000/0.134 / 1.000/0.162\n",
      "152: Training / validation acc/loss: 1.000/0.133 / 1.000/0.160\n",
      "153: Training / validation acc/loss: 1.000/0.131 / 1.000/0.159\n",
      "154: Training / validation acc/loss: 1.000/0.130 / 1.000/0.157\n",
      "155: Training / validation acc/loss: 1.000/0.128 / 1.000/0.156\n",
      "156: Training / validation acc/loss: 1.000/0.127 / 1.000/0.154\n",
      "157: Training / validation acc/loss: 1.000/0.125 / 1.000/0.153\n",
      "158: Training / validation acc/loss: 1.000/0.124 / 1.000/0.151\n",
      "159: Training / validation acc/loss: 1.000/0.123 / 1.000/0.150\n",
      "160: Training / validation acc/loss: 1.000/0.121 / 1.000/0.149\n",
      "161: Training / validation acc/loss: 1.000/0.120 / 1.000/0.148\n",
      "162: Training / validation acc/loss: 1.000/0.119 / 1.000/0.146\n",
      "163: Training / validation acc/loss: 1.000/0.118 / 1.000/0.145\n",
      "164: Training / validation acc/loss: 1.000/0.116 / 1.000/0.144\n",
      "165: Training / validation acc/loss: 1.000/0.115 / 1.000/0.142\n",
      "166: Training / validation acc/loss: 1.000/0.114 / 1.000/0.141\n",
      "167: Training / validation acc/loss: 1.000/0.113 / 1.000/0.140\n",
      "168: Training / validation acc/loss: 1.000/0.112 / 1.000/0.139\n",
      "169: Training / validation acc/loss: 1.000/0.111 / 1.000/0.138\n",
      "170: Training / validation acc/loss: 1.000/0.109 / 1.000/0.137\n",
      "171: Training / validation acc/loss: 1.000/0.108 / 1.000/0.136\n",
      "172: Training / validation acc/loss: 1.000/0.107 / 1.000/0.135\n",
      "173: Training / validation acc/loss: 1.000/0.106 / 1.000/0.133\n",
      "174: Training / validation acc/loss: 1.000/0.105 / 1.000/0.132\n",
      "175: Training / validation acc/loss: 1.000/0.104 / 1.000/0.131\n",
      "176: Training / validation acc/loss: 1.000/0.103 / 1.000/0.130\n",
      "177: Training / validation acc/loss: 1.000/0.102 / 1.000/0.129\n",
      "178: Training / validation acc/loss: 1.000/0.101 / 1.000/0.128\n",
      "179: Training / validation acc/loss: 1.000/0.100 / 1.000/0.127\n",
      "180: Training / validation acc/loss: 1.000/0.100 / 1.000/0.126\n",
      "181: Training / validation acc/loss: 1.000/0.099 / 1.000/0.125\n",
      "182: Training / validation acc/loss: 1.000/0.098 / 1.000/0.124\n",
      "183: Training / validation acc/loss: 1.000/0.097 / 1.000/0.123\n",
      "184: Training / validation acc/loss: 1.000/0.096 / 1.000/0.123\n",
      "185: Training / validation acc/loss: 1.000/0.095 / 1.000/0.122\n",
      "186: Training / validation acc/loss: 1.000/0.094 / 1.000/0.121\n",
      "187: Training / validation acc/loss: 1.000/0.093 / 1.000/0.120\n",
      "188: Training / validation acc/loss: 1.000/0.093 / 1.000/0.119\n",
      "189: Training / validation acc/loss: 1.000/0.092 / 1.000/0.118\n",
      "190: Training / validation acc/loss: 1.000/0.091 / 1.000/0.117\n",
      "191: Training / validation acc/loss: 1.000/0.090 / 1.000/0.116\n",
      "192: Training / validation acc/loss: 1.000/0.090 / 1.000/0.116\n",
      "193: Training / validation acc/loss: 1.000/0.089 / 1.000/0.115\n",
      "194: Training / validation acc/loss: 1.000/0.088 / 1.000/0.114\n",
      "195: Training / validation acc/loss: 1.000/0.087 / 1.000/0.113\n",
      "196: Training / validation acc/loss: 1.000/0.087 / 1.000/0.112\n",
      "197: Training / validation acc/loss: 1.000/0.086 / 1.000/0.112\n",
      "198: Training / validation acc/loss: 1.000/0.085 / 1.000/0.111\n",
      "199: Training / validation acc/loss: 1.000/0.085 / 1.000/0.110\n",
      "200: Training / validation acc/loss: 1.000/0.084 / 1.000/0.109\n",
      "201: Training / validation acc/loss: 1.000/0.083 / 1.000/0.109\n",
      "202: Training / validation acc/loss: 1.000/0.083 / 1.000/0.108\n",
      "203: Training / validation acc/loss: 1.000/0.082 / 1.000/0.107\n",
      "204: Training / validation acc/loss: 1.000/0.081 / 1.000/0.107\n",
      "205: Training / validation acc/loss: 1.000/0.081 / 1.000/0.106\n",
      "206: Training / validation acc/loss: 1.000/0.080 / 1.000/0.105\n",
      "207: Training / validation acc/loss: 1.000/0.080 / 1.000/0.105\n",
      "208: Training / validation acc/loss: 1.000/0.079 / 1.000/0.104\n",
      "209: Training / validation acc/loss: 1.000/0.078 / 1.000/0.103\n",
      "210: Training / validation acc/loss: 1.000/0.078 / 1.000/0.103\n",
      "211: Training / validation acc/loss: 1.000/0.077 / 1.000/0.102\n",
      "212: Training / validation acc/loss: 1.000/0.077 / 1.000/0.101\n",
      "213: Training / validation acc/loss: 1.000/0.076 / 1.000/0.101\n",
      "214: Training / validation acc/loss: 1.000/0.076 / 1.000/0.100\n",
      "215: Training / validation acc/loss: 1.000/0.075 / 1.000/0.100\n",
      "216: Training / validation acc/loss: 1.000/0.074 / 1.000/0.099\n",
      "217: Training / validation acc/loss: 1.000/0.074 / 1.000/0.098\n",
      "218: Training / validation acc/loss: 1.000/0.073 / 1.000/0.098\n",
      "219: Training / validation acc/loss: 1.000/0.073 / 1.000/0.097\n",
      "220: Training / validation acc/loss: 1.000/0.072 / 1.000/0.097\n",
      "221: Training / validation acc/loss: 1.000/0.072 / 1.000/0.096\n",
      "222: Training / validation acc/loss: 1.000/0.071 / 1.000/0.096\n",
      "223: Training / validation acc/loss: 1.000/0.071 / 1.000/0.095\n",
      "224: Training / validation acc/loss: 1.000/0.070 / 1.000/0.095\n",
      "225: Training / validation acc/loss: 1.000/0.070 / 1.000/0.094\n",
      "226: Training / validation acc/loss: 1.000/0.070 / 1.000/0.093\n",
      "227: Training / validation acc/loss: 1.000/0.069 / 1.000/0.093\n",
      "228: Training / validation acc/loss: 1.000/0.069 / 1.000/0.092\n",
      "229: Training / validation acc/loss: 1.000/0.068 / 1.000/0.092\n",
      "230: Training / validation acc/loss: 1.000/0.068 / 1.000/0.091\n",
      "231: Training / validation acc/loss: 1.000/0.067 / 1.000/0.091\n",
      "232: Training / validation acc/loss: 1.000/0.067 / 1.000/0.090\n",
      "233: Training / validation acc/loss: 1.000/0.066 / 1.000/0.090\n",
      "234: Training / validation acc/loss: 1.000/0.066 / 1.000/0.090\n",
      "235: Training / validation acc/loss: 1.000/0.066 / 1.000/0.089\n",
      "236: Training / validation acc/loss: 1.000/0.065 / 1.000/0.089\n",
      "237: Training / validation acc/loss: 1.000/0.065 / 1.000/0.088\n",
      "238: Training / validation acc/loss: 1.000/0.064 / 1.000/0.088\n",
      "239: Training / validation acc/loss: 1.000/0.064 / 1.000/0.087\n",
      "240: Training / validation acc/loss: 1.000/0.064 / 1.000/0.087\n",
      "241: Training / validation acc/loss: 1.000/0.063 / 1.000/0.086\n",
      "242: Training / validation acc/loss: 1.000/0.063 / 1.000/0.086\n",
      "243: Training / validation acc/loss: 1.000/0.062 / 1.000/0.086\n",
      "244: Training / validation acc/loss: 1.000/0.062 / 1.000/0.085\n",
      "245: Training / validation acc/loss: 1.000/0.062 / 1.000/0.085\n",
      "246: Training / validation acc/loss: 1.000/0.061 / 1.000/0.084\n",
      "247: Training / validation acc/loss: 1.000/0.061 / 1.000/0.084\n",
      "248: Training / validation acc/loss: 1.000/0.061 / 1.000/0.083\n",
      "249: Training / validation acc/loss: 1.000/0.060 / 1.000/0.083\n",
      "250: Training / validation acc/loss: 1.000/0.060 / 1.000/0.083\n",
      "251: Training / validation acc/loss: 1.000/0.060 / 1.000/0.082\n",
      "252: Training / validation acc/loss: 1.000/0.059 / 1.000/0.082\n",
      "253: Training / validation acc/loss: 1.000/0.059 / 1.000/0.081\n",
      "254: Training / validation acc/loss: 1.000/0.058 / 1.000/0.081\n",
      "255: Training / validation acc/loss: 1.000/0.058 / 1.000/0.081\n",
      "256: Training / validation acc/loss: 1.000/0.058 / 1.000/0.080\n",
      "257: Training / validation acc/loss: 1.000/0.057 / 1.000/0.080\n",
      "258: Training / validation acc/loss: 1.000/0.057 / 1.000/0.080\n",
      "259: Training / validation acc/loss: 1.000/0.057 / 1.000/0.079\n",
      "260: Training / validation acc/loss: 1.000/0.057 / 1.000/0.079\n",
      "261: Training / validation acc/loss: 1.000/0.056 / 1.000/0.078\n",
      "262: Training / validation acc/loss: 1.000/0.056 / 1.000/0.078\n",
      "263: Training / validation acc/loss: 1.000/0.056 / 1.000/0.078\n",
      "264: Training / validation acc/loss: 1.000/0.055 / 1.000/0.077\n",
      "265: Training / validation acc/loss: 1.000/0.055 / 1.000/0.077\n",
      "266: Training / validation acc/loss: 1.000/0.055 / 1.000/0.077\n",
      "267: Training / validation acc/loss: 1.000/0.054 / 1.000/0.076\n",
      "268: Training / validation acc/loss: 1.000/0.054 / 1.000/0.076\n",
      "269: Training / validation acc/loss: 1.000/0.054 / 1.000/0.076\n",
      "270: Training / validation acc/loss: 1.000/0.054 / 1.000/0.075\n",
      "271: Training / validation acc/loss: 1.000/0.053 / 1.000/0.075\n",
      "272: Training / validation acc/loss: 1.000/0.053 / 1.000/0.075\n",
      "273: Training / validation acc/loss: 1.000/0.053 / 1.000/0.074\n",
      "274: Training / validation acc/loss: 1.000/0.052 / 1.000/0.074\n",
      "275: Training / validation acc/loss: 1.000/0.052 / 1.000/0.074\n",
      "276: Training / validation acc/loss: 1.000/0.052 / 1.000/0.073\n",
      "277: Training / validation acc/loss: 1.000/0.052 / 1.000/0.073\n",
      "278: Training / validation acc/loss: 1.000/0.051 / 1.000/0.073\n",
      "279: Training / validation acc/loss: 1.000/0.051 / 1.000/0.072\n",
      "280: Training / validation acc/loss: 1.000/0.051 / 1.000/0.072\n",
      "281: Training / validation acc/loss: 1.000/0.051 / 1.000/0.072\n",
      "282: Training / validation acc/loss: 1.000/0.050 / 1.000/0.071\n",
      "283: Training / validation acc/loss: 1.000/0.050 / 1.000/0.071\n",
      "284: Training / validation acc/loss: 1.000/0.050 / 1.000/0.071\n",
      "285: Training / validation acc/loss: 1.000/0.050 / 1.000/0.070\n",
      "286: Training / validation acc/loss: 1.000/0.049 / 1.000/0.070\n",
      "287: Training / validation acc/loss: 1.000/0.049 / 1.000/0.070\n",
      "288: Training / validation acc/loss: 1.000/0.049 / 1.000/0.070\n",
      "289: Training / validation acc/loss: 1.000/0.049 / 1.000/0.069\n",
      "290: Training / validation acc/loss: 1.000/0.048 / 1.000/0.069\n",
      "291: Training / validation acc/loss: 1.000/0.048 / 1.000/0.069\n",
      "292: Training / validation acc/loss: 1.000/0.048 / 1.000/0.068\n",
      "293: Training / validation acc/loss: 1.000/0.048 / 1.000/0.068\n",
      "294: Training / validation acc/loss: 1.000/0.047 / 1.000/0.068\n",
      "295: Training / validation acc/loss: 1.000/0.047 / 1.000/0.068\n",
      "296: Training / validation acc/loss: 1.000/0.047 / 1.000/0.067\n",
      "297: Training / validation acc/loss: 1.000/0.047 / 1.000/0.067\n",
      "298: Training / validation acc/loss: 1.000/0.047 / 1.000/0.067\n",
      "299: Training / validation acc/loss: 1.000/0.046 / 1.000/0.067\n",
      "300: Training / validation acc/loss: 1.000/0.046 / 1.000/0.066\n",
      "301: Training / validation acc/loss: 1.000/0.046 / 1.000/0.066\n",
      "302: Training / validation acc/loss: 1.000/0.046 / 1.000/0.066\n",
      "303: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "304: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "305: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "306: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "307: Training / validation acc/loss: 1.000/0.045 / 1.000/0.064\n",
      "308: Training / validation acc/loss: 1.000/0.044 / 1.000/0.064\n",
      "309: Training / validation acc/loss: 1.000/0.044 / 1.000/0.064\n",
      "310: Training / validation acc/loss: 1.000/0.044 / 1.000/0.064\n",
      "311: Training / validation acc/loss: 1.000/0.044 / 1.000/0.063\n",
      "312: Training / validation acc/loss: 1.000/0.044 / 1.000/0.063\n",
      "313: Training / validation acc/loss: 1.000/0.043 / 1.000/0.063\n",
      "314: Training / validation acc/loss: 1.000/0.043 / 1.000/0.063\n",
      "315: Training / validation acc/loss: 1.000/0.043 / 1.000/0.062\n",
      "316: Training / validation acc/loss: 1.000/0.043 / 1.000/0.062\n",
      "317: Training / validation acc/loss: 1.000/0.043 / 1.000/0.062\n",
      "318: Training / validation acc/loss: 1.000/0.043 / 1.000/0.062\n",
      "319: Training / validation acc/loss: 1.000/0.042 / 1.000/0.062\n",
      "320: Training / validation acc/loss: 1.000/0.042 / 1.000/0.061\n",
      "321: Training / validation acc/loss: 1.000/0.042 / 1.000/0.061\n",
      "322: Training / validation acc/loss: 1.000/0.042 / 1.000/0.061\n",
      "323: Training / validation acc/loss: 1.000/0.042 / 1.000/0.061\n",
      "324: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "325: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "326: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "327: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "328: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "329: Training / validation acc/loss: 1.000/0.041 / 1.000/0.059\n",
      "330: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "331: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "332: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "333: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "334: Training / validation acc/loss: 1.000/0.040 / 1.000/0.058\n",
      "335: Training / validation acc/loss: 1.000/0.040 / 1.000/0.058\n",
      "336: Training / validation acc/loss: 1.000/0.039 / 1.000/0.058\n",
      "337: Training / validation acc/loss: 1.000/0.039 / 1.000/0.058\n",
      "338: Training / validation acc/loss: 1.000/0.039 / 1.000/0.058\n",
      "339: Training / validation acc/loss: 1.000/0.039 / 1.000/0.057\n",
      "340: Training / validation acc/loss: 1.000/0.039 / 1.000/0.057\n",
      "341: Training / validation acc/loss: 1.000/0.039 / 1.000/0.057\n",
      "342: Training / validation acc/loss: 1.000/0.039 / 1.000/0.057\n",
      "343: Training / validation acc/loss: 1.000/0.038 / 1.000/0.057\n",
      "344: Training / validation acc/loss: 1.000/0.038 / 1.000/0.056\n",
      "345: Training / validation acc/loss: 1.000/0.038 / 1.000/0.056\n",
      "346: Training / validation acc/loss: 1.000/0.038 / 1.000/0.056\n",
      "347: Training / validation acc/loss: 1.000/0.038 / 1.000/0.056\n",
      "348: Training / validation acc/loss: 1.000/0.038 / 1.000/0.056\n",
      "349: Training / validation acc/loss: 1.000/0.037 / 1.000/0.056\n",
      "350: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "351: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "352: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "353: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "354: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "355: Training / validation acc/loss: 1.000/0.037 / 1.000/0.054\n",
      "356: Training / validation acc/loss: 1.000/0.037 / 1.000/0.054\n",
      "357: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "358: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "359: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "360: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "361: Training / validation acc/loss: 1.000/0.036 / 1.000/0.053\n",
      "362: Training / validation acc/loss: 1.000/0.036 / 1.000/0.053\n",
      "363: Training / validation acc/loss: 1.000/0.036 / 1.000/0.053\n",
      "364: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "365: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "366: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "367: Training / validation acc/loss: 1.000/0.035 / 1.000/0.052\n",
      "368: Training / validation acc/loss: 1.000/0.035 / 1.000/0.052\n",
      "369: Training / validation acc/loss: 1.000/0.035 / 1.000/0.052\n",
      "370: Training / validation acc/loss: 1.000/0.035 / 1.000/0.052\n",
      "371: Training / validation acc/loss: 1.000/0.035 / 1.000/0.052\n",
      "372: Training / validation acc/loss: 1.000/0.034 / 1.000/0.052\n",
      "373: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "374: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "375: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "376: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "377: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "378: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "379: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "380: Training / validation acc/loss: 1.000/0.034 / 1.000/0.050\n",
      "381: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "382: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "383: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "384: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "385: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "386: Training / validation acc/loss: 1.000/0.033 / 1.000/0.049\n",
      "387: Training / validation acc/loss: 1.000/0.033 / 1.000/0.049\n",
      "388: Training / validation acc/loss: 1.000/0.033 / 1.000/0.049\n",
      "389: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "390: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "391: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "392: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "393: Training / validation acc/loss: 1.000/0.032 / 1.000/0.048\n",
      "394: Training / validation acc/loss: 1.000/0.032 / 1.000/0.048\n",
      "395: Training / validation acc/loss: 1.000/0.032 / 1.000/0.048\n",
      "396: Training / validation acc/loss: 1.000/0.032 / 1.000/0.048\n",
      "397: Training / validation acc/loss: 1.000/0.032 / 1.000/0.048\n",
      "398: Training / validation acc/loss: 1.000/0.032 / 1.000/0.048\n",
      "399: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "400: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "401: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "402: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "403: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "404: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "405: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "406: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "407: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "408: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "409: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "410: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "411: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "412: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "413: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "414: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "415: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "416: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "417: Training / validation acc/loss: 1.000/0.030 / 1.000/0.045\n",
      "418: Training / validation acc/loss: 1.000/0.030 / 1.000/0.045\n",
      "419: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "420: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "421: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "422: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "423: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "424: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "425: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "426: Training / validation acc/loss: 1.000/0.029 / 1.000/0.044\n",
      "427: Training / validation acc/loss: 1.000/0.029 / 1.000/0.044\n",
      "428: Training / validation acc/loss: 1.000/0.029 / 1.000/0.044\n",
      "429: Training / validation acc/loss: 1.000/0.029 / 1.000/0.044\n",
      "430: Training / validation acc/loss: 1.000/0.029 / 1.000/0.044\n",
      "431: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "432: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "433: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "434: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "435: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "436: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "437: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "438: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "439: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "440: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "441: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "442: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "443: Training / validation acc/loss: 1.000/0.027 / 1.000/0.043\n",
      "444: Training / validation acc/loss: 1.000/0.027 / 1.000/0.043\n",
      "445: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "446: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "447: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "448: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "449: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "450: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "451: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "452: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "453: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "454: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "455: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "456: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "457: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "458: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "459: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "460: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "461: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "462: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "463: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "464: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "465: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "466: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "467: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "468: Training / validation acc/loss: 1.000/0.026 / 1.000/0.040\n",
      "469: Training / validation acc/loss: 1.000/0.026 / 1.000/0.040\n",
      "470: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "471: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "472: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "473: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "474: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "475: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "476: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "477: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "478: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "479: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "480: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "481: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "482: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "483: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "484: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "485: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "486: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "487: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "488: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "489: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "490: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "491: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "492: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "493: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "494: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "495: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "496: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "497: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "498: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "499: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "500: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "501: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "502: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "503: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "504: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "505: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "506: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "507: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "508: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "509: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "510: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "511: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "512: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "513: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "514: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "515: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "516: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "517: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "518: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "519: Training / validation acc/loss: 1.000/0.023 / 1.000/0.036\n",
      "520: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "521: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "522: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "523: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "524: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "525: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "526: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "527: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "528: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "529: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "530: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "531: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "532: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "533: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "534: Training / validation acc/loss: 1.000/0.022 / 1.000/0.035\n",
      "535: Training / validation acc/loss: 1.000/0.022 / 1.000/0.035\n",
      "536: Training / validation acc/loss: 1.000/0.022 / 1.000/0.035\n",
      "537: Training / validation acc/loss: 1.000/0.022 / 1.000/0.035\n",
      "538: Training / validation acc/loss: 1.000/0.022 / 1.000/0.035\n",
      "539: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "540: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "541: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "542: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "543: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "544: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "545: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "546: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "547: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "548: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "549: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "550: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "551: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "552: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "553: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "554: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "555: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "556: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "557: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "558: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "559: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "560: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "561: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "562: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "563: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "564: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "565: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "566: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "567: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "568: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "569: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "570: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "571: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "572: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "573: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "574: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "575: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "576: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "577: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "578: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "579: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "580: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "581: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "582: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "583: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "584: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "585: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "586: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "587: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "588: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "589: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "590: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "591: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "592: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "593: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "594: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "595: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "596: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "597: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "598: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "599: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "600: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "601: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "602: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "603: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "604: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "605: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "606: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "607: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "608: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "609: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "610: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "611: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "612: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "613: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "614: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "615: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "616: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "617: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "618: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "619: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "620: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "621: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "622: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "623: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "624: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "625: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "626: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "627: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "628: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "629: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "630: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "631: Training / validation acc/loss: 1.000/0.018 / 1.000/0.031\n",
      "632: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "633: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "634: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "635: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "636: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "637: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "638: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "639: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "640: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "641: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "642: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "643: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "644: Training / validation acc/loss: 1.000/0.017 / 1.000/0.031\n",
      "645: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "646: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "647: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "648: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "649: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "650: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "651: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "652: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "653: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "654: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "655: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "656: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "657: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "658: Training / validation acc/loss: 1.000/0.017 / 1.000/0.030\n",
      "659: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "660: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "661: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "662: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "663: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "664: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "665: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "666: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "667: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "668: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "669: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "670: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "671: Training / validation acc/loss: 1.000/0.016 / 1.000/0.030\n",
      "672: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "673: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "674: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "675: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "676: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "677: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "678: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "679: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "680: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "681: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "682: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "683: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "684: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "685: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "686: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "687: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "688: Training / validation acc/loss: 1.000/0.016 / 1.000/0.029\n",
      "689: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "690: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "691: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "692: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "693: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "694: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "695: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "696: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "697: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "698: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "699: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "700: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "701: Training / validation acc/loss: 1.000/0.015 / 1.000/0.029\n",
      "702: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "703: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "704: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "705: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "706: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "707: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "708: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "709: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "710: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "711: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "712: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "713: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "714: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "715: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "716: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "717: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "718: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "719: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "720: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "721: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "722: Training / validation acc/loss: 1.000/0.015 / 1.000/0.028\n",
      "723: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "724: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "725: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "726: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "727: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "728: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "729: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "730: Training / validation acc/loss: 1.000/0.014 / 1.000/0.028\n",
      "731: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "732: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "733: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "734: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "735: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "736: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "737: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "738: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "739: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "740: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "741: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "742: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "743: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "744: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "745: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "746: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "747: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "748: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "749: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "750: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "751: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "752: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "753: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "754: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "755: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "756: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "757: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "758: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "759: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "760: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "761: Training / validation acc/loss: 1.000/0.014 / 1.000/0.027\n",
      "762: Training / validation acc/loss: 1.000/0.013 / 1.000/0.027\n",
      "763: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "764: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "765: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "766: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "767: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "768: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "769: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "770: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "771: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "772: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "773: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "774: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "775: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "776: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "777: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "778: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "779: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "780: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "781: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "782: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "783: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "784: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "785: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "786: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "787: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "788: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "789: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "790: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "791: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "792: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "793: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "794: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "795: Training / validation acc/loss: 1.000/0.013 / 1.000/0.026\n",
      "796: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "797: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "798: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "799: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "800: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "801: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "802: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "803: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "804: Training / validation acc/loss: 1.000/0.013 / 1.000/0.025\n",
      "805: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "806: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "807: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "808: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "809: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "810: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "811: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "812: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "813: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "814: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "815: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "816: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "817: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "818: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "819: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "820: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "821: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "822: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "823: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "824: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "825: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "826: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "827: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "828: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "829: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "830: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "831: Training / validation acc/loss: 1.000/0.012 / 1.000/0.025\n",
      "832: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "833: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "834: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "835: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "836: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "837: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "838: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "839: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "840: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "841: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "842: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "843: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "844: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "845: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "846: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "847: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "848: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "849: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "850: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "851: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "852: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "853: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "854: Training / validation acc/loss: 1.000/0.012 / 1.000/0.024\n",
      "855: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "856: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "857: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "858: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "859: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "860: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "861: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "862: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "863: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "864: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "865: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "866: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "867: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "868: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "869: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "870: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "871: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "872: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "873: Training / validation acc/loss: 1.000/0.011 / 1.000/0.024\n",
      "874: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "875: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "876: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "877: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "878: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "879: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "880: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "881: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "882: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "883: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "884: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "885: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "886: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "887: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "888: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "889: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "890: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "891: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "892: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "893: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "894: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "895: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "896: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "897: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "898: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "899: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "900: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "901: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "902: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "903: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "904: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "905: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "906: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "907: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "908: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "909: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "910: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "911: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "912: Training / validation acc/loss: 1.000/0.011 / 1.000/0.023\n",
      "913: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "914: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "915: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "916: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "917: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "918: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "919: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "920: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "921: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "922: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "923: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "924: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "925: Training / validation acc/loss: 1.000/0.010 / 1.000/0.023\n",
      "926: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "927: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "928: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "929: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "930: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "931: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "932: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "933: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "934: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "935: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "936: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "937: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "938: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "939: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "940: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "941: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "942: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "943: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "944: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "945: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "946: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "947: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "948: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "949: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "950: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "951: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "952: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "953: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "954: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "955: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "956: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "957: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "958: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "959: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "960: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "961: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "962: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "963: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "964: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "965: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "966: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "967: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "968: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "969: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "970: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "971: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "972: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "973: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "974: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "975: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "976: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "977: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "978: Training / validation acc/loss: 1.000/0.010 / 1.000/0.022\n",
      "979: Training / validation acc/loss: 1.000/0.010 / 1.000/0.021\n",
      "980: Training / validation acc/loss: 1.000/0.010 / 1.000/0.021\n",
      "981: Training / validation acc/loss: 1.000/0.010 / 1.000/0.021\n",
      "982: Training / validation acc/loss: 1.000/0.010 / 1.000/0.021\n",
      "983: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "984: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "985: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "986: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "987: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "988: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "989: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "990: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "991: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "992: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "993: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "994: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "995: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "996: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "997: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "998: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n",
      "999: Training / validation acc/loss: 1.000/0.009 / 1.000/0.021\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "sigma = 2 / (3 + 6)\n",
    "net1 = Shallow(sigma).to(dev)\n",
    "train(net1, train_loader, val_loader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4068a98a-2654-41a4-b59f-fb39b5210833",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:29:09.157202Z",
     "iopub.status.busy": "2023-04-19T18:29:09.156497Z",
     "iopub.status.idle": "2023-04-19T18:29:09.328489Z",
     "shell.execute_reply": "2023-04-19T18:29:09.327719Z",
     "shell.execute_reply.started": "2023-04-19T18:29:09.157170Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(train_data[0], train_data[1], net1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594d153-0df4-448b-af02-b45473a54481",
   "metadata": {},
   "source": [
    "As we can see, the accuracy is perfect and the decision boundary is also near perfect. The sequence converge near the epoch 149"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce05db-1930-4ef6-97b5-7852320fefb9",
   "metadata": {},
   "source": [
    "Small sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22953c15-8390-4b78-8506-ea85358583c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:36:49.151452Z",
     "iopub.status.busy": "2023-04-19T18:36:49.150505Z",
     "iopub.status.idle": "2023-04-19T18:36:51.382102Z",
     "shell.execute_reply": "2023-04-19T18:36:51.381177Z",
     "shell.execute_reply.started": "2023-04-19T18:36:49.151422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.460/0.693 / 0.460/0.693\n",
      "1: Training / validation acc/loss: 0.400/0.693 / 0.400/0.693\n",
      "2: Training / validation acc/loss: 0.380/0.693 / 0.340/0.693\n",
      "3: Training / validation acc/loss: 0.360/0.693 / 0.350/0.693\n",
      "4: Training / validation acc/loss: 0.330/0.693 / 0.350/0.693\n",
      "5: Training / validation acc/loss: 0.300/0.693 / 0.330/0.693\n",
      "6: Training / validation acc/loss: 0.290/0.693 / 0.350/0.693\n",
      "7: Training / validation acc/loss: 0.300/0.693 / 0.370/0.693\n",
      "8: Training / validation acc/loss: 0.320/0.693 / 0.410/0.693\n",
      "9: Training / validation acc/loss: 0.370/0.693 / 0.410/0.693\n",
      "10: Training / validation acc/loss: 0.400/0.693 / 0.420/0.693\n",
      "11: Training / validation acc/loss: 0.400/0.693 / 0.420/0.693\n",
      "12: Training / validation acc/loss: 0.410/0.693 / 0.420/0.693\n",
      "13: Training / validation acc/loss: 0.420/0.693 / 0.430/0.693\n",
      "14: Training / validation acc/loss: 0.420/0.693 / 0.430/0.693\n",
      "15: Training / validation acc/loss: 0.430/0.693 / 0.430/0.693\n",
      "16: Training / validation acc/loss: 0.450/0.693 / 0.440/0.693\n",
      "17: Training / validation acc/loss: 0.450/0.693 / 0.450/0.693\n",
      "18: Training / validation acc/loss: 0.460/0.693 / 0.480/0.693\n",
      "19: Training / validation acc/loss: 0.530/0.693 / 0.590/0.693\n",
      "20: Training / validation acc/loss: 0.580/0.693 / 0.650/0.693\n",
      "21: Training / validation acc/loss: 0.630/0.693 / 0.670/0.693\n",
      "22: Training / validation acc/loss: 0.660/0.693 / 0.690/0.693\n",
      "23: Training / validation acc/loss: 0.690/0.693 / 0.690/0.693\n",
      "24: Training / validation acc/loss: 0.700/0.693 / 0.690/0.693\n",
      "25: Training / validation acc/loss: 0.690/0.693 / 0.660/0.693\n",
      "26: Training / validation acc/loss: 0.670/0.693 / 0.660/0.693\n",
      "27: Training / validation acc/loss: 0.670/0.693 / 0.670/0.693\n",
      "28: Training / validation acc/loss: 0.660/0.693 / 0.670/0.693\n",
      "29: Training / validation acc/loss: 0.670/0.693 / 0.680/0.693\n",
      "30: Training / validation acc/loss: 0.680/0.693 / 0.680/0.693\n",
      "31: Training / validation acc/loss: 0.700/0.693 / 0.690/0.693\n",
      "32: Training / validation acc/loss: 0.700/0.693 / 0.700/0.693\n",
      "33: Training / validation acc/loss: 0.700/0.693 / 0.710/0.693\n",
      "34: Training / validation acc/loss: 0.700/0.693 / 0.720/0.693\n",
      "35: Training / validation acc/loss: 0.720/0.693 / 0.720/0.693\n",
      "36: Training / validation acc/loss: 0.720/0.693 / 0.720/0.693\n",
      "37: Training / validation acc/loss: 0.730/0.693 / 0.750/0.693\n",
      "38: Training / validation acc/loss: 0.730/0.693 / 0.740/0.693\n",
      "39: Training / validation acc/loss: 0.730/0.693 / 0.750/0.693\n",
      "40: Training / validation acc/loss: 0.730/0.693 / 0.750/0.693\n",
      "41: Training / validation acc/loss: 0.740/0.693 / 0.750/0.693\n",
      "42: Training / validation acc/loss: 0.750/0.693 / 0.750/0.693\n",
      "43: Training / validation acc/loss: 0.750/0.693 / 0.750/0.693\n",
      "44: Training / validation acc/loss: 0.750/0.693 / 0.750/0.693\n",
      "45: Training / validation acc/loss: 0.750/0.693 / 0.750/0.693\n",
      "46: Training / validation acc/loss: 0.750/0.693 / 0.750/0.693\n",
      "47: Training / validation acc/loss: 0.750/0.693 / 0.760/0.693\n",
      "48: Training / validation acc/loss: 0.750/0.693 / 0.760/0.693\n",
      "49: Training / validation acc/loss: 0.750/0.693 / 0.760/0.693\n",
      "50: Training / validation acc/loss: 0.760/0.693 / 0.770/0.693\n",
      "51: Training / validation acc/loss: 0.780/0.693 / 0.770/0.693\n",
      "52: Training / validation acc/loss: 0.780/0.693 / 0.770/0.693\n",
      "53: Training / validation acc/loss: 0.800/0.693 / 0.770/0.693\n",
      "54: Training / validation acc/loss: 0.810/0.693 / 0.770/0.693\n",
      "55: Training / validation acc/loss: 0.810/0.693 / 0.770/0.693\n",
      "56: Training / validation acc/loss: 0.800/0.693 / 0.770/0.693\n",
      "57: Training / validation acc/loss: 0.800/0.693 / 0.770/0.693\n",
      "58: Training / validation acc/loss: 0.800/0.693 / 0.780/0.693\n",
      "59: Training / validation acc/loss: 0.800/0.693 / 0.780/0.693\n",
      "60: Training / validation acc/loss: 0.800/0.693 / 0.780/0.693\n",
      "61: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "62: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "63: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "64: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "65: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "66: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "67: Training / validation acc/loss: 0.820/0.693 / 0.790/0.693\n",
      "68: Training / validation acc/loss: 0.820/0.693 / 0.790/0.693\n",
      "69: Training / validation acc/loss: 0.830/0.693 / 0.790/0.693\n",
      "70: Training / validation acc/loss: 0.830/0.693 / 0.790/0.693\n",
      "71: Training / validation acc/loss: 0.820/0.693 / 0.790/0.693\n",
      "72: Training / validation acc/loss: 0.840/0.693 / 0.790/0.693\n",
      "73: Training / validation acc/loss: 0.840/0.693 / 0.790/0.693\n",
      "74: Training / validation acc/loss: 0.840/0.693 / 0.790/0.693\n",
      "75: Training / validation acc/loss: 0.840/0.693 / 0.790/0.693\n",
      "76: Training / validation acc/loss: 0.810/0.693 / 0.790/0.693\n",
      "77: Training / validation acc/loss: 0.810/0.693 / 0.790/0.693\n",
      "78: Training / validation acc/loss: 0.810/0.693 / 0.790/0.693\n",
      "79: Training / validation acc/loss: 0.810/0.693 / 0.790/0.693\n",
      "80: Training / validation acc/loss: 0.810/0.693 / 0.790/0.693\n",
      "81: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "82: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "83: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "84: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "85: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "86: Training / validation acc/loss: 0.800/0.693 / 0.790/0.693\n",
      "87: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "88: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "89: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "90: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "91: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "92: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "93: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "94: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "95: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "96: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "97: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "98: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "99: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "100: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "101: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "102: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "103: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "104: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "105: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "106: Training / validation acc/loss: 0.800/0.693 / 0.810/0.693\n",
      "107: Training / validation acc/loss: 0.800/0.693 / 0.810/0.693\n",
      "108: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "109: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "110: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "111: Training / validation acc/loss: 0.800/0.693 / 0.800/0.693\n",
      "112: Training / validation acc/loss: 0.790/0.693 / 0.800/0.693\n",
      "113: Training / validation acc/loss: 0.790/0.693 / 0.800/0.693\n",
      "114: Training / validation acc/loss: 0.790/0.693 / 0.800/0.693\n",
      "115: Training / validation acc/loss: 0.790/0.693 / 0.800/0.693\n",
      "116: Training / validation acc/loss: 0.790/0.693 / 0.800/0.693\n",
      "117: Training / validation acc/loss: 0.780/0.693 / 0.800/0.693\n",
      "118: Training / validation acc/loss: 0.780/0.693 / 0.800/0.693\n",
      "119: Training / validation acc/loss: 0.780/0.693 / 0.800/0.693\n",
      "120: Training / validation acc/loss: 0.780/0.693 / 0.800/0.693\n",
      "121: Training / validation acc/loss: 0.780/0.693 / 0.800/0.693\n",
      "122: Training / validation acc/loss: 0.780/0.693 / 0.800/0.693\n",
      "123: Training / validation acc/loss: 0.780/0.693 / 0.800/0.693\n",
      "124: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "125: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "126: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "127: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "128: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "129: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "130: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "131: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "132: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "133: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "134: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "135: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "136: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "137: Training / validation acc/loss: 0.780/0.693 / 0.810/0.693\n",
      "138: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "139: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "140: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "141: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "142: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "143: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "144: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "145: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "146: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "147: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "148: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "149: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "150: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "151: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "152: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "153: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "154: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "155: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "156: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "157: Training / validation acc/loss: 0.780/0.693 / 0.820/0.693\n",
      "158: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "159: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "160: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "161: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "162: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "163: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "164: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "165: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "166: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "167: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "168: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "169: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "170: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "171: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "172: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "173: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "174: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "175: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "176: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "177: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "178: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "179: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "180: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "181: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "182: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "183: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "184: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "185: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "186: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "187: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "188: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "189: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "190: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "191: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "192: Training / validation acc/loss: 0.770/0.693 / 0.820/0.693\n",
      "193: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "194: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "195: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "196: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "197: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "198: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "199: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "200: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "201: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "202: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "203: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "204: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "205: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "206: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "207: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "208: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "209: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "210: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "211: Training / validation acc/loss: 0.770/0.693 / 0.810/0.693\n",
      "212: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "213: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "214: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "215: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "216: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "217: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "218: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "219: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "220: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "221: Training / validation acc/loss: 0.770/0.693 / 0.800/0.693\n",
      "222: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "223: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "224: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "225: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "226: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "227: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "228: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "229: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "230: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "231: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "232: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "233: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "234: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "235: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "236: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "237: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "238: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "239: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "240: Training / validation acc/loss: 0.770/0.693 / 0.790/0.693\n",
      "241: Training / validation acc/loss: 0.760/0.693 / 0.790/0.693\n",
      "242: Training / validation acc/loss: 0.760/0.693 / 0.790/0.693\n",
      "243: Training / validation acc/loss: 0.760/0.693 / 0.790/0.693\n",
      "244: Training / validation acc/loss: 0.760/0.693 / 0.790/0.693\n",
      "245: Training / validation acc/loss: 0.760/0.693 / 0.790/0.693\n",
      "246: Training / validation acc/loss: 0.760/0.692 / 0.790/0.693\n",
      "247: Training / validation acc/loss: 0.760/0.692 / 0.790/0.693\n",
      "248: Training / validation acc/loss: 0.760/0.692 / 0.790/0.693\n",
      "249: Training / validation acc/loss: 0.760/0.692 / 0.790/0.693\n",
      "250: Training / validation acc/loss: 0.760/0.692 / 0.790/0.693\n",
      "251: Training / validation acc/loss: 0.760/0.692 / 0.790/0.692\n",
      "252: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "253: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "254: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "255: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "256: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "257: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "258: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "259: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "260: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "261: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "262: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "263: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "264: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "265: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "266: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "267: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "268: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "269: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "270: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "271: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "272: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "273: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "274: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "275: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "276: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "277: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "278: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "279: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "280: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "281: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "282: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "283: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "284: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "285: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "286: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "287: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "288: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "289: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "290: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "291: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "292: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "293: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "294: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "295: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "296: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "297: Training / validation acc/loss: 0.760/0.692 / 0.780/0.692\n",
      "298: Training / validation acc/loss: 0.760/0.691 / 0.780/0.692\n",
      "299: Training / validation acc/loss: 0.760/0.691 / 0.780/0.692\n",
      "300: Training / validation acc/loss: 0.760/0.691 / 0.780/0.692\n",
      "301: Training / validation acc/loss: 0.760/0.691 / 0.780/0.692\n",
      "302: Training / validation acc/loss: 0.760/0.691 / 0.780/0.692\n",
      "303: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "304: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "305: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "306: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "307: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "308: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "309: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "310: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "311: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "312: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "313: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "314: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "315: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "316: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "317: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "318: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "319: Training / validation acc/loss: 0.760/0.691 / 0.780/0.691\n",
      "320: Training / validation acc/loss: 0.760/0.690 / 0.780/0.691\n",
      "321: Training / validation acc/loss: 0.760/0.690 / 0.780/0.691\n",
      "322: Training / validation acc/loss: 0.750/0.690 / 0.780/0.691\n",
      "323: Training / validation acc/loss: 0.750/0.690 / 0.780/0.691\n",
      "324: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "325: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "326: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "327: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "328: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "329: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "330: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "331: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "332: Training / validation acc/loss: 0.750/0.690 / 0.780/0.690\n",
      "333: Training / validation acc/loss: 0.750/0.689 / 0.780/0.690\n",
      "334: Training / validation acc/loss: 0.750/0.689 / 0.780/0.690\n",
      "335: Training / validation acc/loss: 0.750/0.689 / 0.780/0.690\n",
      "336: Training / validation acc/loss: 0.740/0.689 / 0.780/0.690\n",
      "337: Training / validation acc/loss: 0.740/0.689 / 0.780/0.690\n",
      "338: Training / validation acc/loss: 0.740/0.689 / 0.780/0.689\n",
      "339: Training / validation acc/loss: 0.740/0.689 / 0.780/0.689\n",
      "340: Training / validation acc/loss: 0.740/0.689 / 0.780/0.689\n",
      "341: Training / validation acc/loss: 0.740/0.689 / 0.780/0.689\n",
      "342: Training / validation acc/loss: 0.740/0.688 / 0.780/0.689\n",
      "343: Training / validation acc/loss: 0.740/0.688 / 0.780/0.689\n",
      "344: Training / validation acc/loss: 0.740/0.688 / 0.780/0.689\n",
      "345: Training / validation acc/loss: 0.740/0.688 / 0.780/0.689\n",
      "346: Training / validation acc/loss: 0.740/0.688 / 0.780/0.689\n",
      "347: Training / validation acc/loss: 0.740/0.688 / 0.780/0.688\n",
      "348: Training / validation acc/loss: 0.740/0.688 / 0.780/0.688\n",
      "349: Training / validation acc/loss: 0.740/0.687 / 0.780/0.688\n",
      "350: Training / validation acc/loss: 0.740/0.687 / 0.780/0.688\n",
      "351: Training / validation acc/loss: 0.740/0.687 / 0.780/0.688\n",
      "352: Training / validation acc/loss: 0.740/0.687 / 0.780/0.688\n",
      "353: Training / validation acc/loss: 0.740/0.687 / 0.780/0.687\n",
      "354: Training / validation acc/loss: 0.740/0.687 / 0.780/0.687\n",
      "355: Training / validation acc/loss: 0.740/0.686 / 0.780/0.687\n",
      "356: Training / validation acc/loss: 0.740/0.686 / 0.780/0.687\n",
      "357: Training / validation acc/loss: 0.740/0.686 / 0.770/0.687\n",
      "358: Training / validation acc/loss: 0.740/0.686 / 0.770/0.687\n",
      "359: Training / validation acc/loss: 0.740/0.685 / 0.770/0.686\n",
      "360: Training / validation acc/loss: 0.740/0.685 / 0.770/0.686\n",
      "361: Training / validation acc/loss: 0.740/0.685 / 0.770/0.686\n",
      "362: Training / validation acc/loss: 0.740/0.685 / 0.770/0.686\n",
      "363: Training / validation acc/loss: 0.740/0.684 / 0.770/0.685\n",
      "364: Training / validation acc/loss: 0.740/0.684 / 0.770/0.685\n",
      "365: Training / validation acc/loss: 0.740/0.684 / 0.770/0.685\n",
      "366: Training / validation acc/loss: 0.740/0.684 / 0.770/0.685\n",
      "367: Training / validation acc/loss: 0.740/0.683 / 0.770/0.684\n",
      "368: Training / validation acc/loss: 0.740/0.683 / 0.770/0.684\n",
      "369: Training / validation acc/loss: 0.740/0.682 / 0.770/0.684\n",
      "370: Training / validation acc/loss: 0.740/0.682 / 0.770/0.683\n",
      "371: Training / validation acc/loss: 0.740/0.682 / 0.770/0.683\n",
      "372: Training / validation acc/loss: 0.740/0.681 / 0.770/0.683\n",
      "373: Training / validation acc/loss: 0.740/0.681 / 0.760/0.682\n",
      "374: Training / validation acc/loss: 0.740/0.680 / 0.760/0.682\n",
      "375: Training / validation acc/loss: 0.740/0.680 / 0.760/0.682\n",
      "376: Training / validation acc/loss: 0.740/0.680 / 0.760/0.681\n",
      "377: Training / validation acc/loss: 0.740/0.679 / 0.760/0.681\n",
      "378: Training / validation acc/loss: 0.740/0.678 / 0.760/0.680\n",
      "379: Training / validation acc/loss: 0.740/0.678 / 0.760/0.680\n",
      "380: Training / validation acc/loss: 0.740/0.677 / 0.760/0.679\n",
      "381: Training / validation acc/loss: 0.740/0.677 / 0.760/0.679\n",
      "382: Training / validation acc/loss: 0.740/0.676 / 0.760/0.678\n",
      "383: Training / validation acc/loss: 0.740/0.675 / 0.760/0.678\n",
      "384: Training / validation acc/loss: 0.740/0.675 / 0.760/0.677\n",
      "385: Training / validation acc/loss: 0.740/0.674 / 0.760/0.676\n",
      "386: Training / validation acc/loss: 0.740/0.673 / 0.760/0.676\n",
      "387: Training / validation acc/loss: 0.740/0.672 / 0.760/0.675\n",
      "388: Training / validation acc/loss: 0.740/0.672 / 0.760/0.674\n",
      "389: Training / validation acc/loss: 0.740/0.671 / 0.760/0.673\n",
      "390: Training / validation acc/loss: 0.740/0.670 / 0.760/0.673\n",
      "391: Training / validation acc/loss: 0.740/0.669 / 0.760/0.672\n",
      "392: Training / validation acc/loss: 0.740/0.668 / 0.760/0.671\n",
      "393: Training / validation acc/loss: 0.740/0.667 / 0.750/0.670\n",
      "394: Training / validation acc/loss: 0.740/0.665 / 0.750/0.669\n",
      "395: Training / validation acc/loss: 0.740/0.664 / 0.750/0.668\n",
      "396: Training / validation acc/loss: 0.740/0.663 / 0.750/0.667\n",
      "397: Training / validation acc/loss: 0.740/0.662 / 0.750/0.666\n",
      "398: Training / validation acc/loss: 0.740/0.660 / 0.750/0.664\n",
      "399: Training / validation acc/loss: 0.740/0.659 / 0.750/0.663\n",
      "400: Training / validation acc/loss: 0.740/0.657 / 0.750/0.662\n",
      "401: Training / validation acc/loss: 0.740/0.656 / 0.750/0.660\n",
      "402: Training / validation acc/loss: 0.740/0.654 / 0.750/0.659\n",
      "403: Training / validation acc/loss: 0.730/0.652 / 0.750/0.658\n",
      "404: Training / validation acc/loss: 0.730/0.650 / 0.750/0.656\n",
      "405: Training / validation acc/loss: 0.730/0.649 / 0.750/0.654\n",
      "406: Training / validation acc/loss: 0.730/0.647 / 0.750/0.653\n",
      "407: Training / validation acc/loss: 0.730/0.645 / 0.750/0.651\n",
      "408: Training / validation acc/loss: 0.730/0.642 / 0.740/0.649\n",
      "409: Training / validation acc/loss: 0.730/0.640 / 0.740/0.647\n",
      "410: Training / validation acc/loss: 0.730/0.638 / 0.740/0.645\n",
      "411: Training / validation acc/loss: 0.730/0.636 / 0.740/0.643\n",
      "412: Training / validation acc/loss: 0.730/0.633 / 0.740/0.641\n",
      "413: Training / validation acc/loss: 0.730/0.631 / 0.740/0.639\n",
      "414: Training / validation acc/loss: 0.730/0.628 / 0.740/0.636\n",
      "415: Training / validation acc/loss: 0.730/0.625 / 0.730/0.634\n",
      "416: Training / validation acc/loss: 0.730/0.623 / 0.730/0.632\n",
      "417: Training / validation acc/loss: 0.730/0.620 / 0.730/0.629\n",
      "418: Training / validation acc/loss: 0.730/0.617 / 0.730/0.627\n",
      "419: Training / validation acc/loss: 0.740/0.614 / 0.730/0.624\n",
      "420: Training / validation acc/loss: 0.740/0.611 / 0.730/0.621\n",
      "421: Training / validation acc/loss: 0.740/0.608 / 0.730/0.619\n",
      "422: Training / validation acc/loss: 0.740/0.605 / 0.740/0.616\n",
      "423: Training / validation acc/loss: 0.740/0.602 / 0.740/0.613\n",
      "424: Training / validation acc/loss: 0.740/0.599 / 0.740/0.610\n",
      "425: Training / validation acc/loss: 0.740/0.596 / 0.740/0.607\n",
      "426: Training / validation acc/loss: 0.740/0.593 / 0.740/0.605\n",
      "427: Training / validation acc/loss: 0.740/0.589 / 0.740/0.602\n",
      "428: Training / validation acc/loss: 0.740/0.586 / 0.740/0.599\n",
      "429: Training / validation acc/loss: 0.740/0.583 / 0.740/0.596\n",
      "430: Training / validation acc/loss: 0.750/0.580 / 0.750/0.593\n",
      "431: Training / validation acc/loss: 0.750/0.576 / 0.760/0.590\n",
      "432: Training / validation acc/loss: 0.750/0.573 / 0.770/0.586\n",
      "433: Training / validation acc/loss: 0.750/0.570 / 0.770/0.583\n",
      "434: Training / validation acc/loss: 0.750/0.566 / 0.760/0.580\n",
      "435: Training / validation acc/loss: 0.760/0.563 / 0.760/0.577\n",
      "436: Training / validation acc/loss: 0.760/0.560 / 0.760/0.574\n",
      "437: Training / validation acc/loss: 0.760/0.557 / 0.760/0.571\n",
      "438: Training / validation acc/loss: 0.760/0.553 / 0.770/0.568\n",
      "439: Training / validation acc/loss: 0.760/0.550 / 0.760/0.565\n",
      "440: Training / validation acc/loss: 0.760/0.547 / 0.760/0.561\n",
      "441: Training / validation acc/loss: 0.760/0.544 / 0.760/0.558\n",
      "442: Training / validation acc/loss: 0.760/0.540 / 0.760/0.555\n",
      "443: Training / validation acc/loss: 0.760/0.537 / 0.770/0.551\n",
      "444: Training / validation acc/loss: 0.760/0.533 / 0.770/0.548\n",
      "445: Training / validation acc/loss: 0.760/0.530 / 0.780/0.544\n",
      "446: Training / validation acc/loss: 0.760/0.527 / 0.780/0.541\n",
      "447: Training / validation acc/loss: 0.760/0.523 / 0.780/0.538\n",
      "448: Training / validation acc/loss: 0.760/0.520 / 0.780/0.534\n",
      "449: Training / validation acc/loss: 0.760/0.516 / 0.780/0.530\n",
      "450: Training / validation acc/loss: 0.760/0.512 / 0.780/0.527\n",
      "451: Training / validation acc/loss: 0.760/0.508 / 0.780/0.523\n",
      "452: Training / validation acc/loss: 0.760/0.505 / 0.780/0.519\n",
      "453: Training / validation acc/loss: 0.760/0.501 / 0.780/0.516\n",
      "454: Training / validation acc/loss: 0.760/0.497 / 0.770/0.512\n",
      "455: Training / validation acc/loss: 0.770/0.493 / 0.770/0.508\n",
      "456: Training / validation acc/loss: 0.770/0.490 / 0.770/0.505\n",
      "457: Training / validation acc/loss: 0.770/0.486 / 0.770/0.501\n",
      "458: Training / validation acc/loss: 0.770/0.482 / 0.770/0.497\n",
      "459: Training / validation acc/loss: 0.770/0.478 / 0.770/0.493\n",
      "460: Training / validation acc/loss: 0.780/0.474 / 0.780/0.489\n",
      "461: Training / validation acc/loss: 0.780/0.470 / 0.780/0.485\n",
      "462: Training / validation acc/loss: 0.780/0.466 / 0.780/0.481\n",
      "463: Training / validation acc/loss: 0.780/0.461 / 0.780/0.477\n",
      "464: Training / validation acc/loss: 0.770/0.457 / 0.780/0.473\n",
      "465: Training / validation acc/loss: 0.780/0.453 / 0.780/0.469\n",
      "466: Training / validation acc/loss: 0.790/0.449 / 0.780/0.465\n",
      "467: Training / validation acc/loss: 0.790/0.444 / 0.780/0.460\n",
      "468: Training / validation acc/loss: 0.790/0.440 / 0.790/0.456\n",
      "469: Training / validation acc/loss: 0.810/0.435 / 0.790/0.452\n",
      "470: Training / validation acc/loss: 0.820/0.431 / 0.790/0.447\n",
      "471: Training / validation acc/loss: 0.820/0.426 / 0.800/0.443\n",
      "472: Training / validation acc/loss: 0.830/0.421 / 0.800/0.438\n",
      "473: Training / validation acc/loss: 0.840/0.417 / 0.800/0.434\n",
      "474: Training / validation acc/loss: 0.840/0.412 / 0.810/0.429\n",
      "475: Training / validation acc/loss: 0.840/0.407 / 0.810/0.424\n",
      "476: Training / validation acc/loss: 0.840/0.402 / 0.830/0.419\n",
      "477: Training / validation acc/loss: 0.850/0.397 / 0.830/0.414\n",
      "478: Training / validation acc/loss: 0.870/0.392 / 0.840/0.409\n",
      "479: Training / validation acc/loss: 0.880/0.387 / 0.840/0.404\n",
      "480: Training / validation acc/loss: 0.890/0.381 / 0.840/0.398\n",
      "481: Training / validation acc/loss: 0.890/0.376 / 0.850/0.393\n",
      "482: Training / validation acc/loss: 0.900/0.371 / 0.850/0.388\n",
      "483: Training / validation acc/loss: 0.910/0.365 / 0.860/0.382\n",
      "484: Training / validation acc/loss: 0.910/0.360 / 0.870/0.377\n",
      "485: Training / validation acc/loss: 0.920/0.355 / 0.880/0.372\n",
      "486: Training / validation acc/loss: 0.930/0.349 / 0.890/0.366\n",
      "487: Training / validation acc/loss: 0.930/0.344 / 0.890/0.361\n",
      "488: Training / validation acc/loss: 0.930/0.338 / 0.900/0.355\n",
      "489: Training / validation acc/loss: 0.940/0.333 / 0.900/0.350\n",
      "490: Training / validation acc/loss: 0.950/0.327 / 0.910/0.345\n",
      "491: Training / validation acc/loss: 0.960/0.322 / 0.920/0.339\n",
      "492: Training / validation acc/loss: 0.970/0.317 / 0.930/0.334\n",
      "493: Training / validation acc/loss: 0.970/0.311 / 0.930/0.329\n",
      "494: Training / validation acc/loss: 0.970/0.306 / 0.930/0.324\n",
      "495: Training / validation acc/loss: 0.970/0.301 / 0.940/0.319\n",
      "496: Training / validation acc/loss: 0.970/0.296 / 0.950/0.314\n",
      "497: Training / validation acc/loss: 0.970/0.291 / 0.950/0.310\n",
      "498: Training / validation acc/loss: 0.970/0.286 / 0.950/0.305\n",
      "499: Training / validation acc/loss: 0.980/0.281 / 0.950/0.300\n",
      "500: Training / validation acc/loss: 0.980/0.277 / 0.950/0.296\n",
      "501: Training / validation acc/loss: 0.980/0.272 / 0.950/0.292\n",
      "502: Training / validation acc/loss: 0.980/0.268 / 0.950/0.288\n",
      "503: Training / validation acc/loss: 0.980/0.263 / 0.950/0.284\n",
      "504: Training / validation acc/loss: 0.990/0.259 / 0.950/0.280\n",
      "505: Training / validation acc/loss: 0.990/0.255 / 0.950/0.276\n",
      "506: Training / validation acc/loss: 0.990/0.251 / 0.960/0.272\n",
      "507: Training / validation acc/loss: 0.990/0.247 / 0.960/0.268\n",
      "508: Training / validation acc/loss: 0.990/0.243 / 0.960/0.265\n",
      "509: Training / validation acc/loss: 0.990/0.239 / 0.970/0.261\n",
      "510: Training / validation acc/loss: 0.990/0.235 / 0.970/0.258\n",
      "511: Training / validation acc/loss: 0.990/0.232 / 0.970/0.255\n",
      "512: Training / validation acc/loss: 0.990/0.228 / 0.980/0.251\n",
      "513: Training / validation acc/loss: 0.990/0.225 / 0.980/0.248\n",
      "514: Training / validation acc/loss: 0.990/0.221 / 0.980/0.245\n",
      "515: Training / validation acc/loss: 0.990/0.218 / 0.990/0.242\n",
      "516: Training / validation acc/loss: 0.990/0.215 / 0.990/0.239\n",
      "517: Training / validation acc/loss: 0.990/0.211 / 0.990/0.236\n",
      "518: Training / validation acc/loss: 0.990/0.208 / 0.990/0.233\n",
      "519: Training / validation acc/loss: 0.990/0.205 / 0.990/0.231\n",
      "520: Training / validation acc/loss: 1.000/0.202 / 0.990/0.228\n",
      "521: Training / validation acc/loss: 1.000/0.199 / 0.990/0.225\n",
      "522: Training / validation acc/loss: 1.000/0.196 / 0.990/0.223\n",
      "523: Training / validation acc/loss: 1.000/0.194 / 0.990/0.220\n",
      "524: Training / validation acc/loss: 1.000/0.191 / 0.990/0.218\n",
      "525: Training / validation acc/loss: 1.000/0.188 / 0.990/0.215\n",
      "526: Training / validation acc/loss: 1.000/0.185 / 0.990/0.213\n",
      "527: Training / validation acc/loss: 1.000/0.183 / 0.990/0.210\n",
      "528: Training / validation acc/loss: 1.000/0.180 / 0.990/0.208\n",
      "529: Training / validation acc/loss: 1.000/0.178 / 0.990/0.206\n",
      "530: Training / validation acc/loss: 1.000/0.175 / 0.990/0.203\n",
      "531: Training / validation acc/loss: 1.000/0.173 / 0.990/0.201\n",
      "532: Training / validation acc/loss: 1.000/0.170 / 0.990/0.199\n",
      "533: Training / validation acc/loss: 1.000/0.168 / 0.990/0.197\n",
      "534: Training / validation acc/loss: 1.000/0.166 / 0.990/0.194\n",
      "535: Training / validation acc/loss: 1.000/0.163 / 0.990/0.192\n",
      "536: Training / validation acc/loss: 1.000/0.161 / 0.990/0.190\n",
      "537: Training / validation acc/loss: 1.000/0.159 / 0.990/0.188\n",
      "538: Training / validation acc/loss: 1.000/0.157 / 0.990/0.186\n",
      "539: Training / validation acc/loss: 1.000/0.155 / 0.990/0.184\n",
      "540: Training / validation acc/loss: 1.000/0.153 / 1.000/0.183\n",
      "541: Training / validation acc/loss: 1.000/0.151 / 1.000/0.181\n",
      "542: Training / validation acc/loss: 1.000/0.149 / 1.000/0.179\n",
      "543: Training / validation acc/loss: 1.000/0.147 / 1.000/0.177\n",
      "544: Training / validation acc/loss: 1.000/0.146 / 1.000/0.175\n",
      "545: Training / validation acc/loss: 1.000/0.144 / 1.000/0.174\n",
      "546: Training / validation acc/loss: 1.000/0.142 / 1.000/0.172\n",
      "547: Training / validation acc/loss: 1.000/0.140 / 1.000/0.170\n",
      "548: Training / validation acc/loss: 1.000/0.139 / 1.000/0.168\n",
      "549: Training / validation acc/loss: 1.000/0.137 / 1.000/0.167\n",
      "550: Training / validation acc/loss: 1.000/0.136 / 1.000/0.165\n",
      "551: Training / validation acc/loss: 1.000/0.134 / 1.000/0.164\n",
      "552: Training / validation acc/loss: 1.000/0.132 / 1.000/0.162\n",
      "553: Training / validation acc/loss: 1.000/0.131 / 1.000/0.160\n",
      "554: Training / validation acc/loss: 1.000/0.129 / 1.000/0.159\n",
      "555: Training / validation acc/loss: 1.000/0.128 / 1.000/0.157\n",
      "556: Training / validation acc/loss: 1.000/0.126 / 1.000/0.156\n",
      "557: Training / validation acc/loss: 1.000/0.125 / 1.000/0.154\n",
      "558: Training / validation acc/loss: 1.000/0.124 / 1.000/0.153\n",
      "559: Training / validation acc/loss: 1.000/0.122 / 1.000/0.151\n",
      "560: Training / validation acc/loss: 1.000/0.121 / 1.000/0.150\n",
      "561: Training / validation acc/loss: 1.000/0.120 / 1.000/0.149\n",
      "562: Training / validation acc/loss: 1.000/0.118 / 1.000/0.147\n",
      "563: Training / validation acc/loss: 1.000/0.117 / 1.000/0.146\n",
      "564: Training / validation acc/loss: 1.000/0.116 / 1.000/0.145\n",
      "565: Training / validation acc/loss: 1.000/0.115 / 1.000/0.143\n",
      "566: Training / validation acc/loss: 1.000/0.113 / 1.000/0.142\n",
      "567: Training / validation acc/loss: 1.000/0.112 / 1.000/0.141\n",
      "568: Training / validation acc/loss: 1.000/0.111 / 1.000/0.140\n",
      "569: Training / validation acc/loss: 1.000/0.110 / 1.000/0.138\n",
      "570: Training / validation acc/loss: 1.000/0.109 / 1.000/0.137\n",
      "571: Training / validation acc/loss: 1.000/0.108 / 1.000/0.136\n",
      "572: Training / validation acc/loss: 1.000/0.107 / 1.000/0.135\n",
      "573: Training / validation acc/loss: 1.000/0.106 / 1.000/0.134\n",
      "574: Training / validation acc/loss: 1.000/0.105 / 1.000/0.133\n",
      "575: Training / validation acc/loss: 1.000/0.104 / 1.000/0.132\n",
      "576: Training / validation acc/loss: 1.000/0.103 / 1.000/0.131\n",
      "577: Training / validation acc/loss: 1.000/0.102 / 1.000/0.130\n",
      "578: Training / validation acc/loss: 1.000/0.101 / 1.000/0.129\n",
      "579: Training / validation acc/loss: 1.000/0.100 / 1.000/0.128\n",
      "580: Training / validation acc/loss: 1.000/0.099 / 1.000/0.127\n",
      "581: Training / validation acc/loss: 1.000/0.098 / 1.000/0.126\n",
      "582: Training / validation acc/loss: 1.000/0.097 / 1.000/0.126\n",
      "583: Training / validation acc/loss: 1.000/0.096 / 1.000/0.125\n",
      "584: Training / validation acc/loss: 1.000/0.096 / 1.000/0.124\n",
      "585: Training / validation acc/loss: 1.000/0.095 / 1.000/0.123\n",
      "586: Training / validation acc/loss: 1.000/0.094 / 1.000/0.122\n",
      "587: Training / validation acc/loss: 1.000/0.093 / 1.000/0.122\n",
      "588: Training / validation acc/loss: 1.000/0.092 / 1.000/0.121\n",
      "589: Training / validation acc/loss: 1.000/0.092 / 1.000/0.120\n",
      "590: Training / validation acc/loss: 1.000/0.091 / 1.000/0.119\n",
      "591: Training / validation acc/loss: 1.000/0.090 / 1.000/0.118\n",
      "592: Training / validation acc/loss: 1.000/0.089 / 1.000/0.118\n",
      "593: Training / validation acc/loss: 1.000/0.089 / 1.000/0.117\n",
      "594: Training / validation acc/loss: 1.000/0.088 / 1.000/0.116\n",
      "595: Training / validation acc/loss: 1.000/0.087 / 1.000/0.115\n",
      "596: Training / validation acc/loss: 1.000/0.087 / 1.000/0.114\n",
      "597: Training / validation acc/loss: 1.000/0.086 / 1.000/0.114\n",
      "598: Training / validation acc/loss: 1.000/0.085 / 1.000/0.113\n",
      "599: Training / validation acc/loss: 1.000/0.084 / 1.000/0.112\n",
      "600: Training / validation acc/loss: 1.000/0.084 / 1.000/0.112\n",
      "601: Training / validation acc/loss: 1.000/0.083 / 1.000/0.111\n",
      "602: Training / validation acc/loss: 1.000/0.083 / 1.000/0.110\n",
      "603: Training / validation acc/loss: 1.000/0.082 / 1.000/0.109\n",
      "604: Training / validation acc/loss: 1.000/0.081 / 1.000/0.109\n",
      "605: Training / validation acc/loss: 1.000/0.081 / 1.000/0.108\n",
      "606: Training / validation acc/loss: 1.000/0.080 / 1.000/0.107\n",
      "607: Training / validation acc/loss: 1.000/0.080 / 1.000/0.107\n",
      "608: Training / validation acc/loss: 1.000/0.079 / 1.000/0.106\n",
      "609: Training / validation acc/loss: 1.000/0.078 / 1.000/0.105\n",
      "610: Training / validation acc/loss: 1.000/0.078 / 1.000/0.105\n",
      "611: Training / validation acc/loss: 1.000/0.077 / 1.000/0.104\n",
      "612: Training / validation acc/loss: 1.000/0.077 / 1.000/0.103\n",
      "613: Training / validation acc/loss: 1.000/0.076 / 1.000/0.103\n",
      "614: Training / validation acc/loss: 1.000/0.076 / 1.000/0.102\n",
      "615: Training / validation acc/loss: 1.000/0.075 / 1.000/0.102\n",
      "616: Training / validation acc/loss: 1.000/0.075 / 1.000/0.101\n",
      "617: Training / validation acc/loss: 1.000/0.074 / 1.000/0.100\n",
      "618: Training / validation acc/loss: 1.000/0.074 / 1.000/0.100\n",
      "619: Training / validation acc/loss: 1.000/0.073 / 1.000/0.099\n",
      "620: Training / validation acc/loss: 1.000/0.073 / 1.000/0.099\n",
      "621: Training / validation acc/loss: 1.000/0.072 / 1.000/0.098\n",
      "622: Training / validation acc/loss: 1.000/0.072 / 1.000/0.097\n",
      "623: Training / validation acc/loss: 1.000/0.071 / 1.000/0.097\n",
      "624: Training / validation acc/loss: 1.000/0.071 / 1.000/0.096\n",
      "625: Training / validation acc/loss: 1.000/0.070 / 1.000/0.096\n",
      "626: Training / validation acc/loss: 1.000/0.070 / 1.000/0.095\n",
      "627: Training / validation acc/loss: 1.000/0.069 / 1.000/0.095\n",
      "628: Training / validation acc/loss: 1.000/0.069 / 1.000/0.094\n",
      "629: Training / validation acc/loss: 1.000/0.068 / 1.000/0.094\n",
      "630: Training / validation acc/loss: 1.000/0.068 / 1.000/0.093\n",
      "631: Training / validation acc/loss: 1.000/0.067 / 1.000/0.093\n",
      "632: Training / validation acc/loss: 1.000/0.067 / 1.000/0.092\n",
      "633: Training / validation acc/loss: 1.000/0.067 / 1.000/0.092\n",
      "634: Training / validation acc/loss: 1.000/0.066 / 1.000/0.091\n",
      "635: Training / validation acc/loss: 1.000/0.066 / 1.000/0.091\n",
      "636: Training / validation acc/loss: 1.000/0.065 / 1.000/0.090\n",
      "637: Training / validation acc/loss: 1.000/0.065 / 1.000/0.090\n",
      "638: Training / validation acc/loss: 1.000/0.065 / 1.000/0.089\n",
      "639: Training / validation acc/loss: 1.000/0.064 / 1.000/0.089\n",
      "640: Training / validation acc/loss: 1.000/0.064 / 1.000/0.088\n",
      "641: Training / validation acc/loss: 1.000/0.063 / 1.000/0.088\n",
      "642: Training / validation acc/loss: 1.000/0.063 / 1.000/0.087\n",
      "643: Training / validation acc/loss: 1.000/0.063 / 1.000/0.087\n",
      "644: Training / validation acc/loss: 1.000/0.062 / 1.000/0.087\n",
      "645: Training / validation acc/loss: 1.000/0.062 / 1.000/0.086\n",
      "646: Training / validation acc/loss: 1.000/0.062 / 1.000/0.086\n",
      "647: Training / validation acc/loss: 1.000/0.061 / 1.000/0.085\n",
      "648: Training / validation acc/loss: 1.000/0.061 / 1.000/0.085\n",
      "649: Training / validation acc/loss: 1.000/0.060 / 1.000/0.084\n",
      "650: Training / validation acc/loss: 1.000/0.060 / 1.000/0.084\n",
      "651: Training / validation acc/loss: 1.000/0.060 / 1.000/0.083\n",
      "652: Training / validation acc/loss: 1.000/0.059 / 1.000/0.083\n",
      "653: Training / validation acc/loss: 1.000/0.059 / 1.000/0.083\n",
      "654: Training / validation acc/loss: 1.000/0.059 / 1.000/0.082\n",
      "655: Training / validation acc/loss: 1.000/0.058 / 1.000/0.082\n",
      "656: Training / validation acc/loss: 1.000/0.058 / 1.000/0.081\n",
      "657: Training / validation acc/loss: 1.000/0.058 / 1.000/0.081\n",
      "658: Training / validation acc/loss: 1.000/0.057 / 1.000/0.081\n",
      "659: Training / validation acc/loss: 1.000/0.057 / 1.000/0.080\n",
      "660: Training / validation acc/loss: 1.000/0.057 / 1.000/0.080\n",
      "661: Training / validation acc/loss: 1.000/0.056 / 1.000/0.079\n",
      "662: Training / validation acc/loss: 1.000/0.056 / 1.000/0.079\n",
      "663: Training / validation acc/loss: 1.000/0.056 / 1.000/0.079\n",
      "664: Training / validation acc/loss: 1.000/0.056 / 1.000/0.078\n",
      "665: Training / validation acc/loss: 1.000/0.055 / 1.000/0.078\n",
      "666: Training / validation acc/loss: 1.000/0.055 / 1.000/0.077\n",
      "667: Training / validation acc/loss: 1.000/0.055 / 1.000/0.077\n",
      "668: Training / validation acc/loss: 1.000/0.054 / 1.000/0.077\n",
      "669: Training / validation acc/loss: 1.000/0.054 / 1.000/0.076\n",
      "670: Training / validation acc/loss: 1.000/0.054 / 1.000/0.076\n",
      "671: Training / validation acc/loss: 1.000/0.053 / 1.000/0.076\n",
      "672: Training / validation acc/loss: 1.000/0.053 / 1.000/0.075\n",
      "673: Training / validation acc/loss: 1.000/0.053 / 1.000/0.075\n",
      "674: Training / validation acc/loss: 1.000/0.053 / 1.000/0.075\n",
      "675: Training / validation acc/loss: 1.000/0.052 / 1.000/0.074\n",
      "676: Training / validation acc/loss: 1.000/0.052 / 1.000/0.074\n",
      "677: Training / validation acc/loss: 1.000/0.052 / 1.000/0.074\n",
      "678: Training / validation acc/loss: 1.000/0.052 / 1.000/0.073\n",
      "679: Training / validation acc/loss: 1.000/0.051 / 1.000/0.073\n",
      "680: Training / validation acc/loss: 1.000/0.051 / 1.000/0.073\n",
      "681: Training / validation acc/loss: 1.000/0.051 / 1.000/0.072\n",
      "682: Training / validation acc/loss: 1.000/0.051 / 1.000/0.072\n",
      "683: Training / validation acc/loss: 1.000/0.050 / 1.000/0.072\n",
      "684: Training / validation acc/loss: 1.000/0.050 / 1.000/0.071\n",
      "685: Training / validation acc/loss: 1.000/0.050 / 1.000/0.071\n",
      "686: Training / validation acc/loss: 1.000/0.050 / 1.000/0.071\n",
      "687: Training / validation acc/loss: 1.000/0.049 / 1.000/0.070\n",
      "688: Training / validation acc/loss: 1.000/0.049 / 1.000/0.070\n",
      "689: Training / validation acc/loss: 1.000/0.049 / 1.000/0.070\n",
      "690: Training / validation acc/loss: 1.000/0.049 / 1.000/0.070\n",
      "691: Training / validation acc/loss: 1.000/0.048 / 1.000/0.069\n",
      "692: Training / validation acc/loss: 1.000/0.048 / 1.000/0.069\n",
      "693: Training / validation acc/loss: 1.000/0.048 / 1.000/0.069\n",
      "694: Training / validation acc/loss: 1.000/0.048 / 1.000/0.068\n",
      "695: Training / validation acc/loss: 1.000/0.047 / 1.000/0.068\n",
      "696: Training / validation acc/loss: 1.000/0.047 / 1.000/0.068\n",
      "697: Training / validation acc/loss: 1.000/0.047 / 1.000/0.068\n",
      "698: Training / validation acc/loss: 1.000/0.047 / 1.000/0.067\n",
      "699: Training / validation acc/loss: 1.000/0.046 / 1.000/0.067\n",
      "700: Training / validation acc/loss: 1.000/0.046 / 1.000/0.067\n",
      "701: Training / validation acc/loss: 1.000/0.046 / 1.000/0.066\n",
      "702: Training / validation acc/loss: 1.000/0.046 / 1.000/0.066\n",
      "703: Training / validation acc/loss: 1.000/0.046 / 1.000/0.066\n",
      "704: Training / validation acc/loss: 1.000/0.045 / 1.000/0.066\n",
      "705: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "706: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "707: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "708: Training / validation acc/loss: 1.000/0.045 / 1.000/0.065\n",
      "709: Training / validation acc/loss: 1.000/0.044 / 1.000/0.064\n",
      "710: Training / validation acc/loss: 1.000/0.044 / 1.000/0.064\n",
      "711: Training / validation acc/loss: 1.000/0.044 / 1.000/0.064\n",
      "712: Training / validation acc/loss: 1.000/0.044 / 1.000/0.064\n",
      "713: Training / validation acc/loss: 1.000/0.044 / 1.000/0.063\n",
      "714: Training / validation acc/loss: 1.000/0.043 / 1.000/0.063\n",
      "715: Training / validation acc/loss: 1.000/0.043 / 1.000/0.063\n",
      "716: Training / validation acc/loss: 1.000/0.043 / 1.000/0.063\n",
      "717: Training / validation acc/loss: 1.000/0.043 / 1.000/0.063\n",
      "718: Training / validation acc/loss: 1.000/0.043 / 1.000/0.062\n",
      "719: Training / validation acc/loss: 1.000/0.042 / 1.000/0.062\n",
      "720: Training / validation acc/loss: 1.000/0.042 / 1.000/0.062\n",
      "721: Training / validation acc/loss: 1.000/0.042 / 1.000/0.062\n",
      "722: Training / validation acc/loss: 1.000/0.042 / 1.000/0.061\n",
      "723: Training / validation acc/loss: 1.000/0.042 / 1.000/0.061\n",
      "724: Training / validation acc/loss: 1.000/0.042 / 1.000/0.061\n",
      "725: Training / validation acc/loss: 1.000/0.041 / 1.000/0.061\n",
      "726: Training / validation acc/loss: 1.000/0.041 / 1.000/0.061\n",
      "727: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "728: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "729: Training / validation acc/loss: 1.000/0.041 / 1.000/0.060\n",
      "730: Training / validation acc/loss: 1.000/0.040 / 1.000/0.060\n",
      "731: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "732: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "733: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "734: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "735: Training / validation acc/loss: 1.000/0.040 / 1.000/0.059\n",
      "736: Training / validation acc/loss: 1.000/0.040 / 1.000/0.058\n",
      "737: Training / validation acc/loss: 1.000/0.039 / 1.000/0.058\n",
      "738: Training / validation acc/loss: 1.000/0.039 / 1.000/0.058\n",
      "739: Training / validation acc/loss: 1.000/0.039 / 1.000/0.058\n",
      "740: Training / validation acc/loss: 1.000/0.039 / 1.000/0.058\n",
      "741: Training / validation acc/loss: 1.000/0.039 / 1.000/0.057\n",
      "742: Training / validation acc/loss: 1.000/0.039 / 1.000/0.057\n",
      "743: Training / validation acc/loss: 1.000/0.038 / 1.000/0.057\n",
      "744: Training / validation acc/loss: 1.000/0.038 / 1.000/0.057\n",
      "745: Training / validation acc/loss: 1.000/0.038 / 1.000/0.057\n",
      "746: Training / validation acc/loss: 1.000/0.038 / 1.000/0.057\n",
      "747: Training / validation acc/loss: 1.000/0.038 / 1.000/0.056\n",
      "748: Training / validation acc/loss: 1.000/0.038 / 1.000/0.056\n",
      "749: Training / validation acc/loss: 1.000/0.037 / 1.000/0.056\n",
      "750: Training / validation acc/loss: 1.000/0.037 / 1.000/0.056\n",
      "751: Training / validation acc/loss: 1.000/0.037 / 1.000/0.056\n",
      "752: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "753: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "754: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "755: Training / validation acc/loss: 1.000/0.037 / 1.000/0.055\n",
      "756: Training / validation acc/loss: 1.000/0.036 / 1.000/0.055\n",
      "757: Training / validation acc/loss: 1.000/0.036 / 1.000/0.055\n",
      "758: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "759: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "760: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "761: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "762: Training / validation acc/loss: 1.000/0.036 / 1.000/0.054\n",
      "763: Training / validation acc/loss: 1.000/0.036 / 1.000/0.053\n",
      "764: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "765: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "766: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "767: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "768: Training / validation acc/loss: 1.000/0.035 / 1.000/0.053\n",
      "769: Training / validation acc/loss: 1.000/0.035 / 1.000/0.052\n",
      "770: Training / validation acc/loss: 1.000/0.035 / 1.000/0.052\n",
      "771: Training / validation acc/loss: 1.000/0.034 / 1.000/0.052\n",
      "772: Training / validation acc/loss: 1.000/0.034 / 1.000/0.052\n",
      "773: Training / validation acc/loss: 1.000/0.034 / 1.000/0.052\n",
      "774: Training / validation acc/loss: 1.000/0.034 / 1.000/0.052\n",
      "775: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "776: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "777: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "778: Training / validation acc/loss: 1.000/0.034 / 1.000/0.051\n",
      "779: Training / validation acc/loss: 1.000/0.033 / 1.000/0.051\n",
      "780: Training / validation acc/loss: 1.000/0.033 / 1.000/0.051\n",
      "781: Training / validation acc/loss: 1.000/0.033 / 1.000/0.051\n",
      "782: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "783: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "784: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "785: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "786: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "787: Training / validation acc/loss: 1.000/0.033 / 1.000/0.050\n",
      "788: Training / validation acc/loss: 1.000/0.032 / 1.000/0.050\n",
      "789: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "790: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "791: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "792: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "793: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "794: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "795: Training / validation acc/loss: 1.000/0.032 / 1.000/0.049\n",
      "796: Training / validation acc/loss: 1.000/0.032 / 1.000/0.048\n",
      "797: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "798: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "799: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "800: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "801: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "802: Training / validation acc/loss: 1.000/0.031 / 1.000/0.048\n",
      "803: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "804: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "805: Training / validation acc/loss: 1.000/0.031 / 1.000/0.047\n",
      "806: Training / validation acc/loss: 1.000/0.030 / 1.000/0.047\n",
      "807: Training / validation acc/loss: 1.000/0.030 / 1.000/0.047\n",
      "808: Training / validation acc/loss: 1.000/0.030 / 1.000/0.047\n",
      "809: Training / validation acc/loss: 1.000/0.030 / 1.000/0.047\n",
      "810: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "811: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "812: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "813: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "814: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "815: Training / validation acc/loss: 1.000/0.030 / 1.000/0.046\n",
      "816: Training / validation acc/loss: 1.000/0.029 / 1.000/0.046\n",
      "817: Training / validation acc/loss: 1.000/0.029 / 1.000/0.046\n",
      "818: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "819: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "820: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "821: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "822: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "823: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "824: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "825: Training / validation acc/loss: 1.000/0.029 / 1.000/0.045\n",
      "826: Training / validation acc/loss: 1.000/0.029 / 1.000/0.044\n",
      "827: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "828: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "829: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "830: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "831: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "832: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "833: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "834: Training / validation acc/loss: 1.000/0.028 / 1.000/0.044\n",
      "835: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "836: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "837: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "838: Training / validation acc/loss: 1.000/0.028 / 1.000/0.043\n",
      "839: Training / validation acc/loss: 1.000/0.027 / 1.000/0.043\n",
      "840: Training / validation acc/loss: 1.000/0.027 / 1.000/0.043\n",
      "841: Training / validation acc/loss: 1.000/0.027 / 1.000/0.043\n",
      "842: Training / validation acc/loss: 1.000/0.027 / 1.000/0.043\n",
      "843: Training / validation acc/loss: 1.000/0.027 / 1.000/0.043\n",
      "844: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "845: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "846: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "847: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "848: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "849: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "850: Training / validation acc/loss: 1.000/0.027 / 1.000/0.042\n",
      "851: Training / validation acc/loss: 1.000/0.026 / 1.000/0.042\n",
      "852: Training / validation acc/loss: 1.000/0.026 / 1.000/0.042\n",
      "853: Training / validation acc/loss: 1.000/0.026 / 1.000/0.042\n",
      "854: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "855: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "856: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "857: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "858: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "859: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "860: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "861: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "862: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "863: Training / validation acc/loss: 1.000/0.026 / 1.000/0.041\n",
      "864: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "865: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "866: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "867: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "868: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "869: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "870: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "871: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "872: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "873: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "874: Training / validation acc/loss: 1.000/0.025 / 1.000/0.040\n",
      "875: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "876: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "877: Training / validation acc/loss: 1.000/0.025 / 1.000/0.039\n",
      "878: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "879: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "880: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "881: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "882: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "883: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "884: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "885: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "886: Training / validation acc/loss: 1.000/0.024 / 1.000/0.039\n",
      "887: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "888: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "889: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "890: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "891: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "892: Training / validation acc/loss: 1.000/0.024 / 1.000/0.038\n",
      "893: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "894: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "895: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "896: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "897: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "898: Training / validation acc/loss: 1.000/0.023 / 1.000/0.038\n",
      "899: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "900: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "901: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "902: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "903: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "904: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "905: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "906: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "907: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "908: Training / validation acc/loss: 1.000/0.023 / 1.000/0.037\n",
      "909: Training / validation acc/loss: 1.000/0.022 / 1.000/0.037\n",
      "910: Training / validation acc/loss: 1.000/0.022 / 1.000/0.037\n",
      "911: Training / validation acc/loss: 1.000/0.022 / 1.000/0.037\n",
      "912: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "913: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "914: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "915: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "916: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "917: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "918: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "919: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "920: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "921: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "922: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "923: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "924: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "925: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "926: Training / validation acc/loss: 1.000/0.022 / 1.000/0.036\n",
      "927: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "928: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "929: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "930: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "931: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "932: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "933: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "934: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "935: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "936: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "937: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "938: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "939: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "940: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "941: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "942: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "943: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "944: Training / validation acc/loss: 1.000/0.021 / 1.000/0.035\n",
      "945: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "946: Training / validation acc/loss: 1.000/0.021 / 1.000/0.034\n",
      "947: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "948: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "949: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "950: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "951: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "952: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "953: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "954: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "955: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "956: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "957: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "958: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "959: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "960: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "961: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "962: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "963: Training / validation acc/loss: 1.000/0.020 / 1.000/0.034\n",
      "964: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "965: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "966: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "967: Training / validation acc/loss: 1.000/0.020 / 1.000/0.033\n",
      "968: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "969: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "970: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "971: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "972: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "973: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "974: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "975: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "976: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "977: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "978: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "979: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "980: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "981: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "982: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "983: Training / validation acc/loss: 1.000/0.019 / 1.000/0.033\n",
      "984: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "985: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "986: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "987: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "988: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "989: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "990: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "991: Training / validation acc/loss: 1.000/0.019 / 1.000/0.032\n",
      "992: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "993: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "994: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "995: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "996: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "997: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "998: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n",
      "999: Training / validation acc/loss: 1.000/0.018 / 1.000/0.032\n"
     ]
    }
   ],
   "source": [
    "sigma = 0.05\n",
    "net2 = Shallow(sigma).to(dev)\n",
    "train(net2, train_loader, val_loader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2e867-793a-4362-9397-580f63296a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d94c6af-71c7-4422-be3b-553a4f14378d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:38:13.920099Z",
     "iopub.status.busy": "2023-04-19T18:38:13.919246Z",
     "iopub.status.idle": "2023-04-19T18:38:14.060187Z",
     "shell.execute_reply": "2023-04-19T18:38:14.059412Z",
     "shell.execute_reply.started": "2023-04-19T18:38:13.919990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(train_data[0], train_data[1], net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cb9ea7-2ed6-4c1f-81ba-9e66efeb4e6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:39:00.396294Z",
     "iopub.status.busy": "2023-04-19T18:39:00.395518Z",
     "iopub.status.idle": "2023-04-19T18:39:00.401366Z",
     "shell.execute_reply": "2023-04-19T18:39:00.400467Z",
     "shell.execute_reply.started": "2023-04-19T18:39:00.396264Z"
    }
   },
   "source": [
    "Weights converge, but much later, after ~500 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554c490-beb5-4444-9c10-5e4b3cf8f1c2",
   "metadata": {},
   "source": [
    "Big sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c200ddf-cd81-4c66-b928-bc1a0f5f4672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:41:02.633373Z",
     "iopub.status.busy": "2023-04-19T18:41:02.632537Z",
     "iopub.status.idle": "2023-04-19T18:41:04.827767Z",
     "shell.execute_reply": "2023-04-19T18:41:04.826609Z",
     "shell.execute_reply.started": "2023-04-19T18:41:02.633342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.510/12001.704 / 0.500/12718.478\n",
      "1: Training / validation acc/loss: 0.500/8478.695 / 0.500/79.916\n",
      "2: Training / validation acc/loss: 0.500/54.040 / 0.510/0.686\n",
      "3: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "4: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "5: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "6: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "7: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "8: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "9: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "10: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "11: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "12: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "13: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "14: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "15: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "16: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "17: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "18: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "19: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "20: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "21: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "22: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "23: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "24: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "25: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "26: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "27: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "28: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "29: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "30: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "31: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "32: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "33: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "34: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "35: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "36: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "37: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "38: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "39: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "40: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "41: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "42: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "43: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "44: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "45: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "46: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "47: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "48: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "49: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "50: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "51: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "52: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "53: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "54: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "55: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "56: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "57: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "58: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "59: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "60: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "61: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "62: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "63: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "64: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "65: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "66: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "67: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "68: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "69: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "70: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "71: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "72: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "73: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "74: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "75: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "76: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "77: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "78: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "79: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "80: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "81: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "82: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "83: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "84: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "85: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "86: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "87: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "88: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "89: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "90: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "91: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "92: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "93: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "94: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "95: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "96: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "97: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "98: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "99: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "100: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "101: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "102: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "103: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "104: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "105: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "106: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "107: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "108: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "109: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "110: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "111: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "112: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "113: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "114: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "115: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "116: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "117: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "118: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "119: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "120: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "121: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "122: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "123: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "124: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "125: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "126: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "127: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "128: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "129: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "130: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "131: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "132: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "133: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "134: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "135: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "136: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "137: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "138: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "139: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "140: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "141: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "142: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "143: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "144: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "145: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "146: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "147: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "148: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "149: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "150: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "151: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "152: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "153: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "154: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "155: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "156: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "157: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "158: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "159: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "160: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "161: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "162: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "163: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "164: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "165: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "166: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "167: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "168: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "169: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "170: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "171: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "172: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "173: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "174: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "175: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "176: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "177: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "178: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "179: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "180: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "181: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "182: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "183: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "184: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "185: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "186: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "187: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "188: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "189: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "190: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "191: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "192: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "193: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "194: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "195: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "196: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "197: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "198: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "199: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "200: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "201: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "202: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "203: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "204: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "205: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "206: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "207: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "208: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "209: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "210: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "211: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "212: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "213: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "214: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "215: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "216: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "217: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "218: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "219: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "220: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "221: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "222: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "223: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "224: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "225: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "226: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "227: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "228: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "229: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "230: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "231: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "232: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "233: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "234: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "235: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "236: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "237: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "238: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "239: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "240: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "241: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "242: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "243: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "244: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "245: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "246: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "247: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "248: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "249: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "250: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "251: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "252: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "253: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "254: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "255: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "256: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "257: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "258: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "259: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "260: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "261: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "262: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "263: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "264: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "265: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "266: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "267: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "268: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "269: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "270: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "271: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "272: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "273: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "274: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "275: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "276: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "277: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "278: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "279: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "280: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "281: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "282: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "283: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "284: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "285: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "286: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "287: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "288: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "289: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "290: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "291: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "292: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "293: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "294: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "295: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "296: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "297: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "298: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "299: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "300: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "301: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "302: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "303: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "304: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "305: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "306: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "307: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "308: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "309: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "310: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "311: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "312: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "313: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "314: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "315: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "316: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "317: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "318: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "319: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "320: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "321: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "322: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "323: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "324: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "325: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "326: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "327: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "328: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "329: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "330: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "331: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "332: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "333: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "334: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "335: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "336: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "337: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "338: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "339: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "340: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "341: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "342: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "343: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "344: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "345: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "346: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "347: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "348: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "349: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "350: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "351: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "352: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "353: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "354: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "355: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "356: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "357: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "358: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "359: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "360: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "361: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "362: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "363: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "364: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "365: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "366: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "367: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "368: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "369: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "370: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "371: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "372: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "373: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "374: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "375: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "376: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "377: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "378: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "379: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "380: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "381: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "382: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "383: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "384: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "385: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "386: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "387: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "388: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "389: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "390: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "391: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "392: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "393: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "394: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "395: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "396: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "397: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "398: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "399: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "400: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "401: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "402: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "403: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "404: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "405: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "406: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "407: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "408: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "409: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "410: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "411: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "412: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "413: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "414: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "415: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "416: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "417: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "418: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "419: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "420: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "421: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "422: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "423: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "424: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "425: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "426: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "427: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "428: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "429: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "430: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "431: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "432: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "433: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "434: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "435: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "436: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "437: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "438: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "439: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "440: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "441: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "442: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "443: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "444: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "445: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "446: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "447: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "448: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "449: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "450: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "451: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "452: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "453: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "454: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "455: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "456: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "457: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "458: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "459: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "460: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "461: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "462: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "463: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "464: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "465: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "466: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "467: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "468: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "469: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "470: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "471: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "472: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "473: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "474: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "475: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "476: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "477: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "478: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "479: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "480: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "481: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "482: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "483: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "484: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "485: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "486: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "487: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "488: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "489: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "490: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "491: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "492: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "493: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "494: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "495: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "496: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "497: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "498: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "499: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "500: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "501: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "502: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "503: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "504: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "505: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "506: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "507: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "508: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "509: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "510: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "511: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "512: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "513: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "514: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "515: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "516: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "517: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "518: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "519: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "520: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "521: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "522: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "523: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "524: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "525: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "526: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "527: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "528: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "529: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "530: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "531: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "532: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "533: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "534: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "535: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "536: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "537: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "538: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "539: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "540: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "541: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "542: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "543: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "544: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "545: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "546: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "547: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "548: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "549: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "550: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "551: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "552: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "553: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "554: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "555: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "556: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "557: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "558: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "559: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "560: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "561: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "562: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "563: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "564: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "565: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "566: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "567: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "568: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "569: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "570: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "571: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "572: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "573: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "574: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "575: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "576: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "577: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "578: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "579: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "580: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "581: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "582: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "583: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "584: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "585: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "586: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "587: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "588: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "589: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "590: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "591: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "592: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "593: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "594: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "595: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "596: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "597: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "598: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "599: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "600: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "601: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "602: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "603: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "604: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "605: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "606: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "607: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "608: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "609: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "610: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "611: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "612: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "613: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "614: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "615: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "616: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "617: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "618: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "619: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "620: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "621: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "622: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "623: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "624: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "625: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "626: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "627: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "628: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "629: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "630: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "631: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "632: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "633: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "634: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "635: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "636: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "637: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "638: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "639: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "640: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "641: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "642: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "643: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "644: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "645: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "646: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "647: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "648: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "649: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "650: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "651: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "652: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "653: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "654: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "655: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "656: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "657: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "658: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "659: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "660: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "661: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "662: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "663: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "664: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "665: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "666: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "667: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "668: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "669: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "670: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "671: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "672: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "673: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "674: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "675: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "676: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "677: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "678: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "679: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "680: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "681: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "682: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "683: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "684: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "685: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "686: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "687: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "688: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "689: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "690: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "691: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "692: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "693: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "694: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "695: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "696: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "697: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "698: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "699: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "700: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "701: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "702: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "703: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "704: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "705: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "706: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "707: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "708: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "709: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "710: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "711: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "712: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "713: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "714: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "715: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "716: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "717: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "718: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "719: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "720: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "721: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "722: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "723: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "724: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "725: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "726: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "727: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "728: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "729: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "730: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "731: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "732: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "733: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "734: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "735: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "736: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "737: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "738: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "739: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "740: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "741: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "742: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "743: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "744: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "745: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "746: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "747: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "748: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "749: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "750: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "751: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "752: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "753: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "754: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "755: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "756: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "757: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "758: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "759: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "760: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "761: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "762: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "763: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "764: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "765: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "766: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "767: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "768: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "769: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "770: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "771: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "772: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "773: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "774: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "775: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "776: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "777: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "778: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "779: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "780: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "781: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "782: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "783: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "784: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "785: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "786: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "787: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "788: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "789: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "790: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "791: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "792: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "793: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "794: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "795: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "796: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "797: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "798: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "799: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "800: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "801: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "802: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "803: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "804: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "805: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "806: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "807: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "808: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "809: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "810: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "811: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "812: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "813: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "814: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "815: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "816: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "817: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "818: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "819: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "820: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "821: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "822: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "823: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "824: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "825: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "826: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "827: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "828: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "829: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "830: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "831: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "832: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "833: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "834: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "835: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "836: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "837: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "838: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "839: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "840: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "841: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "842: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "843: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "844: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "845: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "846: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "847: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "848: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "849: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "850: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "851: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "852: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "853: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "854: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "855: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "856: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "857: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "858: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "859: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "860: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "861: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "862: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "863: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "864: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "865: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "866: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "867: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "868: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "869: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "870: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "871: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "872: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "873: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "874: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "875: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "876: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "877: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "878: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "879: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "880: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "881: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "882: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "883: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "884: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "885: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "886: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "887: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "888: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "889: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "890: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "891: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "892: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "893: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "894: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "895: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "896: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "897: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "898: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "899: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "900: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "901: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "902: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "903: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "904: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "905: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "906: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "907: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "908: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "909: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "910: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "911: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "912: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "913: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "914: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "915: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "916: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "917: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "918: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "919: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "920: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "921: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "922: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "923: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "924: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "925: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "926: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "927: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "928: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "929: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "930: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "931: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "932: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "933: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "934: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "935: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "936: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "937: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "938: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "939: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "940: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "941: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "942: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "943: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "944: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "945: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "946: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "947: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "948: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "949: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "950: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "951: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "952: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "953: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "954: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "955: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "956: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "957: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "958: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "959: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "960: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "961: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "962: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "963: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "964: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "965: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "966: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "967: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "968: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "969: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "970: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "971: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "972: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "973: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "974: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "975: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "976: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "977: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "978: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "979: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "980: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "981: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "982: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "983: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "984: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "985: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "986: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "987: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "988: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "989: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "990: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "991: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "992: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "993: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "994: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "995: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "996: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "997: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "998: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n",
      "999: Training / validation acc/loss: 0.520/0.679 / 0.510/0.686\n"
     ]
    }
   ],
   "source": [
    "sigma = 20\n",
    "net3 = Shallow(sigma).to(dev)\n",
    "train(net3, train_loader, val_loader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1eecd8f8-be84-4643-b067-13fb976d6f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:41:10.602258Z",
     "iopub.status.busy": "2023-04-19T18:41:10.600855Z",
     "iopub.status.idle": "2023-04-19T18:41:10.731263Z",
     "shell.execute_reply": "2023-04-19T18:41:10.730317Z",
     "shell.execute_reply.started": "2023-04-19T18:41:10.602191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(train_data[0], train_data[1], net3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee972ea-2c2e-4d35-8e39-dc47e8269f9c",
   "metadata": {},
   "source": [
    "Sigma is too big, the sequence diverge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d29a06-650b-4f9b-be5c-2b877949625a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:42:20.505726Z",
     "iopub.status.busy": "2023-04-19T18:42:20.505121Z",
     "iopub.status.idle": "2023-04-19T18:42:20.511221Z",
     "shell.execute_reply": "2023-04-19T18:42:20.510252Z",
     "shell.execute_reply.started": "2023-04-19T18:42:20.505726Z"
    }
   },
   "source": [
    "Glorot initiazliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1fedbaf3-3d00-4bfd-afa9-2d64ff9850bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:54:15.544233Z",
     "iopub.status.busy": "2023-04-19T18:54:15.543595Z",
     "iopub.status.idle": "2023-04-19T18:54:17.876324Z",
     "shell.execute_reply": "2023-04-19T18:54:17.875601Z",
     "shell.execute_reply.started": "2023-04-19T18:54:15.544205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.500/0.558 / 0.510/0.590\n",
      "1: Training / validation acc/loss: 0.540/0.541 / 0.550/0.574\n",
      "2: Training / validation acc/loss: 0.570/0.528 / 0.590/0.560\n",
      "3: Training / validation acc/loss: 0.620/0.516 / 0.600/0.548\n",
      "4: Training / validation acc/loss: 0.650/0.505 / 0.610/0.537\n",
      "5: Training / validation acc/loss: 0.690/0.496 / 0.630/0.527\n",
      "6: Training / validation acc/loss: 0.700/0.487 / 0.640/0.518\n",
      "7: Training / validation acc/loss: 0.710/0.478 / 0.670/0.510\n",
      "8: Training / validation acc/loss: 0.720/0.470 / 0.700/0.502\n",
      "9: Training / validation acc/loss: 0.730/0.463 / 0.730/0.494\n",
      "10: Training / validation acc/loss: 0.730/0.455 / 0.740/0.487\n",
      "11: Training / validation acc/loss: 0.730/0.448 / 0.750/0.480\n",
      "12: Training / validation acc/loss: 0.750/0.441 / 0.750/0.474\n",
      "13: Training / validation acc/loss: 0.760/0.435 / 0.750/0.467\n",
      "14: Training / validation acc/loss: 0.790/0.428 / 0.770/0.460\n",
      "15: Training / validation acc/loss: 0.830/0.421 / 0.770/0.454\n",
      "16: Training / validation acc/loss: 0.840/0.415 / 0.780/0.448\n",
      "17: Training / validation acc/loss: 0.850/0.408 / 0.780/0.441\n",
      "18: Training / validation acc/loss: 0.860/0.402 / 0.790/0.435\n",
      "19: Training / validation acc/loss: 0.860/0.396 / 0.800/0.430\n",
      "20: Training / validation acc/loss: 0.860/0.390 / 0.800/0.424\n",
      "21: Training / validation acc/loss: 0.870/0.384 / 0.800/0.418\n",
      "22: Training / validation acc/loss: 0.870/0.378 / 0.800/0.412\n",
      "23: Training / validation acc/loss: 0.870/0.372 / 0.800/0.407\n",
      "24: Training / validation acc/loss: 0.870/0.366 / 0.800/0.401\n",
      "25: Training / validation acc/loss: 0.910/0.360 / 0.810/0.396\n",
      "26: Training / validation acc/loss: 0.910/0.355 / 0.810/0.390\n",
      "27: Training / validation acc/loss: 0.910/0.349 / 0.810/0.385\n",
      "28: Training / validation acc/loss: 0.910/0.344 / 0.850/0.380\n",
      "29: Training / validation acc/loss: 0.910/0.339 / 0.850/0.375\n",
      "30: Training / validation acc/loss: 0.920/0.334 / 0.850/0.370\n",
      "31: Training / validation acc/loss: 0.920/0.329 / 0.850/0.365\n",
      "32: Training / validation acc/loss: 0.930/0.324 / 0.860/0.360\n",
      "33: Training / validation acc/loss: 0.940/0.319 / 0.860/0.355\n",
      "34: Training / validation acc/loss: 0.940/0.314 / 0.860/0.351\n",
      "35: Training / validation acc/loss: 0.940/0.309 / 0.870/0.346\n",
      "36: Training / validation acc/loss: 0.950/0.305 / 0.870/0.342\n",
      "37: Training / validation acc/loss: 0.960/0.300 / 0.880/0.337\n",
      "38: Training / validation acc/loss: 0.970/0.296 / 0.880/0.333\n",
      "39: Training / validation acc/loss: 0.970/0.292 / 0.880/0.329\n",
      "40: Training / validation acc/loss: 0.970/0.287 / 0.880/0.325\n",
      "41: Training / validation acc/loss: 0.970/0.283 / 0.890/0.320\n",
      "42: Training / validation acc/loss: 0.970/0.279 / 0.890/0.316\n",
      "43: Training / validation acc/loss: 0.970/0.275 / 0.890/0.312\n",
      "44: Training / validation acc/loss: 0.990/0.271 / 0.890/0.309\n",
      "45: Training / validation acc/loss: 0.990/0.267 / 0.890/0.305\n",
      "46: Training / validation acc/loss: 0.990/0.264 / 0.890/0.301\n",
      "47: Training / validation acc/loss: 0.990/0.260 / 0.890/0.297\n",
      "48: Training / validation acc/loss: 0.990/0.256 / 0.890/0.294\n",
      "49: Training / validation acc/loss: 0.990/0.253 / 0.890/0.290\n",
      "50: Training / validation acc/loss: 0.990/0.249 / 0.890/0.287\n",
      "51: Training / validation acc/loss: 0.990/0.246 / 0.890/0.283\n",
      "52: Training / validation acc/loss: 0.990/0.243 / 0.890/0.280\n",
      "53: Training / validation acc/loss: 0.990/0.239 / 0.900/0.277\n",
      "54: Training / validation acc/loss: 0.990/0.236 / 0.900/0.273\n",
      "55: Training / validation acc/loss: 0.990/0.233 / 0.910/0.270\n",
      "56: Training / validation acc/loss: 0.990/0.230 / 0.920/0.267\n",
      "57: Training / validation acc/loss: 0.990/0.227 / 0.920/0.264\n",
      "58: Training / validation acc/loss: 0.990/0.224 / 0.920/0.261\n",
      "59: Training / validation acc/loss: 0.990/0.221 / 0.920/0.258\n",
      "60: Training / validation acc/loss: 1.000/0.218 / 0.930/0.255\n",
      "61: Training / validation acc/loss: 1.000/0.215 / 0.940/0.252\n",
      "62: Training / validation acc/loss: 1.000/0.212 / 0.940/0.249\n",
      "63: Training / validation acc/loss: 1.000/0.210 / 0.940/0.246\n",
      "64: Training / validation acc/loss: 1.000/0.207 / 0.940/0.244\n",
      "65: Training / validation acc/loss: 1.000/0.204 / 0.940/0.241\n",
      "66: Training / validation acc/loss: 1.000/0.202 / 0.940/0.238\n",
      "67: Training / validation acc/loss: 1.000/0.199 / 0.940/0.236\n",
      "68: Training / validation acc/loss: 1.000/0.197 / 0.940/0.233\n",
      "69: Training / validation acc/loss: 1.000/0.194 / 0.950/0.230\n",
      "70: Training / validation acc/loss: 1.000/0.192 / 0.950/0.228\n",
      "71: Training / validation acc/loss: 1.000/0.189 / 0.950/0.226\n",
      "72: Training / validation acc/loss: 1.000/0.187 / 0.950/0.223\n",
      "73: Training / validation acc/loss: 1.000/0.185 / 0.960/0.221\n",
      "74: Training / validation acc/loss: 1.000/0.183 / 0.960/0.218\n",
      "75: Training / validation acc/loss: 1.000/0.180 / 0.960/0.216\n",
      "76: Training / validation acc/loss: 1.000/0.178 / 0.970/0.214\n",
      "77: Training / validation acc/loss: 1.000/0.176 / 0.970/0.212\n",
      "78: Training / validation acc/loss: 1.000/0.174 / 0.980/0.210\n",
      "79: Training / validation acc/loss: 1.000/0.172 / 0.980/0.207\n",
      "80: Training / validation acc/loss: 1.000/0.170 / 0.980/0.205\n",
      "81: Training / validation acc/loss: 1.000/0.168 / 0.980/0.203\n",
      "82: Training / validation acc/loss: 1.000/0.166 / 0.980/0.201\n",
      "83: Training / validation acc/loss: 1.000/0.164 / 0.980/0.199\n",
      "84: Training / validation acc/loss: 1.000/0.162 / 0.980/0.198\n",
      "85: Training / validation acc/loss: 1.000/0.160 / 0.980/0.196\n",
      "86: Training / validation acc/loss: 1.000/0.159 / 0.980/0.194\n",
      "87: Training / validation acc/loss: 1.000/0.157 / 0.980/0.192\n",
      "88: Training / validation acc/loss: 1.000/0.155 / 0.990/0.190\n",
      "89: Training / validation acc/loss: 1.000/0.153 / 0.990/0.188\n",
      "90: Training / validation acc/loss: 1.000/0.152 / 0.990/0.187\n",
      "91: Training / validation acc/loss: 1.000/0.150 / 0.990/0.185\n",
      "92: Training / validation acc/loss: 1.000/0.148 / 0.990/0.183\n",
      "93: Training / validation acc/loss: 1.000/0.147 / 0.990/0.182\n",
      "94: Training / validation acc/loss: 1.000/0.145 / 0.990/0.180\n",
      "95: Training / validation acc/loss: 1.000/0.144 / 0.990/0.179\n",
      "96: Training / validation acc/loss: 1.000/0.142 / 0.990/0.177\n",
      "97: Training / validation acc/loss: 1.000/0.141 / 0.990/0.176\n",
      "98: Training / validation acc/loss: 1.000/0.139 / 0.990/0.174\n",
      "99: Training / validation acc/loss: 1.000/0.138 / 0.990/0.173\n",
      "100: Training / validation acc/loss: 1.000/0.137 / 0.990/0.171\n",
      "101: Training / validation acc/loss: 1.000/0.135 / 0.990/0.170\n",
      "102: Training / validation acc/loss: 1.000/0.134 / 0.990/0.169\n",
      "103: Training / validation acc/loss: 1.000/0.132 / 0.990/0.167\n",
      "104: Training / validation acc/loss: 1.000/0.131 / 0.990/0.166\n",
      "105: Training / validation acc/loss: 1.000/0.130 / 0.990/0.164\n",
      "106: Training / validation acc/loss: 1.000/0.129 / 0.990/0.163\n",
      "107: Training / validation acc/loss: 1.000/0.127 / 0.990/0.162\n",
      "108: Training / validation acc/loss: 1.000/0.126 / 0.990/0.161\n",
      "109: Training / validation acc/loss: 1.000/0.125 / 0.990/0.159\n",
      "110: Training / validation acc/loss: 1.000/0.124 / 0.990/0.158\n",
      "111: Training / validation acc/loss: 1.000/0.122 / 0.990/0.157\n",
      "112: Training / validation acc/loss: 1.000/0.121 / 0.990/0.156\n",
      "113: Training / validation acc/loss: 1.000/0.120 / 0.990/0.155\n",
      "114: Training / validation acc/loss: 1.000/0.119 / 0.990/0.153\n",
      "115: Training / validation acc/loss: 1.000/0.118 / 0.990/0.152\n",
      "116: Training / validation acc/loss: 1.000/0.117 / 0.990/0.151\n",
      "117: Training / validation acc/loss: 1.000/0.116 / 0.990/0.150\n",
      "118: Training / validation acc/loss: 1.000/0.115 / 0.990/0.149\n",
      "119: Training / validation acc/loss: 1.000/0.114 / 0.990/0.148\n",
      "120: Training / validation acc/loss: 1.000/0.113 / 0.990/0.147\n",
      "121: Training / validation acc/loss: 1.000/0.112 / 0.990/0.146\n",
      "122: Training / validation acc/loss: 1.000/0.111 / 0.990/0.145\n",
      "123: Training / validation acc/loss: 1.000/0.110 / 0.990/0.144\n",
      "124: Training / validation acc/loss: 1.000/0.109 / 0.990/0.143\n",
      "125: Training / validation acc/loss: 1.000/0.108 / 0.990/0.142\n",
      "126: Training / validation acc/loss: 1.000/0.107 / 0.990/0.141\n",
      "127: Training / validation acc/loss: 1.000/0.106 / 0.990/0.140\n",
      "128: Training / validation acc/loss: 1.000/0.105 / 0.990/0.139\n",
      "129: Training / validation acc/loss: 1.000/0.104 / 0.990/0.138\n",
      "130: Training / validation acc/loss: 1.000/0.103 / 0.990/0.137\n",
      "131: Training / validation acc/loss: 1.000/0.102 / 0.990/0.136\n",
      "132: Training / validation acc/loss: 1.000/0.101 / 0.990/0.135\n",
      "133: Training / validation acc/loss: 1.000/0.100 / 0.990/0.134\n",
      "134: Training / validation acc/loss: 1.000/0.100 / 0.990/0.134\n",
      "135: Training / validation acc/loss: 1.000/0.099 / 0.990/0.133\n",
      "136: Training / validation acc/loss: 1.000/0.098 / 0.990/0.132\n",
      "137: Training / validation acc/loss: 1.000/0.097 / 0.990/0.131\n",
      "138: Training / validation acc/loss: 1.000/0.096 / 0.990/0.130\n",
      "139: Training / validation acc/loss: 1.000/0.095 / 0.990/0.129\n",
      "140: Training / validation acc/loss: 1.000/0.095 / 0.990/0.129\n",
      "141: Training / validation acc/loss: 1.000/0.094 / 0.990/0.128\n",
      "142: Training / validation acc/loss: 1.000/0.093 / 0.990/0.127\n",
      "143: Training / validation acc/loss: 1.000/0.092 / 0.990/0.126\n",
      "144: Training / validation acc/loss: 1.000/0.092 / 0.990/0.126\n",
      "145: Training / validation acc/loss: 1.000/0.091 / 0.990/0.125\n",
      "146: Training / validation acc/loss: 1.000/0.090 / 0.990/0.124\n",
      "147: Training / validation acc/loss: 1.000/0.090 / 0.990/0.123\n",
      "148: Training / validation acc/loss: 1.000/0.089 / 0.990/0.123\n",
      "149: Training / validation acc/loss: 1.000/0.088 / 0.990/0.122\n",
      "150: Training / validation acc/loss: 1.000/0.088 / 0.990/0.121\n",
      "151: Training / validation acc/loss: 1.000/0.087 / 0.990/0.120\n",
      "152: Training / validation acc/loss: 1.000/0.086 / 0.990/0.120\n",
      "153: Training / validation acc/loss: 1.000/0.086 / 0.990/0.119\n",
      "154: Training / validation acc/loss: 1.000/0.085 / 0.990/0.118\n",
      "155: Training / validation acc/loss: 1.000/0.084 / 0.990/0.118\n",
      "156: Training / validation acc/loss: 1.000/0.084 / 0.990/0.117\n",
      "157: Training / validation acc/loss: 1.000/0.083 / 0.990/0.116\n",
      "158: Training / validation acc/loss: 1.000/0.082 / 0.990/0.116\n",
      "159: Training / validation acc/loss: 1.000/0.082 / 0.990/0.115\n",
      "160: Training / validation acc/loss: 1.000/0.081 / 0.990/0.115\n",
      "161: Training / validation acc/loss: 1.000/0.081 / 0.990/0.114\n",
      "162: Training / validation acc/loss: 1.000/0.080 / 0.990/0.113\n",
      "163: Training / validation acc/loss: 1.000/0.079 / 0.990/0.113\n",
      "164: Training / validation acc/loss: 1.000/0.079 / 0.990/0.112\n",
      "165: Training / validation acc/loss: 1.000/0.078 / 0.990/0.111\n",
      "166: Training / validation acc/loss: 1.000/0.078 / 0.990/0.111\n",
      "167: Training / validation acc/loss: 1.000/0.077 / 0.990/0.110\n",
      "168: Training / validation acc/loss: 1.000/0.077 / 0.990/0.110\n",
      "169: Training / validation acc/loss: 1.000/0.076 / 0.990/0.109\n",
      "170: Training / validation acc/loss: 1.000/0.076 / 0.990/0.109\n",
      "171: Training / validation acc/loss: 1.000/0.075 / 0.990/0.108\n",
      "172: Training / validation acc/loss: 1.000/0.075 / 0.990/0.108\n",
      "173: Training / validation acc/loss: 1.000/0.074 / 0.990/0.107\n",
      "174: Training / validation acc/loss: 1.000/0.073 / 0.990/0.106\n",
      "175: Training / validation acc/loss: 1.000/0.073 / 0.990/0.106\n",
      "176: Training / validation acc/loss: 1.000/0.073 / 0.990/0.105\n",
      "177: Training / validation acc/loss: 1.000/0.072 / 0.990/0.105\n",
      "178: Training / validation acc/loss: 1.000/0.072 / 0.990/0.105\n",
      "179: Training / validation acc/loss: 1.000/0.071 / 0.990/0.104\n",
      "180: Training / validation acc/loss: 1.000/0.071 / 0.990/0.104\n",
      "181: Training / validation acc/loss: 1.000/0.070 / 0.990/0.103\n",
      "182: Training / validation acc/loss: 1.000/0.070 / 0.990/0.103\n",
      "183: Training / validation acc/loss: 1.000/0.069 / 0.990/0.102\n",
      "184: Training / validation acc/loss: 1.000/0.069 / 0.990/0.102\n",
      "185: Training / validation acc/loss: 1.000/0.068 / 0.990/0.101\n",
      "186: Training / validation acc/loss: 1.000/0.068 / 0.990/0.101\n",
      "187: Training / validation acc/loss: 1.000/0.067 / 0.990/0.100\n",
      "188: Training / validation acc/loss: 1.000/0.067 / 0.990/0.100\n",
      "189: Training / validation acc/loss: 1.000/0.067 / 0.990/0.099\n",
      "190: Training / validation acc/loss: 1.000/0.066 / 0.990/0.099\n",
      "191: Training / validation acc/loss: 1.000/0.066 / 0.990/0.099\n",
      "192: Training / validation acc/loss: 1.000/0.065 / 0.990/0.098\n",
      "193: Training / validation acc/loss: 1.000/0.065 / 0.990/0.098\n",
      "194: Training / validation acc/loss: 1.000/0.065 / 0.990/0.097\n",
      "195: Training / validation acc/loss: 1.000/0.064 / 0.990/0.097\n",
      "196: Training / validation acc/loss: 1.000/0.064 / 0.990/0.097\n",
      "197: Training / validation acc/loss: 1.000/0.063 / 0.990/0.096\n",
      "198: Training / validation acc/loss: 1.000/0.063 / 0.990/0.096\n",
      "199: Training / validation acc/loss: 1.000/0.063 / 0.990/0.095\n",
      "200: Training / validation acc/loss: 1.000/0.062 / 0.990/0.095\n",
      "201: Training / validation acc/loss: 1.000/0.062 / 0.990/0.095\n",
      "202: Training / validation acc/loss: 1.000/0.062 / 0.990/0.094\n",
      "203: Training / validation acc/loss: 1.000/0.061 / 0.990/0.094\n",
      "204: Training / validation acc/loss: 1.000/0.061 / 0.990/0.094\n",
      "205: Training / validation acc/loss: 1.000/0.061 / 0.990/0.093\n",
      "206: Training / validation acc/loss: 1.000/0.060 / 0.990/0.093\n",
      "207: Training / validation acc/loss: 1.000/0.060 / 0.990/0.093\n",
      "208: Training / validation acc/loss: 1.000/0.060 / 0.990/0.092\n",
      "209: Training / validation acc/loss: 1.000/0.059 / 0.990/0.092\n",
      "210: Training / validation acc/loss: 1.000/0.059 / 0.990/0.091\n",
      "211: Training / validation acc/loss: 1.000/0.059 / 0.990/0.091\n",
      "212: Training / validation acc/loss: 1.000/0.058 / 0.990/0.091\n",
      "213: Training / validation acc/loss: 1.000/0.058 / 0.990/0.090\n",
      "214: Training / validation acc/loss: 1.000/0.058 / 0.990/0.090\n",
      "215: Training / validation acc/loss: 1.000/0.057 / 0.990/0.090\n",
      "216: Training / validation acc/loss: 1.000/0.057 / 0.990/0.089\n",
      "217: Training / validation acc/loss: 1.000/0.057 / 0.990/0.089\n",
      "218: Training / validation acc/loss: 1.000/0.056 / 0.990/0.089\n",
      "219: Training / validation acc/loss: 1.000/0.056 / 0.990/0.088\n",
      "220: Training / validation acc/loss: 1.000/0.056 / 0.990/0.088\n",
      "221: Training / validation acc/loss: 1.000/0.055 / 0.990/0.088\n",
      "222: Training / validation acc/loss: 1.000/0.055 / 0.990/0.088\n",
      "223: Training / validation acc/loss: 1.000/0.055 / 0.990/0.087\n",
      "224: Training / validation acc/loss: 1.000/0.054 / 0.990/0.087\n",
      "225: Training / validation acc/loss: 1.000/0.054 / 0.990/0.087\n",
      "226: Training / validation acc/loss: 1.000/0.054 / 0.990/0.086\n",
      "227: Training / validation acc/loss: 1.000/0.054 / 0.990/0.086\n",
      "228: Training / validation acc/loss: 1.000/0.053 / 0.990/0.086\n",
      "229: Training / validation acc/loss: 1.000/0.053 / 0.990/0.085\n",
      "230: Training / validation acc/loss: 1.000/0.053 / 0.990/0.085\n",
      "231: Training / validation acc/loss: 1.000/0.053 / 0.990/0.085\n",
      "232: Training / validation acc/loss: 1.000/0.052 / 0.990/0.084\n",
      "233: Training / validation acc/loss: 1.000/0.052 / 0.990/0.084\n",
      "234: Training / validation acc/loss: 1.000/0.052 / 0.990/0.084\n",
      "235: Training / validation acc/loss: 1.000/0.051 / 0.990/0.084\n",
      "236: Training / validation acc/loss: 1.000/0.051 / 0.990/0.083\n",
      "237: Training / validation acc/loss: 1.000/0.051 / 0.990/0.083\n",
      "238: Training / validation acc/loss: 1.000/0.051 / 0.990/0.083\n",
      "239: Training / validation acc/loss: 1.000/0.050 / 0.990/0.082\n",
      "240: Training / validation acc/loss: 1.000/0.050 / 0.990/0.082\n",
      "241: Training / validation acc/loss: 1.000/0.050 / 0.990/0.082\n",
      "242: Training / validation acc/loss: 1.000/0.050 / 0.990/0.082\n",
      "243: Training / validation acc/loss: 1.000/0.049 / 0.990/0.081\n",
      "244: Training / validation acc/loss: 1.000/0.049 / 0.990/0.081\n",
      "245: Training / validation acc/loss: 1.000/0.049 / 0.990/0.081\n",
      "246: Training / validation acc/loss: 1.000/0.049 / 0.990/0.081\n",
      "247: Training / validation acc/loss: 1.000/0.048 / 0.990/0.080\n",
      "248: Training / validation acc/loss: 1.000/0.048 / 0.990/0.080\n",
      "249: Training / validation acc/loss: 1.000/0.048 / 0.990/0.080\n",
      "250: Training / validation acc/loss: 1.000/0.048 / 0.990/0.079\n",
      "251: Training / validation acc/loss: 1.000/0.047 / 0.990/0.079\n",
      "252: Training / validation acc/loss: 1.000/0.047 / 0.990/0.079\n",
      "253: Training / validation acc/loss: 1.000/0.047 / 0.990/0.079\n",
      "254: Training / validation acc/loss: 1.000/0.047 / 0.990/0.078\n",
      "255: Training / validation acc/loss: 1.000/0.047 / 0.990/0.078\n",
      "256: Training / validation acc/loss: 1.000/0.046 / 0.990/0.078\n",
      "257: Training / validation acc/loss: 1.000/0.046 / 0.990/0.078\n",
      "258: Training / validation acc/loss: 1.000/0.046 / 0.990/0.077\n",
      "259: Training / validation acc/loss: 1.000/0.046 / 0.990/0.077\n",
      "260: Training / validation acc/loss: 1.000/0.045 / 0.990/0.077\n",
      "261: Training / validation acc/loss: 1.000/0.045 / 0.990/0.077\n",
      "262: Training / validation acc/loss: 1.000/0.045 / 0.990/0.076\n",
      "263: Training / validation acc/loss: 1.000/0.045 / 0.990/0.076\n",
      "264: Training / validation acc/loss: 1.000/0.045 / 0.990/0.076\n",
      "265: Training / validation acc/loss: 1.000/0.044 / 0.990/0.076\n",
      "266: Training / validation acc/loss: 1.000/0.044 / 0.990/0.076\n",
      "267: Training / validation acc/loss: 1.000/0.044 / 0.990/0.075\n",
      "268: Training / validation acc/loss: 1.000/0.044 / 0.990/0.075\n",
      "269: Training / validation acc/loss: 1.000/0.044 / 0.990/0.075\n",
      "270: Training / validation acc/loss: 1.000/0.043 / 0.990/0.075\n",
      "271: Training / validation acc/loss: 1.000/0.043 / 0.990/0.074\n",
      "272: Training / validation acc/loss: 1.000/0.043 / 0.990/0.074\n",
      "273: Training / validation acc/loss: 1.000/0.043 / 0.990/0.074\n",
      "274: Training / validation acc/loss: 1.000/0.043 / 0.990/0.074\n",
      "275: Training / validation acc/loss: 1.000/0.042 / 0.990/0.074\n",
      "276: Training / validation acc/loss: 1.000/0.042 / 0.990/0.073\n",
      "277: Training / validation acc/loss: 1.000/0.042 / 0.990/0.073\n",
      "278: Training / validation acc/loss: 1.000/0.042 / 0.990/0.073\n",
      "279: Training / validation acc/loss: 1.000/0.042 / 0.990/0.073\n",
      "280: Training / validation acc/loss: 1.000/0.042 / 0.990/0.073\n",
      "281: Training / validation acc/loss: 1.000/0.041 / 0.990/0.072\n",
      "282: Training / validation acc/loss: 1.000/0.041 / 0.990/0.072\n",
      "283: Training / validation acc/loss: 1.000/0.041 / 0.990/0.072\n",
      "284: Training / validation acc/loss: 1.000/0.041 / 0.990/0.072\n",
      "285: Training / validation acc/loss: 1.000/0.041 / 0.990/0.071\n",
      "286: Training / validation acc/loss: 1.000/0.040 / 0.990/0.071\n",
      "287: Training / validation acc/loss: 1.000/0.040 / 0.990/0.071\n",
      "288: Training / validation acc/loss: 1.000/0.040 / 0.990/0.071\n",
      "289: Training / validation acc/loss: 1.000/0.040 / 0.990/0.071\n",
      "290: Training / validation acc/loss: 1.000/0.040 / 0.990/0.071\n",
      "291: Training / validation acc/loss: 1.000/0.040 / 0.990/0.070\n",
      "292: Training / validation acc/loss: 1.000/0.039 / 0.990/0.070\n",
      "293: Training / validation acc/loss: 1.000/0.039 / 0.990/0.070\n",
      "294: Training / validation acc/loss: 1.000/0.039 / 0.990/0.070\n",
      "295: Training / validation acc/loss: 1.000/0.039 / 0.990/0.070\n",
      "296: Training / validation acc/loss: 1.000/0.039 / 0.990/0.069\n",
      "297: Training / validation acc/loss: 1.000/0.039 / 0.990/0.069\n",
      "298: Training / validation acc/loss: 1.000/0.038 / 0.990/0.069\n",
      "299: Training / validation acc/loss: 1.000/0.038 / 0.990/0.069\n",
      "300: Training / validation acc/loss: 1.000/0.038 / 0.990/0.069\n",
      "301: Training / validation acc/loss: 1.000/0.038 / 0.990/0.069\n",
      "302: Training / validation acc/loss: 1.000/0.038 / 0.990/0.068\n",
      "303: Training / validation acc/loss: 1.000/0.038 / 0.990/0.068\n",
      "304: Training / validation acc/loss: 1.000/0.038 / 0.990/0.068\n",
      "305: Training / validation acc/loss: 1.000/0.037 / 0.990/0.068\n",
      "306: Training / validation acc/loss: 1.000/0.037 / 0.990/0.068\n",
      "307: Training / validation acc/loss: 1.000/0.037 / 0.990/0.067\n",
      "308: Training / validation acc/loss: 1.000/0.037 / 0.990/0.067\n",
      "309: Training / validation acc/loss: 1.000/0.037 / 0.990/0.067\n",
      "310: Training / validation acc/loss: 1.000/0.037 / 0.990/0.067\n",
      "311: Training / validation acc/loss: 1.000/0.037 / 0.990/0.067\n",
      "312: Training / validation acc/loss: 1.000/0.036 / 0.990/0.067\n",
      "313: Training / validation acc/loss: 1.000/0.036 / 0.990/0.066\n",
      "314: Training / validation acc/loss: 1.000/0.036 / 0.990/0.066\n",
      "315: Training / validation acc/loss: 1.000/0.036 / 0.990/0.066\n",
      "316: Training / validation acc/loss: 1.000/0.036 / 0.990/0.066\n",
      "317: Training / validation acc/loss: 1.000/0.036 / 0.990/0.066\n",
      "318: Training / validation acc/loss: 1.000/0.036 / 0.990/0.066\n",
      "319: Training / validation acc/loss: 1.000/0.035 / 0.990/0.065\n",
      "320: Training / validation acc/loss: 1.000/0.035 / 0.990/0.065\n",
      "321: Training / validation acc/loss: 1.000/0.035 / 0.990/0.065\n",
      "322: Training / validation acc/loss: 1.000/0.035 / 0.990/0.065\n",
      "323: Training / validation acc/loss: 1.000/0.035 / 0.990/0.065\n",
      "324: Training / validation acc/loss: 1.000/0.035 / 0.990/0.065\n",
      "325: Training / validation acc/loss: 1.000/0.035 / 0.990/0.064\n",
      "326: Training / validation acc/loss: 1.000/0.034 / 0.990/0.064\n",
      "327: Training / validation acc/loss: 1.000/0.034 / 0.990/0.064\n",
      "328: Training / validation acc/loss: 1.000/0.034 / 0.990/0.064\n",
      "329: Training / validation acc/loss: 1.000/0.034 / 0.990/0.064\n",
      "330: Training / validation acc/loss: 1.000/0.034 / 0.990/0.064\n",
      "331: Training / validation acc/loss: 1.000/0.034 / 0.990/0.064\n",
      "332: Training / validation acc/loss: 1.000/0.034 / 0.990/0.063\n",
      "333: Training / validation acc/loss: 1.000/0.034 / 0.990/0.063\n",
      "334: Training / validation acc/loss: 1.000/0.033 / 0.990/0.063\n",
      "335: Training / validation acc/loss: 1.000/0.033 / 0.990/0.063\n",
      "336: Training / validation acc/loss: 1.000/0.033 / 0.990/0.063\n",
      "337: Training / validation acc/loss: 1.000/0.033 / 0.990/0.063\n",
      "338: Training / validation acc/loss: 1.000/0.033 / 0.990/0.063\n",
      "339: Training / validation acc/loss: 1.000/0.033 / 0.990/0.062\n",
      "340: Training / validation acc/loss: 1.000/0.033 / 0.990/0.062\n",
      "341: Training / validation acc/loss: 1.000/0.033 / 0.990/0.062\n",
      "342: Training / validation acc/loss: 1.000/0.032 / 0.990/0.062\n",
      "343: Training / validation acc/loss: 1.000/0.032 / 0.990/0.062\n",
      "344: Training / validation acc/loss: 1.000/0.032 / 0.990/0.062\n",
      "345: Training / validation acc/loss: 1.000/0.032 / 0.990/0.062\n",
      "346: Training / validation acc/loss: 1.000/0.032 / 0.990/0.061\n",
      "347: Training / validation acc/loss: 1.000/0.032 / 0.990/0.061\n",
      "348: Training / validation acc/loss: 1.000/0.032 / 0.990/0.061\n",
      "349: Training / validation acc/loss: 1.000/0.032 / 0.990/0.061\n",
      "350: Training / validation acc/loss: 1.000/0.032 / 0.990/0.061\n",
      "351: Training / validation acc/loss: 1.000/0.031 / 0.990/0.061\n",
      "352: Training / validation acc/loss: 1.000/0.031 / 0.990/0.061\n",
      "353: Training / validation acc/loss: 1.000/0.031 / 0.990/0.061\n",
      "354: Training / validation acc/loss: 1.000/0.031 / 0.990/0.060\n",
      "355: Training / validation acc/loss: 1.000/0.031 / 0.990/0.060\n",
      "356: Training / validation acc/loss: 1.000/0.031 / 0.990/0.060\n",
      "357: Training / validation acc/loss: 1.000/0.031 / 0.990/0.060\n",
      "358: Training / validation acc/loss: 1.000/0.031 / 0.990/0.060\n",
      "359: Training / validation acc/loss: 1.000/0.031 / 0.990/0.060\n",
      "360: Training / validation acc/loss: 1.000/0.030 / 0.990/0.060\n",
      "361: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "362: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "363: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "364: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "365: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "366: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "367: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "368: Training / validation acc/loss: 1.000/0.030 / 0.990/0.059\n",
      "369: Training / validation acc/loss: 1.000/0.030 / 0.990/0.058\n",
      "370: Training / validation acc/loss: 1.000/0.029 / 0.990/0.058\n",
      "371: Training / validation acc/loss: 1.000/0.029 / 0.990/0.058\n",
      "372: Training / validation acc/loss: 1.000/0.029 / 0.990/0.058\n",
      "373: Training / validation acc/loss: 1.000/0.029 / 0.990/0.058\n",
      "374: Training / validation acc/loss: 1.000/0.029 / 0.990/0.058\n",
      "375: Training / validation acc/loss: 1.000/0.029 / 0.990/0.058\n",
      "376: Training / validation acc/loss: 1.000/0.029 / 0.990/0.058\n",
      "377: Training / validation acc/loss: 1.000/0.029 / 0.990/0.057\n",
      "378: Training / validation acc/loss: 1.000/0.029 / 0.990/0.057\n",
      "379: Training / validation acc/loss: 1.000/0.029 / 0.990/0.057\n",
      "380: Training / validation acc/loss: 1.000/0.029 / 0.990/0.057\n",
      "381: Training / validation acc/loss: 1.000/0.028 / 0.990/0.057\n",
      "382: Training / validation acc/loss: 1.000/0.028 / 0.990/0.057\n",
      "383: Training / validation acc/loss: 1.000/0.028 / 0.990/0.057\n",
      "384: Training / validation acc/loss: 1.000/0.028 / 0.990/0.057\n",
      "385: Training / validation acc/loss: 1.000/0.028 / 0.990/0.057\n",
      "386: Training / validation acc/loss: 1.000/0.028 / 0.990/0.056\n",
      "387: Training / validation acc/loss: 1.000/0.028 / 0.990/0.056\n",
      "388: Training / validation acc/loss: 1.000/0.028 / 0.990/0.056\n",
      "389: Training / validation acc/loss: 1.000/0.028 / 0.990/0.056\n",
      "390: Training / validation acc/loss: 1.000/0.028 / 0.990/0.056\n",
      "391: Training / validation acc/loss: 1.000/0.028 / 0.990/0.056\n",
      "392: Training / validation acc/loss: 1.000/0.027 / 0.990/0.056\n",
      "393: Training / validation acc/loss: 1.000/0.027 / 0.990/0.056\n",
      "394: Training / validation acc/loss: 1.000/0.027 / 0.990/0.056\n",
      "395: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "396: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "397: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "398: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "399: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "400: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "401: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "402: Training / validation acc/loss: 1.000/0.027 / 0.990/0.055\n",
      "403: Training / validation acc/loss: 1.000/0.026 / 0.990/0.055\n",
      "404: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "405: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "406: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "407: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "408: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "409: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "410: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "411: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "412: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "413: Training / validation acc/loss: 1.000/0.026 / 0.990/0.054\n",
      "414: Training / validation acc/loss: 1.000/0.026 / 0.990/0.053\n",
      "415: Training / validation acc/loss: 1.000/0.026 / 0.990/0.053\n",
      "416: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "417: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "418: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "419: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "420: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "421: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "422: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "423: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "424: Training / validation acc/loss: 1.000/0.025 / 0.990/0.053\n",
      "425: Training / validation acc/loss: 1.000/0.025 / 0.990/0.052\n",
      "426: Training / validation acc/loss: 1.000/0.025 / 0.990/0.052\n",
      "427: Training / validation acc/loss: 1.000/0.025 / 0.990/0.052\n",
      "428: Training / validation acc/loss: 1.000/0.025 / 0.990/0.052\n",
      "429: Training / validation acc/loss: 1.000/0.024 / 0.990/0.052\n",
      "430: Training / validation acc/loss: 1.000/0.024 / 0.990/0.052\n",
      "431: Training / validation acc/loss: 1.000/0.024 / 0.990/0.052\n",
      "432: Training / validation acc/loss: 1.000/0.024 / 0.990/0.052\n",
      "433: Training / validation acc/loss: 1.000/0.024 / 0.990/0.052\n",
      "434: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "435: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "436: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "437: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "438: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "439: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "440: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "441: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "442: Training / validation acc/loss: 1.000/0.024 / 0.990/0.051\n",
      "443: Training / validation acc/loss: 1.000/0.023 / 0.990/0.051\n",
      "444: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "445: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "446: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "447: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "448: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "449: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "450: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "451: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "452: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "453: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "454: Training / validation acc/loss: 1.000/0.023 / 0.990/0.050\n",
      "455: Training / validation acc/loss: 1.000/0.023 / 0.990/0.049\n",
      "456: Training / validation acc/loss: 1.000/0.023 / 0.990/0.049\n",
      "457: Training / validation acc/loss: 1.000/0.023 / 0.990/0.049\n",
      "458: Training / validation acc/loss: 1.000/0.023 / 0.990/0.049\n",
      "459: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "460: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "461: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "462: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "463: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "464: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "465: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "466: Training / validation acc/loss: 1.000/0.022 / 0.990/0.049\n",
      "467: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "468: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "469: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "470: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "471: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "472: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "473: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "474: Training / validation acc/loss: 1.000/0.022 / 0.990/0.048\n",
      "475: Training / validation acc/loss: 1.000/0.021 / 0.990/0.048\n",
      "476: Training / validation acc/loss: 1.000/0.021 / 0.990/0.048\n",
      "477: Training / validation acc/loss: 1.000/0.021 / 0.990/0.048\n",
      "478: Training / validation acc/loss: 1.000/0.021 / 0.990/0.048\n",
      "479: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "480: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "481: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "482: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "483: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "484: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "485: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "486: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "487: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "488: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "489: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "490: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "491: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "492: Training / validation acc/loss: 1.000/0.021 / 0.990/0.047\n",
      "493: Training / validation acc/loss: 1.000/0.020 / 0.990/0.047\n",
      "494: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "495: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "496: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "497: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "498: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "499: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "500: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "501: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "502: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "503: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "504: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "505: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "506: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "507: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "508: Training / validation acc/loss: 1.000/0.020 / 0.990/0.046\n",
      "509: Training / validation acc/loss: 1.000/0.020 / 0.990/0.045\n",
      "510: Training / validation acc/loss: 1.000/0.020 / 0.990/0.045\n",
      "511: Training / validation acc/loss: 1.000/0.020 / 0.990/0.045\n",
      "512: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "513: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "514: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "515: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "516: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "517: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "518: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "519: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "520: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "521: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "522: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "523: Training / validation acc/loss: 1.000/0.019 / 0.990/0.045\n",
      "524: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "525: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "526: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "527: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "528: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "529: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "530: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "531: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "532: Training / validation acc/loss: 1.000/0.019 / 0.990/0.044\n",
      "533: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "534: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "535: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "536: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "537: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "538: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "539: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "540: Training / validation acc/loss: 1.000/0.018 / 0.990/0.044\n",
      "541: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "542: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "543: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "544: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "545: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "546: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "547: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "548: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "549: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "550: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "551: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "552: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "553: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "554: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "555: Training / validation acc/loss: 1.000/0.018 / 0.990/0.043\n",
      "556: Training / validation acc/loss: 1.000/0.017 / 0.990/0.043\n",
      "557: Training / validation acc/loss: 1.000/0.017 / 0.990/0.043\n",
      "558: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "559: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "560: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "561: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "562: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "563: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "564: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "565: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "566: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "567: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "568: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "569: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "570: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "571: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "572: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "573: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "574: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "575: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "576: Training / validation acc/loss: 1.000/0.017 / 0.990/0.042\n",
      "577: Training / validation acc/loss: 1.000/0.017 / 0.990/0.041\n",
      "578: Training / validation acc/loss: 1.000/0.017 / 0.990/0.041\n",
      "579: Training / validation acc/loss: 1.000/0.017 / 0.990/0.041\n",
      "580: Training / validation acc/loss: 1.000/0.017 / 0.990/0.041\n",
      "581: Training / validation acc/loss: 1.000/0.017 / 0.990/0.041\n",
      "582: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "583: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "584: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "585: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "586: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "587: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "588: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "589: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "590: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "591: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "592: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "593: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "594: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "595: Training / validation acc/loss: 1.000/0.016 / 0.990/0.041\n",
      "596: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "597: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "598: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "599: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "600: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "601: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "602: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "603: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "604: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "605: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "606: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "607: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "608: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "609: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "610: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "611: Training / validation acc/loss: 1.000/0.016 / 0.990/0.040\n",
      "612: Training / validation acc/loss: 1.000/0.015 / 0.990/0.040\n",
      "613: Training / validation acc/loss: 1.000/0.015 / 0.990/0.040\n",
      "614: Training / validation acc/loss: 1.000/0.015 / 0.990/0.040\n",
      "615: Training / validation acc/loss: 1.000/0.015 / 0.990/0.040\n",
      "616: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "617: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "618: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "619: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "620: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "621: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "622: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "623: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "624: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "625: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "626: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "627: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "628: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "629: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "630: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "631: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "632: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "633: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "634: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "635: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "636: Training / validation acc/loss: 1.000/0.015 / 0.990/0.039\n",
      "637: Training / validation acc/loss: 1.000/0.015 / 0.990/0.038\n",
      "638: Training / validation acc/loss: 1.000/0.015 / 0.990/0.038\n",
      "639: Training / validation acc/loss: 1.000/0.015 / 0.990/0.038\n",
      "640: Training / validation acc/loss: 1.000/0.015 / 0.990/0.038\n",
      "641: Training / validation acc/loss: 1.000/0.015 / 0.990/0.038\n",
      "642: Training / validation acc/loss: 1.000/0.015 / 0.990/0.038\n",
      "643: Training / validation acc/loss: 1.000/0.015 / 0.990/0.038\n",
      "644: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "645: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "646: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "647: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "648: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "649: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "650: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "651: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "652: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "653: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "654: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "655: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "656: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "657: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "658: Training / validation acc/loss: 1.000/0.014 / 0.990/0.038\n",
      "659: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "660: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "661: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "662: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "663: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "664: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "665: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "666: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "667: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "668: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "669: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "670: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "671: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "672: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "673: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "674: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "675: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "676: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "677: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "678: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "679: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "680: Training / validation acc/loss: 1.000/0.014 / 0.990/0.037\n",
      "681: Training / validation acc/loss: 1.000/0.013 / 0.990/0.037\n",
      "682: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "683: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "684: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "685: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "686: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "687: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "688: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "689: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "690: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "691: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "692: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "693: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "694: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "695: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "696: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "697: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "698: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "699: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "700: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "701: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "702: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "703: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "704: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "705: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "706: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "707: Training / validation acc/loss: 1.000/0.013 / 0.990/0.036\n",
      "708: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "709: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "710: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "711: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "712: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "713: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "714: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "715: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "716: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "717: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "718: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "719: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "720: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "721: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "722: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "723: Training / validation acc/loss: 1.000/0.013 / 0.990/0.035\n",
      "724: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "725: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "726: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "727: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "728: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "729: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "730: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "731: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "732: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "733: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "734: Training / validation acc/loss: 1.000/0.012 / 0.990/0.035\n",
      "735: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "736: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "737: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "738: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "739: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "740: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "741: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "742: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "743: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "744: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "745: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "746: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "747: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "748: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "749: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "750: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "751: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "752: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "753: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "754: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "755: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "756: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "757: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "758: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "759: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "760: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "761: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "762: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "763: Training / validation acc/loss: 1.000/0.012 / 0.990/0.034\n",
      "764: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "765: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "766: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "767: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "768: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "769: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "770: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "771: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "772: Training / validation acc/loss: 1.000/0.012 / 0.990/0.033\n",
      "773: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "774: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "775: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "776: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "777: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "778: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "779: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "780: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "781: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "782: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "783: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "784: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "785: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "786: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "787: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "788: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "789: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "790: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "791: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "792: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "793: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "794: Training / validation acc/loss: 1.000/0.011 / 0.990/0.033\n",
      "795: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "796: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "797: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "798: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "799: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "800: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "801: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "802: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "803: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "804: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "805: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "806: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "807: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "808: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "809: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "810: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "811: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "812: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "813: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "814: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "815: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "816: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "817: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "818: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "819: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "820: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "821: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "822: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "823: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "824: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "825: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "826: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "827: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "828: Training / validation acc/loss: 1.000/0.011 / 0.990/0.032\n",
      "829: Training / validation acc/loss: 1.000/0.011 / 0.990/0.031\n",
      "830: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "831: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "832: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "833: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "834: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "835: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "836: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "837: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "838: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "839: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "840: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "841: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "842: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "843: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "844: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "845: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "846: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "847: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "848: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "849: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "850: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "851: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "852: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "853: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "854: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "855: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "856: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "857: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "858: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "859: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "860: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "861: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "862: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "863: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "864: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "865: Training / validation acc/loss: 1.000/0.010 / 0.990/0.031\n",
      "866: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "867: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "868: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "869: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "870: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "871: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "872: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "873: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "874: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "875: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "876: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "877: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "878: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "879: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "880: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "881: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "882: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "883: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "884: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "885: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "886: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "887: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "888: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "889: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "890: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "891: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "892: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "893: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "894: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "895: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "896: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "897: Training / validation acc/loss: 1.000/0.010 / 0.990/0.030\n",
      "898: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "899: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "900: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "901: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "902: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "903: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "904: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "905: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "906: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "907: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "908: Training / validation acc/loss: 1.000/0.009 / 0.990/0.030\n",
      "909: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "910: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "911: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "912: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "913: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "914: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "915: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "916: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "917: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "918: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "919: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "920: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "921: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "922: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "923: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "924: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "925: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "926: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "927: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "928: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "929: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "930: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "931: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "932: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "933: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "934: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "935: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "936: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "937: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "938: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "939: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "940: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "941: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "942: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "943: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "944: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "945: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "946: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "947: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "948: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "949: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "950: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "951: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "952: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "953: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "954: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "955: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "956: Training / validation acc/loss: 1.000/0.009 / 0.990/0.029\n",
      "957: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "958: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "959: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "960: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "961: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "962: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "963: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "964: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "965: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "966: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "967: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "968: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "969: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "970: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "971: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "972: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "973: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "974: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "975: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "976: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "977: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "978: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "979: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "980: Training / validation acc/loss: 1.000/0.009 / 0.990/0.028\n",
      "981: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "982: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "983: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "984: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "985: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "986: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "987: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "988: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "989: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "990: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "991: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "992: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "993: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "994: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "995: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "996: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "997: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "998: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n",
      "999: Training / validation acc/loss: 1.000/0.008 / 0.990/0.028\n"
     ]
    }
   ],
   "source": [
    "class Glorot(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "            nn.init.zeros_(m.bias.data)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "glorot = Glorot()\n",
    "train(glorot.to(dev), train_loader, val_loader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "509b5e2f-17aa-4839-ad67-a0f58d951bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:54:29.123745Z",
     "iopub.status.busy": "2023-04-19T18:54:29.122936Z",
     "iopub.status.idle": "2023-04-19T18:54:29.367005Z",
     "shell.execute_reply": "2023-04-19T18:54:29.366401Z",
     "shell.execute_reply.started": "2023-04-19T18:54:29.123715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAGdCAYAAAC/5RwpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3ZklEQVR4nO2deXgT5fbHv0n3NGlpS/eWtSwiCoqyFaHsIEUQBfTn9QoibqAgboALeq8CKrheRFEBFxRlh7JvBdkR3FBZytq9LG2Tpnsyvz/SNPNOm2SSJplJez7Pk4eZzGTmbZjMmfec7zlHwXEcB4IgCIKQEKXUAyAIgiAIMkYEQRCE5JAxIgiCICSHjBFBEAQhOWSMCIIgCMkhY0QQBEFIDhkjgiAIQnLIGBEEQRCS4yv1AGxhNBqRk5MDjUYDhUIh9XAIgiAIB+E4DjqdDnFxcVAqrc9/ZG2McnJykJiYKPUwCIIgiAaSmZmJhIQEq9tlbYw0Gg0A4CHEw588igRBEF5HJYxYgeza+7k1ZG2MzK45fyjJGBHyRKmAqlc8fKODUZ2vR+nhbMBI5R4JQoi9UIusjRFByBlNahKi56XAL97yxFeVrUP+rHTo0jIkHBlBeB803SAIJ9CkJiF+eSp8Y9XM+76xasQvT4UmNUmikRGEd0IzI4IQA98dd7UU0fNSAAAKJet6UCgV4Iwcouf2g27LeXLZEYRIyBgRjQ8Xx3Hqc8fZQqFUwC8hBKpe8Sg9mCX+RBR/IpowZIyIRoWr4zhmd5wz+EYHO3Qeij8RTRmKGRGNBpfHcZQKq+44MVTn60XtR/EngiBjRDQWbBgO83r03H6AA0ZF1SsefvEahw0RZ+RQlaU1udns4YZxE4Q3QsaIaBTYMxz8OI5YHHGzmeFqYjz5s/eJive4Y9wE4Y2QMSIaBWINhyMGRqybjflMjg7ZE9JEx3ncMW6C8EZIwEC4FokUYWINhyMGpvRwNqqydfCNVdc7c+GMHKpzSpAzZRt8I537e90xboLwRsgYES5DSkWYOMOhExfHMWPkkD8rHfHLU8EZOea4FndcOkp/dkC+7YlxE4QXQm46wiVIrgirMRyAxVCYcTSOw0eXloHsCWmozi1h3nfUHWcVN42bILwNBcdxsr3KtVotQkNDMRGJVChVzigVSPp9kt2n+4yuS91+U613dpalRf7sfQ0zHG52P7pt3AQhMZUwYhkyUVxcjJCQEKv7kZuOaDBmRZg1nK5I4AS6tAzotpx3veEwcm4du9vGTRBeAhkjosHIThHmZsPhNrx13AThAsj3RTQYUoQRBNFQyBgRDcasCBMG4M04VJGAIIgmCRkjouGQIowgiAZCxohwCW6XQBME0aghAQPhMkgRRhCEs5AxIlwLKcIIgnACctMRBEEQkkPGiCAIgpAcMkYEQRCE5JAxIgiCICSHjBFBEAQhOWSMCIIgCMkhY0QQBEFIDhkjgiAIQnI8Zozmz58PhUKB6dOne+qUBEEQhJfgEWN0/PhxfP7557j11ls9cTqCIAjCy3C7MSopKcFDDz2EL774AmFhYe4+HUEQBOGFuN0YTZkyBSNGjMCgQYPcfSqCIAjCS3FrodSVK1fi5MmTOH78uKj9KyoqUFFRUbuu1WrdNTSCIAhCRrhtZpSZmYlp06ZhxYoVCAwMFPWZefPmITQ0tPaVmJjoruERBEEQMkLBcZxbms2sX78e9957L3x8fGrfMxgMUCgUUCqVqKioYLYB9c+MEhMTMRGJ8CcVOkEQhNdRCSOWIRPFxcUICQmxup/b3HQDBw7En3/+ybw3ceJEdOzYES+//HIdQwQAAQEBCAgIcNeQCEJWCB+vjJKMgiDkgduMkUajQefOnZn3goODERERUed9giAIomlDnV4Jwh0oFdR+nSAcwKPGKD093ZOnIwhJ0KQmIXpeCvziNbXvVWXrkD8rHbq0DAlHRhDyhVQBBOFCNKlJiF+eCt9YNfO+b6wa8ctTEZKaBCXq/+EpbbwIorFD1zlBuAqlAtHzUgAACqWC2WRej5rbDxBsIwiCjBFBuAxVr3j4xWvqGCIzCqUCfgkhCOoV7+GREYT8IWNEEC7CNzrYpfsRRFOC1HQE4SKq8/Wi9uMK9PCx46kzCIR3lJNENHZoZkQQLqL0cDaqsnXgrEi4OSOHqiwtyg5ne3hkBCF/yBgRhKswciiYlQ4AdQySef3aK/so34gg6oGMEUE4iC0JdtnmDORNTEN1bgnzmeocHa49moaqLefhr1TU+/JR8F9gXo6MgSC8EYoZEYSL0adlQL/lPIJ6xcMnOhiGfD3KDmfDX+qBEYSMIWNEEO7AyKHsYBb7HuUXEYRVaFZPEARBSA7NjAiiHhx5SuPHdHwU7OzHnzcbckTOXVlHu21d9EAycKIxQDMjgiAIQnLIGBEEQRCSQ8aIIAiCkByKGREEbD+VCWM9wrgQf7u/0nrMKMiHPYuBY4M9ZcLgD7OvrXXOxjb2b6P4ESFXaGZEEARBSA7NjAiC8F6ovXujgYwR0WRwxBXHR+h6syXfDhIcSO1rOWuILzuCcsFNs6Ta4kQTuuzKDKyDzVkZuK1NgHe58ai9e+OC3HQEQXgd9tq7a1KTJBoZ4SxkjAiC8C5EtHePpvbuXgcZI4IgvAqx7d1V1N7dq6CYEdFocLaEj2ldvFxbKNHmx4lC/XyYbWF+ln1Dw4OYbSWF5cy6n8LAOz8bvRGOtynLwKm9e+OEZkYEQXgVYtu7i92PkAc0MyIcg6S0hMSY27v7xqrrddVxRg7VOTrTtUl4DWSMCNGQlJaQBUYO+bPSEb88FZyRYwySub17/mxq7+5tkDEiRGGW0goxS2mzJ6RJYpCcLeMj3OZIGR+1IF+IHxcKU7P9XDU86XFwtIo9R6aOWQ8oKLVsK61itmmrhTEtfk4SG90R5h1VMjdl4UzCO3OSdGkZyJ6QVufhqDpHh/zZ++jhyAshY0TYx46UljNyiJ7bD7ot5+lplPAYurQM6LacJ7dxI4GMEWEXs5TWGnwpbamw1TZBuBMjR9dcI4GMEWEXKaW09uSezpbxqSvXtl7GJ1jgposMYOXb6iiL+61Zy1BmW1hSVO1yYAS7LSiMDbAXXiisXfbNYZVgQcWsDJw//hKBC0/otuPLwCuNtqXdjU0GTngPZIwIu5CUliCchNSnoiFjJBdkfNGSlJaQDBn/LuxB6lPHIGMkA2R/0ZKUlpAA2f8ubCBX9amcUXAcJ9s7iFarRWhoKCYiEf6NtFgE/6Kt7yYvp4u23ptDltblUlp3ybX5Em1hjMhWGZ+Q0EBmW0gCK+YIbxdRu9ysfSJ73Js7WVb8WNl36bnTzPqNfy7XLhdfvMZs02axMvASnku0sMLA7lvNRnDY1hRCGThndb1uPMl2DMkWjsaUvOl3UQelAkm/T7LrScjourRJPMBVwohlyERxcTFCQkKs7kczIynxMsk0SWkJBqUCQbxrocxV14KX/S6EkPrUOcgYSYhXXrQkpSUABKcmofncui60glnpKGngjMUrfxc8qJCrczRO35eX0KQvWqUCquQEhIzpAFVyAvWe8SKCU5MQs6z+xnZxy1OhbmBjO2//XZD61DloZiQhTfWiDUlNQlQ9gWnzUzU/nGOrtQPAxoXstXqw1QI8QuXH7htrudGFtQljtoW1j2PWw29pV7sc0P42ZpsxoXPtsqKazRXSRMQw6wHhv1nGHnGR2RYYlsPuG2KJP/kLcpL8i8TnJJVUC1tV2MlJUioQOTcFgHUXWtTcfigRuNAcyUny9t8FqU+dg2ZGEmK+aDkrfm/OyKEqS9uoLlpNahLirLSLdsVTtZwwGAz4bOly9B02EuMnTMZbCz/Bpu27kFdwVeqhOU1Az3j4imhsF9SAxnZe/7uoUZ8CqPM3kPrUOjQzkpKmJpkWEZiOmtsPl7fKMzDtCId//xvPzluE305b4ifr07YAAHx9ffHq88/gpfsGwNfXx9ohZImPJ1xojeB34XQhVy/Oq2ooZIwkprFWH65vyh0kMjAd3DsB5TWBaVvVtAFWoi10ywldcfwyPvwSPoDtMj7hN7dmtqk6dmHWla1uqV3ONKgxZ85r+PbrrwEAmpAQPPbsC/BRKnHxzF/48/ffcPb0P3jjnQ+wZfd+fPn5p2jfzuTmCwxtXnuciLDfmXMERpxh1v01Fhm4X/B1ZptvlpZZD75WVrt8rbya2Warg2x91cCVV8W5xrgCPXNsvgzcnjvGiMbxu3BUferNeVWugIyRDGgqkmmxT8tin77lhNFoxFc/rMYr736Mwhs3AAAP/etfeOzFOYhoHgkACA3wAcdxWL/6J7z+8vM49ssJ9OiTgrffnIMnH39MyuGLpvJIDgzZOihtxEMMOSUmmXcDaRS/C5HqU0qSpZiRfKi5aLVrz5guXm/6wYlEbMDZINPAtDVO/PEXku95EE/PfAOFN26gc+dbsH3nbnz62ZJaQ2RGoVDg3rHjsePAUQzsn4KysjLMeGkm7h41Bldy8qT5AxzByEH76j4A1uMh119Jd9312wR+F/bc1wAQPbdfo1eckjEiPEaZyMB0uVwD0wIKdSV49v2v0Ct1HH75/U9o1MGY/8572HfgIHr26mXzs7Fx8di0bjU+eO8dBAUFIX3ffnQd/iC+Xp0GGRdFAQBUbDmPokmbYcgtYd435JSgYGIaSjefl2hk3ok5r8qeKETVAFGIN0BuOsIliGr1wHG4NjsdMcusB6aLXt2HIAVqgxnCOJCtVg9hwpI+zayX8akj176pJbvvTR1rl/073s5sq4zqgBXf/4DZr76Oq9dMZXvuGTMWM998G9eVGhzKtszsfs+1xG/aNWfdj52i1Bj00BNI6jkQr0x/Cn+cOI5JL/8Ha/afxJL5ryKquaXMUEhYFPNZfjuKwIhLzLagsFxmvehyce2ybw5rQIJ0lcw6v5RQMdtsloknYftFFG6/CL+ecVBGBaMirwSVR3IAIwd/paJOt1lbbWObemsKb8+rchU0MyI8ij4tAwUT0+p9qr72aBrKZP5U/eeZDAwedjcmP/k0rl67ho4dOuDbtWl4/7OvEBUdY/8A9dCqbRK+Wb8Nc954E35+ftiyOQ23pdyN9Vt2uHj0LsbIoepQNirWn0XlIS+L5cgIb8+rchU0MyI8Tunm8yjdegGBveLhEx0MLl+PiiPyvpkV60rw5kdfYtG3q2AwGKBSqTDzpRcx7ZkpuGoItH8AO/j4+OC551/A4KFD8cTkx/DXqVMYN2kK/jX2Xrz/31fRrOF/AiFTKEnWBM2MCGkwcig/mAX92jOoOCTfwDTHcfh+wzbcPGQ8Pl6+EgaDAfeOHoVffzmKF59/Dv7+/vYP4gCdO9+CPen78dIzT0KpVOK7Vetw+4AR2H3sN5eeh5ARlCQLgFpIEA7gbGsHZntNpWef6GAY8vWoPJJjihHx4MeJ1L62c4f4ZXz4JXyAenKHOljK+ETwSvgAgH/7rsw6l3gL/jl7DtNffhXpBw4BANomtcNb7yxA4m3JzL6/51naO/xy6Qaz7WK+xR3ZLpbNserago1bdYqyVKVoGxaIX44dwXNPP4HLFy8AAJ5+/DG8NedVqFQq+F2zuDMrz7E5Sbp/2NYUhecya5eLLrDj0+UKWlMUlNYu36gU35rCVisK4bqUrSnkjKdatHgaaiFByI6gEW0R9nYKfPlJjNk6lL2+H1Vb5BMr0peVY+5/5+ODTz9HdXU1AgMDMe35l/DUM9MQEBCA84Xl9g/iAu7o3hPb0g9i7huv4dtlX+LTJV9i5569WPrZIvQWGFrC+2kUeVUNgKYbhEcIGtEWzZemwkdQk84nVg31F3fD7+62Eo3MAsdxWLv7AG697wm89/EiVFdXY8TQQdh35BdMf+ElBAQEeHxMwWo13l7wATatXom42BicyziPlKEj8PoHn6Oyssr+AQjvoinkVVmB3HQEgyOuOHabjbI9SgViTk6EMsZ6gBa5JTAmfwsYOcYVF+7PyrVDo9kyPiEJlml/WBKbYBohLONz062W8bbpymw7daMaLz4/A7t27QIAxCe2wMv/mY/+Q+9m3HAA8FtWEbP+xxWLdPp6PqsSLC+1SKc1YUHMtrgY1m13c4JltnNrHOvO6BQZjKLCQrz9yovYsm61aZ9bb8WSL77E7YISS1zmP8x6ZcYflvH9xVYDL75YwK7zZOA6geKxsMS6DFxY/bvMYN1NZ8+lJ3TbsdusbmpULrvGhFg3Hd3hCbfj3zMOPnG2k/oU8Rqge6yHRwaUlpXh9Xc/Qo8778CuXbvg7++Pl2fOxLq9R9B/6N0eH48tmoWF4b1Pv8T7S5YjPCICf/zxB/re1QcLPv0SBoPB/gEIQsaQMSLcjthac4oozyb1bdqxB10G3oN5n3yOyspKDBo0CEeP/4JXX3sdQSqV/QNIxNCRo3Hs2HEMGz4clZWVmD13IQaNfQTnL12RemgE4TRkjAi3I7bWHFfgmaS+i7kFGD3xaYyZNBWXMrORGBeD777/HmvXb0BSknf0U4qOicFPq1Zj0aeLoQ5W4eCxE7hjyL348rufZF9OiCDqg9R0TRyXyLVhp8vqL3ngcnSAlZgRjByUeXpE/XEVikBfpoyPJo6dLdUp49PRUsYntFMHZpt/pzuZdX1oS7z/0Sd4Z8H7KC8vh5+fHyY99QymzngRl8sU+DnTEhv6g1fG5+SlQuY4mTlsi4bi6xY5tL6QjS8Zqy1xlsoKduwVgnYOhXrLvle1rGLvemkzZr1zlClO1GXYWOzqfReem/oUDh/4GU/PnIMNgwZg8UfvIy7WVBEiiFdKKCr0V+Y4gRHnmPWAkEzeMivY8Be0pgjitabwU7BuQn+ldRm4rdgjwMaF6saIrMvAxbSmIOQLzYwI92PkUD3nZwB1k/rMaiHN3ENQuFE5tOPno7ij11148625KC8vR6+7+mHLvsN46bU3oAr27ppfiS1a4qf1aXjj7fkICAjA9l170C05BavWrpd6aAQhGjJGhEfgtl1A9RNbgTxWoYW8EoQ+uxOBOy7W/8EGciUnD+OmzMLdE6fhXEYGYqKj8fVXX+C7NRvRtl17t5xTCpRKJSY/NQXb9h7AbV1uRWFRER5+7Ek8POkJXC8stn8AgpAYctMRHoPbdgFVOy5C1SseXJQKioJSKI7nItDH9c9ElVXV+OCzb/D2oqUoLSuHj48Ppjz5OF6d9TJCQkKQU9E4e8O079gR+3dsxrwFH+Cd9z/CqnUb8POBA1jy1kzc3c92WwuCkBLKM2pi2PsW+bEfezEjWy2/bZXx4ZfwAWyX8eGX8AGAiJvbsOPt2K12mUu4GQCQfuAQps18DafPmkqo9OzVG/MWvI/AOEsJoN/z2fjHCUFc6Gy2ZXuRoNW29kYZs16uvVa7XKljj8OMVcPGjALU4cy6mpeHJMxJShDkJHVp0ax2ubNgW8eaVhV//noCLz/7JC6cOwsAmDBxIt5/8Ulo1Jbv23j5L/ZvOfdn7fKNfy4z24Q5SfzWFHpeGSGgYTlJ/HbnwpgR5SR5H5RnRDQ5cvPzMeGpaRg65kGcPpuB5pGR+OSzL7Buy3bcdHNnqYfncW65rRvW7tiPKVOmAgCWL1uGbkPvw4GjJyQeGUHUhYwR4fVUVxvwyffrcWvvgfhhzXooFAo8MfFhHDh+EmMfeBAKReN0yYkhMCgI77z7LrZs3YYWLVrgYmYWBoybgJfeeg/l5RVSD48gaqGYURPHlsxW6HoTyrf5rjhhNW1hGZ+Q5ha3U6iwmragjE84r+tq8E23sONtexuznn42H89Nn45Tp0zupc5db8dr8xaic9fb8GteCVBYVLvvb9kWt9KvArecsIyPttDiiisrYvetELjiKkstxzVUsC48hdLyPfBl3qZ9Wfm2odLixqsqZ7+jyjJWBn6DJwMvqCMDZ2vWdYpUI6zjnViatg9fvTsHP3z3DT5Y8jU27z+KbxZ9iNu6WL5jVZjl/8I3/A/mOIERbOVovgy86HIRs803i5W4B/GKywpl4D4Ko2Ddsix04QlxlQyc3HbS49aZ0bx583DnnXdCo9EgKioKo0ePxpkzZ9x5SqKJkH/1Gh6d8QoGDxqIU6f+RHh4ON547yP8sHkXOne9zf4BmiDBmhC8/8mn+Pr7nxAZFYWzp0+jz9BUzFv4Iaqrq+0fgCDciFuN0b59+zBlyhQcOXIEO3fuRFVVFYYMGQK9vnG3zyXch8FgwKdf/4Cb+4/Et6s3QKFQYMLEifj1t98x9l+PQKkkz7M9hgy/G3sPHcOIe0ahuroab8x7D/1HjMaZc97bM4fwftzqptu2bRuzvnz5ckRFReHEiRPo27evO09NNEKO/Z2Bac/Mw6+n/gYA3Na5E97/36e4887uAIASbaWtjxM8IiKa44vl32H7ymWYPvNVHDvxK3oMGIq50x/D0w+OJqNOeByPxoyKi02+9fDwcDt7ElLB99cL40nCOFBz3nqohm2/HZrIyo35ZXz4JXyAumV8Am66o3a5KrIdrt+4gdf/8xaWfv0tOI5DSGgzvPDKa/i/Rx5FRmEFDmSaZNi/Csr0CMv4ZPFaQWivs1LkkkJ2ts6Xa1fp2aTRqjI2vmSotMSJhHEhWzEjo5GNnfC3V1eysafKiubMekW5JS5UrmePW6BlhQkFLSzrnaPZ/5c+9z2CTT0HYtZzU3Fw3148N+9/2HD4FD7//HO0uY09ZxivrBAABEacql0OaMbKwANCrjLr/jwZeIBABu4viHFpq/npBUIZOLteaeQvC4NGwoCo9W6zFEOSHo89/hiNRkyfPh3Jycno3Ll+mW1FRQW0Wi3zIpouRqMRy79dgS539sJXy78Bx3G474H/w+4jJ/Dwo5Ph4+Nj/yCEXWLjE7Dsx3V4Y/4CqFQqpKen484778Q3qzdQ0VWpUCqgSk5AyJgOUCUnAFbarzQmPDYzmjJlCk6dOoUDBw5Y3WfevHl48803PTUkQsac/OsMps55D0d/NyVldrqpIz5a8C6SeqRIO7BGikKhwEMTJ+O+u4dg0mOP4dixY5j0/GvYsH0PPp37OqIjI6QeYpNBk5qE6Hkp8OM1TazK1iF/Vjp0aY03rueRmdHUqVORlpaGvXv3IiEhwep+s2bNQnFxce0rMzPT6r5E46SwpBRT33gP3e+diKO//wW1Ohjz//smju7fi7uSe0s9vEZPUlISdu/ahf+8+Sb8/HyxccdedB0yBuu27pJ6aE0CTWoS4penwjdWzbzvG6tG/PJUaFK9o8WJM7i1HBDHcXjmmWewbt06pKeno127dvY/xIPKAbke4bcozB3irwtL+sQEshPpls0tDeiibhHkCnVgu7byW4DzY0IAwCXeDI7jsGLVWsx6cx4Krl0HAIy5fywefWkOIqMtxxK2AD952RIX+ieTje0Iy/iUFFlyXUqL2JiGsIxPVbklLiTMHaoT+6m2Lpzgx4yEKH3ZOJuPvyUXyy9IcDMKZNcDeKWFVKFsTpImnC0lFB5pKf9zcwJbjuXWePazt/BiStorZzD1ycn4+5QpNvTQuPvw/tw30azmfMpcS5pG5Vm2NUXxGbbwbdE5Xk7SJfb/SdjevJhXbqm4io3eaOuUEjLylm23M+evC8sICWNIksSMlAok/T4JvrH1t1rhjByqc3TI6Lq0ttq9NyCLckBTpkzBd999h++//x4ajQZ5eXnIy8tDWVmZ/Q8TTYa//jmDQaPHY9IzL6Dg2nW079ABazdtxmdfLWMMEeFZOt9yC7bv2Ydnn3seSqUSK35agzv6DcGe/dZd7YTzqHrFwy9eU3/PLwAKpQJ+CSFQ9Yr38Mg8g1uN0eLFi1FcXIyUlBTExsbWvn788Ud3nrbhNMHgoRTo9KV4+cOvcOfAEThw5DhUQUF4+9WXsefAYfTp28/t51fCiF4RZzA67jiSoy5AqSANlZCAgAC8+sab2LhtB9q0aonM7BwMv+9BzJg9B6Vl5fYPQIjGN1pcXy2x+3kbbhUweKMSpzEGD+t94lAqENQrHoGxahjy9Sg/nA0YOZvdWwMF6wEhFjdTs9asmy5m8ABm3SfJUhWhPKItVq9ejdmzZiI3NxcAMGh4Kmb+Zz7iEhJxMFsHwCT/PZnFunT+uFLErF/llfHRCapp6wtvMOv8Mj5Dmx/B/B7bER9sUWxmlajx8qGB2HixvU25tiNwAvk2H+Fx+fsKP2ew4RoUbqvTUbbMIp0uLbUtA7/Kk4nfyqsG7tuiM9btOYx3/vMavl/+FRZ9sRQ70vfjyyWfo/uddyJAw6ZrhIf9yawHRljcM3Vk4KECGTiv426gwIXnX8F+L47IwPmuOTtVhpjfjKceUarzxRUDELuft0GBGB5NJXioTk1Cm98nocWmsYhaMhyxG+5H4q+PQjWirdvPnZNfgPvG3IuJEx5Bbm4u2rRpg8++W42Pl65AXEKi288PACPi/8DX/VchVsWmDsQFl+DbwRtwT+uzHhmHtxGsVuM/736ApSvXIjomFufOZaD/wMF48z//RWVllf0DEDYpPZyNqmxd3W7INXBGDlVZWpQezvbwyDwDGSMzSgWi56UAQB2frXk9em4/r3fZqVOTEFePwfWJVSNqWSoC7nafQfpp0zZ0HTwGO3bsMLl/XnsNx47/gr4DB7vtnEKUCiPeum19zbJwm+nf+b33kMvOBn0HDMKW/Ucwbuz9MBqNmP/ue0ge8whOnfFOz4FsMHLIn5UOAHUMknk9f/Y+rxIvOAIZoxqaRPDQV4nohQMBhXWDG/KW6w2uvqwCDz/zMh6a+hIKi7Xo2rUrDhw8hJkzZyEwMNCl57JHz+YXEK8qtvonKhVAolqH5Lgcj47L2whtFoavly3Fd998jYjwcPz612l0v+chvPfZchgM1l2ThG10aRnInpCGaoF7sjpHh+wJaV4bKhADtZCoobEHD9WpSYheOBC+kSqr+yiUCvjEaxDYKx5Vh7LrxIyCfIQxo4Da5cAIViLsE21yuXEchykvv42VW/bAx8cH055/EYP+PRWFfn44VNNm4Ldc62V8LgtK/Ngq48Mv4QPUX8YnvLk4F0dUQBEMla5N9BTKvIVxIVsxozpy8qpKq9sMlTZaU1Sw1bn58SQAuFFivTVFgUAG3iUmBLcMHIWfdvfEu7OmY/u2rZj1zsdYv+84ln00D21bWco+qXmtKfwFrSkCmp1n10MsDwL+arYrsH8OGy8JKraMUVi+Sijt5l/PjrSb8DS6tAzotpyHqlc8fKODUZ2vN7nmGumMyAzNjGpozMFDs2vOJyLI/s4AlFGuM7gHTvyBlVv2wNfXFz+sWY8XZ70KXz8/+x90E3ml4v62vBLrRptgaR4VjRU/rsLHiz6FWqPB0SOHcWf/u/HlN997pYhJFhg5lB7MgnbtGZQezGr0hgggY1RLow0eKhWIshILs4axwHUGd/uB4wCAUWPux139+rvsuM5yKC8RWSUaq79tIwdk6tQ4kB3t2YF5OQqFAg89/Ah+PnQUyX3ugr60FFNefAWjHnoUufkFUg+P8ALIGJlppMFDe7EwPpyRgyFbh6ojrouX7Dl6EgDQt/8AO3t6BiOnxMuHB9UsC7eZ/n1xXzKMHP00nKFFy5ZYn7YF7775KgIC/LF9dzpu7zcUP23fJ/XQCJlDMSMe5uChMM+oOkeH/Nn7vDJ4KDbGZXanlL6+Hz4cByjq5hmpAtjLJTDMIj4IjhW0BQmJQlGxFif+Msmku/a8C8U1OSKHeCV8ACD9r3xmnV/GR5g7JCzjU6W3xJT47b8B62V81p2Ox4Plg7Ew5RASNJZzZeuC8fzentiQYb1+YkOwlXMEsDElezEjR3KS+N9DdSWbg1RVwf6/8dubl9hpTXGDF2/qFMmqM8dOeQldB92D559+An/+/iv+NesdrP/lHD56fyGim7GtKCLqtKb4u3Y5oBlbnzIghI0LKs5ZrqWyq4J4oo+w3QQ/J0k+MSLCBBkjAY0teCg2xmW8VoYbL+6Gz/aL9ncWyb4jx2E0GtGhbWtEx8a57LiuYENGa2w63xJ94vMQE1yKXF0gDmRH04zIhbTr0BFrtu3Covffw//efw+r16zFgYOH8MXcWRiekiz18AiZQcaoPmqCh40BcyzMVvFF4/UyZN/6JVBtrFMctSHsPnAEADCgT0+XHdOVGDkl9meZjKS9WQvhHH5+fpj+8mzcP2IIJk1+AmfPncPIR6dh8oP34t1Z06FRe6c6lXA9ZIwaO0YOBbPSEbc8FZyRYwySORZW9NIe+Bg4QKFgXHPC8j9+wawKLiiMV2W6ORvwN6ibY/chk3ih/6AhKOC5fPKKWPeZsLr29SyLK668mHXLVJez+Rf8rquGStvVtW0ZHM5YN8lVqTCiT0I+YoPLkKsPwoGshs2cFHZaefPH54gM3NZxhOv2ZODVlZburpUCGXhluXUZeG4Ce5zrpawM/OZ2t+O7rfvx0bw3seKrz/DFD+uw4/CvWLT4cwzpehezbwjPbRcYycrAffz+YtbLCi3nVReyY9BWs983v6o332UH1JWFM1JvOVT0bgKQT6IJUJKWgZx6EukMOSW4MWkzyjeft/JJ58nKzsHZcxlQKpXo28f7+hCNbncJ5x5fhV0PbMO3I/dh1wPbcO7xVRjd7pJLjq9UGNE3IRfjOp5H34TcJlHxITAoCC//Zz42bN6CxBYtcPnSJYy8exhm/mc+yssr7B+AaNTQzKiJUJKWgZIt5xGSnACf6ODa4qj+9j/qFHv27QcAdOvaxdT/ptDOB2TE6HaXsHLU3jrvx2tKsXLUXjywoT/Wn2vl9PFHJV3C+wOOMOKJLF0wZuzpiQ0Zzh/XjFJhRHJsNmJUeuSVBuPIjSRZxcLu6tsPPx8+ildmvowV336D9xd/hW179mPZx+/htltvlnp4hESQMWpKGDmUC2Nhbqq1t2uvSco7sH+KW47vLpQKIxYOOFqzLNxm0rEsHHAMGzNaOHWDH5V0CSvv2V3n/Ti1Hivv2Y0HNg5skEEa1fY83uv7MxLUlllwdokGLx8dgk2XOzp9XFcTEhKCTz5djBGpI/Hc1Kfw95lzSB5xP16dMRUvjekPX1/rTQkJB1AqvEaMRcaoESK8Rdb1h1vfxo8Z1S3/w86jgqKaWY4TEVO7bDQasWefqQFbvyHDURUQgny9ZWqUW8T69oUlaSpLLXLtihK2DUR1Getq5MdA6saIHHd99UnIR2JIqdXtSgWQGKJHn4R87M90rPGfgqvGwv6Ha48jPK6RAxb2P4JN51vA3tD5MSXz3z0q6SJWDN9ZZ9/YYB2+GbAGD20bgbQrnZhtdSTkvDJDhjoy8GbMegVPBq4TyMBvlLBut2u81hWded1kY7ulYNuB43jlxeewZeN6vPHuh9i8ez+++mwR2rdrhwB/tnahJo+NIQZftMQXg3LYayOwkv3b+Ne2MG3BXudXb8Tb2uHIZ+5ONBr+yLiMa9euQq1Wo3v37lIPxyFig8V1IRa7Hx+zobNZpDVEjz7x+fXvYAOlwoiFKYdqjyM8LgC822efLGNT4RHN8elX3+DDxV8iJCQUx0+cRPKAwdi5p66rlBCHN7bDIWNEuJxdx00KqD533QV/f3dFpdxDrl5c/T6x+/ERa8Bi1NZnZtboE5+HBI3etqHTlKB3jDxTFhQKBe4dOx47DhxFcq+e0OlKMGb8/+Hk3+ekHpr34aXtcMgYES5n97HfAQADBgyUeCSOcyArGplale3addpgHMhyvHZd27Bi+zvBuSKtMcHiDFiMSt6FfmPj4rFl/RrcPXQIqqqq8Oir76Ci0vlOu00Rb22HQzGjJoYwRuSjYN9gY0bsswo/rwhg20b4RplK6JSVl+PgH2cAAN2S+6Gw3OS3z9NZYghFOjaeUFVhPW7BXwbqaaXAW3cmRiTEyCnx/J4eWDlqL4wc+/BoNlDP7+nusHhBqTDisS5nwZnSueqF44AsnQo/Z0YCdh5ahbGeXJ24vlA5Wl8mH8tWKSHhd10tyOOqKreUEhLG/YTr/FJCBYL//wJee3MA6BYXgjkffIYjfbvjr4xL+M/yDXhr1gwAgKoFW6pJHWspF6TKYtuNhJaw49fz2pCXCdK0hL8D/u9EGE8S/s/LzfHpre1waGZEuJSDJ/5ARWUlomNikdS+g9TDcYr151rhgQ39ka1jZyjZumCnZd19EvKRoCm1aogAk5H66o/2Tqn0DmRHI0sXbHVGx3HAtdIAHMyRV1kma0Q0b4633vsIAPDhkqXIv3rNzicIM97aDoeMEeFS9hz+BQDQp18KFLbuvDJn/blWaLdkLAatHIaHN/XDoJXD0G7J/U7nF4mNF50vDLW/Uz0YOSVm7DGVXbLWQigiqAIj27iu9qC7GTJiJLrf1gWVlVX48rsfpR6O1+Ct7XDITdfEsSXtDgyyXqUbAIJjLG4ag8q0vOvIrwBMLrpinvstl9eRs7yUdZ9UlrLxDr4byV5JH1e45qxh5JQOy7et4agwwt7fVV9poU3nW+BGeQAiAutWM1DUSMff7bMfG87G186+bJYOsuMiNVRY/k/rysDZ41aUW2TgxQIZeFklW3YoPsRynT397DQcm/goPv/uJ8x45Q0ExrZi9lXHWyTKqovXmW3BBex1FVRl+U79lcKK3ta13MLfiOxl3zXtcOJtlACTYzscmhkRLqOwqBgn/zDVDuvRp5/Eo5EX7hRGmOkTn4/mQRVWXYEW6Xie0+fwNPeOHo2YmBjk5eVh7br1Ug/HazC3wxGWAKvO0SF7QhrlGRGNm8O//AqO49CuTStExbhmRtFYMAsjTMvCbaZ/nRFG8BErCRervJMD/v7+eHzyYwCA/y1aRG3MHUCXloGMLl/h8shVyH5sCy6PXIWMrktlaYgAMkaECzl68jcAQK87bnf4s0oY0TPsb9wTcwjJ0RdkmZzZUNwhjOAjVhKep3dcOi4lj02ahICAAJw4cQJHT52VejjeRU07HO3aM6a2ODJzzfGhmFETo66E1fq6jx9bH8w/mE1gVWqa1S4bVWE48tspAED3Xr1xrZSV9uby2kaU69ltg8MP4j+dViIuqKZk0C1Atj4EM48OxZpCk9tKqTAiOS4HUQFFyCtReW0jvPXnWmFjRosGt6aoL6b0c2YkMrUqxGvqr/Jg5EyG7+fMSHBc/S0obMm+GyIDr66M5O3Ljv1yKBuLvFBombm1ahYAZUhzjL5vLH78/jss2piO3kOG124PaW2ZgWvOswH5EoGLKpgn9S4RpC0IY0b8dXsxIv6RGt8jlOcgY0S4BKPRiF9OmsQLPe7ohhI7+5sZEHIQC1osrvN+rEqLr/uvQnW56cbz3l0/I0FjOaq5yvX6sy0aPHZP40phhPC4dnOk9vb0SiP+6BNP4cfvv8OarbvwTm4+EmKdj60R8sT7rkpClmRl50CnK4Gfnx9u6iguv0gJA16KXWJatlJP7ZP+e7Fi+FbEqVnzZq5y7ar+Qo2F9eda4YGNA5FTwiY0ZuuCG1wRXEpuvuVW9OidDIPBgCUrVkk9HMIN0MyIcAlnzplqiCW1bQNfX3GX1e3BfyHG33oyo1IBNA8qr7dqgSvaOTRWNmS0wqbzLdAnPh8x6lKvdmvyefTxp3D00EF88f0azJ46GYGBAVIPiXAhZIyaOMIcCj/eum8QGzPyDWZ9+z4aS27JmV9NZVnad+gILkCN4vIiZt9iXgzJ3M66WbC4rHq7UmUn2jk0ZjijEQYA+66YXFm22p3bal9uP8fLss4ZLMtKhRG9Is4gOqgE+WVqHC5oycS4/ALZkj5511l13wXeeucoS6mg2/oNRUJ8PLKys/HD7qP49/89AF9e3lFw/CXmOEGXi5j1EF7FAa0gblVmsF4Wq27MqPG1m5AD3v2oRMiGM6dPAwDat2sn+jNXq8Ls7yQCZ9o5EO5hZKszOPXAYmwauhxf9l2NTUOX4/cxH+DuuN8afGxfX188+dhEAMCiz5aQzLuRQcaIcAlnzpoktx07iu8mekLXCbmVETYTQcXgTDsHwvWMbHUG3w5ah7hgHfN+rEqLL7t/5RKDNPHf/0JQUBB+//MUDhw60uDjEfKB3HRNAKF8W+y+voHs5eEncNPxpd2na2ZGrdp1QJmBg7aCLfFSwisHY6w2WRkjlJh78TF81P4dq+qv62UBCAussClVbkjVgqaArdJCzrrwAFYGruCq8E5PU5dZa11s/9N5NTZfaofKUrbTb6mWLV90ocAiVjkvqOid0DIBYx94EN8sW4r3P/sC/T98tXabpsU/zL7q87nMOl/qHSwoV1QiKA/EpDgoxLvl5F7RW87QzMgVKBVQJScgZEwHqJITZNe0yt0UaktQUFAAAEhywE0HADsLe2HS4YnILWvGvJ+t1+DhnaMwZXcKAPdVLSBcQ3JcDhI0JTab+yUEF6NnZMMLtU5+8ikAwLbNm3HhiryKfRLOQzOjBuJtfebdwdnLphtCbFwcNBqNnb3rsiWnC7bl3IKekecRHajF5fxKHMpLgJFTorq8BP+3eSgW9DuABI0lAJ2tC8bze7o3uGoB4RpiVOJKDEUHaoEGhvg6dLwJKQMGIn3PbixesQbvzXq2YQckZAEZowZg7jMvxNxnXq4FCV3NmcumVtbt27d3+hhGKHHoqmlWVXqdfdrdcL4NNl1oheS4XEQHFDtdtcBVKBXGBldQaGzklYorMZRfHuKS801+8imk79mNpT9txJxnH4M62LtKHBF1IWPkLHb6zHNGDtFz+0G35bys60HZiicpBSVT/IJZoYBCZZoFnck2uehaJ7VHWU2Zfp2whQAvhlRdJejsakNCbF42ANifGQNjdYTV8XqC0e0uYeGAo0gMscwEMrUqPL+nh1fO0hyJJ9mKIf18pTmydMGIU+utxvdySkNwMDsG/s3Y9uulgpp6mTxp95Uidhp1NdKUzHtr8gAktmqNzEsX8e2OI3h8wsMIjGercajjM5n1wMuW86qvscfVVrN/axkvMFRptN4F1oT40kGEdZr241wD8NY+8+7gzEXTjz6pnfMzI29gdLtLWDlqL+I1rEsqXlOKlaP2NulqEEZOiefTe9csC7eZ/p19fLjLZpBKpRIPPfo4AODTL5c3Lpl3E41BkzFyEm/tM+8OLufkAwASW7aUeCTuQ6kwYuGAozXLwm2mfxcOONYoq42LZUNGazyYNrhuKaISNSbsG4+0K51cer7R4/8P6uBg/HPmLHbv+9mlx5YKTWoSkn6fhJabxiL+y7vRctNYJP0+CZrUJKmH5nbITeck3tpn3h1k518FAMTFJ9jZ03vpk5DPuOaENLQaRGOJQ23IaI1N51uib8tCxATrkacPxsHcOPipm7v8XJqQUPz7wXH49Mtl+N+SpRjw3FiXn8OTNPUYNBkjJzH3mfeNVdfrquOMHKpzdLb7zCsVUPWKh290MKrz9aZ93Rxfquvvtr5d4SOMhbE3R2VAEMrKy3Gt0OSLD4+OQ1lNDpG2nG0TUcmLGRmqbbcmkCNiqzw4Uw1CrnEoYTxJbE6SAcD+LL5B5qCosHwv1WXsA1qZjs0zKuHFic7lsQm0HSPVzPpjU5/D4q+WY+vO3bj47MNo19LyQKSOZ3sfBUflW5bz2QeLwEr2GuSXA/IX/L4NnBvKATWSGHRD8L5HL7lQ02cesPSVNyOmz3xjmY7nFlwHAAQGBSEktJm0g3EjYqs8OFoNguJQDaNtUhKGDB0KAPjf9+skHo3zUAyajFGDcLbPvHk67hvLPuWZp+PeZJBKSk1PsWq1BgoHKj14GweyopGpVdksXZSpVUGp4DC+4wX0Tcy1Gz+iOJRrePLpKQCAbzbsQLFObCcteUExaHLTNRhdWgZ0W86Ld7d50XRcKXTTCaTenNIH+gqTLDswKIhRNJUK3B58ObdB0AVUjLTboXG7If4ipnFdkJ8BO8Zvr33fnqvN3XEoV2NLBi5E+H/KX68uZw1GZSkr9S4rscwuL19jv5/MYoHUO0KFzj36om37Djh/9gy+3nUMzzz2CABA1YKNYWoSLC5zbZaW2RZazJYo0hssf2uZ4BKs2x3Zsix04YktD0QxaJoZuQYH+sw3tul4WbnJ3x8YJI9ipaPbXcK5x1dh1wPb8O3Ifdj1wDace3yVS9xd68+1wgMb+iNbx/6tN8r8oQAQHsjGPuy52twZh2pKKBQKPPLYkwCAT5d9B4NB/jFIIeYYtNDlb4YzcqjK0tqOQXs5ZIw8TGObjpeWm54oAwMD7ezpfjwVfxG6I5sFmsQajrraxMaX8kul/27lzuixD6BZaAjOX7qCbXv2Sz0cx2lgDLoxQMbIwzS26XhZmckYBamkNZ6eiL+YjV2cmjV2vkpOVANA8zj7JuZifMcLUCo4ZOmsx6HMfDV8PwkZ7KAKDsajD94PAFi09FuJR+MczsagGwsUM/IwLpGEuxCh1JvvDxdKeX38BJeLQomymphRQGAgI3E11Hm64y8LygHZ6CAqlr6JeW7PA7Jm7MQQG1xWr4T7WqnJxSeMQ/GJ15Rh5ai9eGBDf68pOVTn/5gXMzII4kl1pd6W7UWCckAZBeyNuhNP6v34tBfx4ZLl2LX/IE7llaBzQltmX3X8BctyNNtlWF/AXjtBVZYL1l/QXqJScG3zf0PC35Ojsm+HY9CNCJoZeZpGNh0vNc+MJIwZjW53CT+M3CtqX2fjL2axgbOVWdqGFdfrQgwPqgQH4EZ5gNXPkrJOHC1btkRqqilpdPHixRKPpgE4EINuTJAx8jRKBQyF5bjx2UkYrrM3Rm+cjpuNUUCgNMbI7DoLC6q0vzOc7wrrrBEzS74f62JKwLTmQrQnVBO6+4j6mfL00wCA71aswI1inZ29CTlBbjoPUl/vo+qrpShe9Q9Ktl7wyum4WcAQpPJ8CX9HXGcN7QrrjBEz/1d+9Ud7vNHnN6v7KRVAVHCF1e18SFlnm7vuugu33HIL/vzzTyzdsBMv/HuM1EMiRELGyENYqzvlExGE8CdvR9mRHNkZojrlgOrkGfmirMKkJAsICGKGX1mn5I9lozBG5Cz28nRqz+eCrrDmpNd4Tf2uOiMHGDkFfJWWv9PcADDAx3WuNWdndlLDjyEZqwQxozp5R5b1Ui2rJLxQwMaXLsVbjHOrZqZ9H5n8FF549mksXrsdzz03Db6+ptucplVc7b7q82xMVpvFzqKCSyxjLBFc98KYET8uVDdmZD3viByuLOSm8wR2El0BIHpuP68sFW920wUGeV5+LHaWUFgW0ODgvznp1bQs3Gb696GN/TBo5TA8vMn0b7sl92P9uVaiDQjHmV71nx/I1Do/s/MEfKVg3wT7FSjcxT33jUVE8+bIzMnD5t1eKPNuotDMyAOYE12twU90LT2Y5cGRNRyLgMHz0m6xN/kHN6Ug/Uqc/R3tYE56FSri7LVAtzerMmMWMlqr8ODIzM7TVcDrUwpm6YIxY09PbMho5bbz1kdgYCDuf+D/8Pn/PsZ3azZh1NABHj0/4RxkjDyANyW68t0Mwk6vQjcdlL4oranAEBAUyLgkhNJuo43mZ7ak3LZK0IhxnWXrgrE/M8bqMRxl/blW2JjRwqEbvXlW9eMocYq/wnJ/RPAEGfaMnRBPVwE3i0iExKn1WHnPbjywcSA2XbI0XrQn3edLv4VdgYvL2GrwebyK30Xlln0Hjx6Pz//3MTbv2Y+r1X4IDwuDb2yr2u3q+IvMcYIu3GDWQ3h5ftpq9hosM7AXm9Btx6ehUu+mBBkjD9DYEl35lJuNkYfUdMIn/hf2dMcPo9JdMpsQi5FTOpyrtP5cK7x5sKtNIYOZBzf2h5FTODWrsWYYzFUoXJ2rZC/Z2MgBC/sfweblSR7tz9T+pptxa+eb8cepv7Bm/UZMnviIx85NOAcZIw8gt0RXV2JW0wV4oByQtSf+9491xvibLjjkOpOC+Ue6YNKtZxCvKbM7k3Pmxi3KMAw4ho0ZLVxmGMQWe02Oy8XP2Z6ttzh2zGj8ceov7N67n4yRF0DGyBPUJLrGL08FZ+QYg+SNia58SstMIoKgIPdKu2098c/ofgoPbkzB9bJAWXdKNbnretqs/G2eyTkT85GiCrj4Yq/2VY+uJqlNawBAXkGBx89NOA4ZIw9hrjtVJ88oR4f82ftkk+gqLI/PR1lfOaAaN51/ICvtrlsOiOMt244ZCLeLeeJf0P842i25X3YGSIgYEYSzMR8pqoCLbzpo/WHF1vVgFMqoBfGbSt56pYHdFh1nEq3kF1wFfP2h8LfM3n0C2YoX/mo/Zt030HKtB5ZXM9vqtpBQ8JbFd4EV216iqUDGyIM0xrpTtdJuN8aMvK3vjz2siSAAYHavXzEn+bc6nxET83FXN1pbiBWRHMzx/P9LdGQUACC/oAAcx8H7EieaFmSMPE1N3anGQrk5ZuTGPKPG2PdHKIIwzYaOIDGk/r9BTMxHrGFwZa6SmKaDz+/tKcmMNTKyOQCgtLQUZWVlkF6rSthC3j6NpoxSAVVyAkLGdIAqOUG2CbGWPCP3xYykeOJ3FibxU0TrcYDfh8m2MbVXn05MYq471IWWpoPsNZCtC8YDGwd6PM/IjEajgY+PDwCgsKhIkjEQ4qGZkQypr4ZdVbYO+bPSGxxbsuXvFmK/HJBPrZrOPzCIiRNVCnz71jpYikGKJ35ncCTWYzJaeUhpkYNp3f6CArDaE0mIrRmgM4m5rkiQtZ1/5Vg0hG07bz32CADVvHVh6R34BiA8LAxXr13DjeISJPr5124StkMRtksR5tjxEeYOEa7BI8Zo0aJFeO+995CXl4cuXbrgk08+Qffu3T1xaq/DWg0731g14penyq6qd5kHpN2iXEFueOJ3BEfye0a3u4RPhxxEc5W4SuNC7M0AHUnMdWWCrDP5V+4mLLzGGN24AURKPRrCFm7/9f7444+YMWMG5syZg5MnT6JLly4YOnQoCkhuWRcvq2FXXV2NykpTRnygm6XdNl1BG/pjY0YLh91jrsKRLrNmoxUhsuUFH7H16cTOdDzVpl1K1GqTd6FE730J5U0Nt8+M3n//fUyePBkTJ04EAHz22WfYvHkzli5dipkzZ7r79F6FszXsXPlEwZYDYu+sQtdFWaXlhuoTEIAqXumeOuWAbEi7OYO4Kt7WnvjvSbqCc4+v8lj5GyFi1X4pLXLx6dCDDrnkzIidAYqd6Xg6QdaZ7r31UUfqzVuvEuqoFUqoalqblJaVA0qLhEHochZe63wXtT3XNtvp1fo2oB5XIlGLW2dGlZWVOHHiBAYNGmQ5oVKJQYMG4fDhw3X2r6iogFarZV4eQwaCAW+qYQegNscIAAICPFO12+wK+vF0G+zPjMU9SVckf7oXq+JbO3oXmgdVOmyIACBbp7JbyseRmY69zrWNpZlfcI0xKiv1fNIt4RhunRldu3YNBoMB0dGsWyE6OhqnT5+us/+8efPw5ptvunNI9eJOwYAjeFsNO3P1hcDAACicucM2ECnK39SHWBVfkJ9zrsPlf7bFk9v72PwbHP0uGqNcvj7MTR/15KaTPbKSds+aNQvFxcW1r8zMTLef0ywY8I1VM++bBQOa1CS3j8GMuYadNeUZZ+RQlaWVTQ270lLTjSrYzfEia8jl6d6s9rMnGHTGXhuMwNbziaJLAYn9LrxJLt8QzG46s9CGkC9uNUbNmzeHj48P8vPZm0F+fj5iYuqW9Q8ICEBISAjzcityEwzU1LADrEtaxdSw81GwL2dR+CiYl9LPl3mV1nR5VamCYDSCeVUbOebFcZaXq5DL072t/J6GolAAP4xKt+tudPS7sGdApWzmxxkNvBeYlxCDkat9GTn2xQEICjIZ09LSUiiUPpaXj9LmS+mjqH25Elf8LhsrbjVG/v7+6NatG3bv3l37ntFoxO7du9GrVy93nloUZsFAfZW0AVYw4CnMNeyqc9lWzNU5OtnKugMFdb48hZye7s1qv8Jyf/s7O4BQjWcNR78LqRJkPU3tzKjMu92NTQG3q+lmzJiBRx55BHfccQe6d++ODz/8EHq9vlZdJyVyFQx4Sw272ordHmgfUR9yS4Zdf64Viir8sWP8dpce1+xim3L731h0spPLSgE527nWmzDPjGQbM1IqEFTzO6+S6e/cU7jdGI0fPx5Xr17F66+/jry8PHTt2hXbtm2rI2qQAlkLBryghl1ZTSkgs2LJ08gxGXZ/Zgyul/ojwoGEVuHYrbFwwHFMv+OveiXrzn4XznSu9SbkPDNSpyYhSgbCKbngkStu6tSpuHz5MioqKnD06FH06NHDE6e1i7cJBtyBML6kVCpqXwqlkn35+DCv0nLTDTdIpUKV0ci8+L78uu0kjMyrIdhLhvX0072RU+KTk50c+sy1UvEzS1uSdWe/C6Fc3t2GiI0JGWAUvNixCeJAghdznXFgXkYOCFKZvBp6fSng61f7shUjEsaJXBWD5ROcmoQ4mQin5ELTrk3XiJveeQLzzCjIAzEjW1UF5PZ0P/9IF0zt9g8iAivqVdAZOZMBemFPd+ToVTiUHYkzk9dYdbHxsSdZl9t3ITUqlVnAICM3nVKB5nNTANQvnOKMHKLn9oNuy/kmde9p2sYI3tP0To6YY0aqIPcKBMRUFZBTXTQjp8TT23tj5ai94Ky4zKbu7MXMVKy52OrDXv8mZ78LVxRMlRuqILObTj7S7iAnK600dpq8MQK8RzDgLM66FurIWpU+zGpZuck4qFSqOh0tbXV6dQRHCpDKCUfFAdb2t4UrJeuuLJjqToTXkYHn5hWWCuIABAWbywGZpN1mhFW661aod5/22kemwimpIWNkxgsEA3LDnPQa5KaZkVwqLDiLoy4z8/5Tbv8bCwcct3t8V0nWvdXgi6F2ZiSjckAGOQunJER+v2DCazDnGbla2q1UGHFXfDZe6XHc5RUWnGl+1xAcFQcYOSUWnezksYRURyqOeyO15YBkZIzKSDhVLzQzIpzGHTGjka3O4J2eO5CgEf9UKNZd5S2uKE9K1sVWHLcWn5I75mtTTjMjGDlcm52OmGUknOJDM6Mmjo9CwbyUPsraV50yKb5+zKu25XiwClUGI/OqrGZfRiNX++IMBvZVI/Ed2fIffDtoHeLUjrknxLirvK13j6ck654oqaRUGNE3IQfjOmSgb0KO3VkWK/3nmJdR8GKl3YKXkUNAYI2arqzMFPOseQmvbVsIfyOukHrr0zKQ4yWVVjwFzYy8HV4Gd3W+HmWHswEP9Uwpc+HMSKkw4p3eu2uWxX1GbIUFb409eUKm7e6SSvXNRrN0arx4oB82XnB/Lk2QjFtIlKRloGTLearAUAMZIy/GWuuLa7PToffAk5WPr+nyKdE3/IfeOyYLCeoS+zvW4Ii7yptdUe6WrLuzpJI1YUScugQrhm3GQ9tGuN0gmR+UKioqYDAY4OPjY+cTHsbIoaxGOOWdUTnXQcbISzG3vhDiG6tGzLJU5ExIQ0mNQeLLroWdJssM7E+gotKSAV+hrWC3XbvOrN/WsS1+BHDyl+NIfZwtEBoVwibC+gdYLjUfQSM+pZ8/YkPYc9nDkfppcqnu3RDclQPkrviUmNnou332Ie1im4YMn0khMAqubSMAf96svaLagGB/03Uq7Fpsb51wP2SMvBE7rS84I4eouf1Q4uYM7ju6dAYAnPj9VIOPlV+qtr8TgLcPdcHeK7EO3YyddUXJJQnU3cILdxRMFTUb1ZQgOTYHR4rDnBm2KAJ5Ss+y8goEq7y7P1NjhoyRF6ISmcEd1Cu+1gXgDm675WYoFApk5uTian4eIqPr9qgSy6H8RGSXaBAbrLPpLvrvoa4OGwRnXFFyUd55KgfI1fEpsbPMmGA9UOzUKRymrMKx2TfhWWguKgalAqrkBISM6QBVcoLnmu1ZQS6tLzTqYNx2i6ko6MG9Oxt0LCOnxMtHh9QsC7eZ/n1+b0+nbo6O9u6Ri/LO0zlAriyYKnY2mqd37zW6dvUqAEBYWDiiwt03AyMaDs2M7GBNJCBlmXdHW1/w40QGjr2rVQruzsVVlphRuOA8ukw2uVRzIxuj+3bHyT/+woEdaXh8kqVHVZso1u12khdD8leFsmMILAQAbMu/AxN/DsTbt29gxAzZumC8sK83Nl5oDaCq/j/WDmJdUXJS3kkhvHCVa/JgTiyydMGIU+utz0b1Ghy+2gp+atZw+assHZ6DBbHHiHBW6t4hxrJvq2bscQJKCrBg3tsAgOeeegzK/Eu1V0/xxVxmX10OK54pK7TUsiupZo19maD2la2YbN11EFYgY2QDWyKB+OWpkuUDmFtf+Maq6+1Syxk5VOfoTDJvNzNqYB+8/r9lOLAvHTqtFpoGtorfnNUZ6/6ORHJsNmJUemQXKXEgO8YlN34xrig5Ke88LbxwpWvSyCkxY09PrLxnt1VhxMxDA9xq0H9atxHnzl9AeFgzPD15InDhmNvORTQcctNZw45IAACi5/aTxmVX0/oCqFs40rxe4KEM7pvatED7lgmorKzEnp07XHJMI6fEzzmJWJXREfuz4lx6w7LnipKT8s6TbdXd4ZrckNEKD2wciJwS1hWXrdfg4Z2jsPFi+4YM2SbV1dWYu/AjAMBzTz8BjVqcQIaQDjJGVjCLBOqbeQBsmXcpMLe+qC+Dmy/rdjcKhQKjB/UBAGzZtMEj53QnnjQA9jALL1xVo85aXT53xqY2ZLRCuy/GYeja0Xhk2xAMXTsanb9/3K2GCAC2rF9TOyt66rEJbj0X4RrITWcFuYgEbGGt9YXSxoxI6MMWxozKeet8vzkAlObeYNars0wGb9StrfEugL27diDIUAaVSoUWAv99M956oYbdVq5ln1p9yi0G1ljNtu/mBJ1AG9opVog7k0AdxZU5QLZccDfKA1zumuS3a+DggwO5LWvX/YKDwU899Q1i//8D1Jb4rEoQM2oTxf7e2oZbrqWoYNPtzGAw4IuPFgAAZkwcj7DqIqCoCCWXz9Xuq8++xhxHX8DGR7V6S2xSL8jFE/5m+OuOxISaepKrEJoZWcFRkYBk1LS+0K49Y2qBIUEpkduSWqBly5YoLS3Fjp0NU9VJjaPKO3fjihp19lxwI9teETUWOScF81m/dg3OnTuLsFANpvxrrNTDIURCxsgKpVTmXTQKhQL3jh4NAFi3br2kY3EFnipS6sh42i0Zi0Erh+HhTf0waOUwtFtyv6hxiHHBPdjpgqhxeMI12VAMBgPenT8fAPDcxAcRomlaDeq8GXLTWaNGJBC/3EVl3pUKj3WSrTP9Z6Sn7Cahy4EvWy3TszJqXa6OWS/PtjxR3zewNz786CNs3boF1fkX0boZG0vju1cKBMcpFWTgV+ktWZCGCvZpvK7bzj3ODk8UKXUEZ2vUiVEHRgWXo0AfgOaqCqddk8LOqUpff6vrvv7WpdwAK+e2JeUGWDl3cPkNrFyzDufOnkFYs1A8OeB2VF05W7udL+fWZmmZ4whd0nw5t1DKLfzNsKkTJOV2FjJGNjCLBIR5RtU5OuTP3ida1i3HXCVXc+dttyIuJgo5eQXYc+Aw4lPul3pIDcbdRUo9gVjX2g9/t8Uzd/zt9v5J7sRgMODtBSYF3fSnHkdIsPxncoQFeV9dMkCXloGMLl/h8shVyH5sCy6PXIWMrksdMkTxy1PhG8sGac25SppU95fR9wRKpRKjhg0GAKzbsl3i0RBmxLrWNp1vISvXpDOsWr8RZzPOW/KKCK+CZkZiqBEJOIyIgqbRc/tB5+aCpp5i9PDBWLx8BdJ27MGTc6vh60uXl9Q4og40ckpZuSYdwWAwYO7CjwEA056cjBCNBt7/i2pa0N3CjYgtaKrqFe+csXOCuj5t9g7FbykhLINSeo2NPeiuWMoDqQuz0bdDPMJDQ3DtRiEu//kLevW5q3Z7pzhLCaC/s1l/fUkRO2ssL7asV5WxeVTCWARf6u2u+JE346g83JZrUhgX4su3+cv1rfsEWGZotqTcACvntiXlBixy7jWr1+HMuQyEhWrw7Nih8C3KYqTcACvntiXlBlg5ty0pN0Byblch/0ceL8YbcpVcia+vD1L79wIAbNu8SeLRuA9ryaNyRW7qQFdjNBqx4J13AADTJzxACjovhWZGbsRrcpVcyOiBffDN+u3YlrYRc96eD6WycT3v1Jc8WlAagGd29sK6s60lHJlt5KYOdCXr163FmdP/oFmIBs88Mk7q4RBOQsbIjYgtaNqYcpUG974TzULUyM3JxuEDPyO5bz+ph+QyzMmjwv/JKFUFVt6TjoXHrmH2/jslGZsYnFEH8qt455UG40C2vAyYwWDAu/PmAQCmTxiPUA3VoPNWyBi5E1fnKrkBW+WBhGVQygvZ5mSleZbyQNXZ5wGYLqj7+9yOL7fsx6afVmD0kBQAQLsIi4soKZq9YRRdZWeG/Lyj6nI2ZiTMM+KvuzNmZE4eVQBQWKmN+3z3Uzie2xzrzsl3hmQPflxodPsrWJhyCAkay/9Plk6NF3++CxvOt2XiQj6C3CHfAMF6oOX/XJhXFKRm44D83CJbeUUAsO2nb3D2zGk0Cw3FUwO7Wc0rAtjcIlt5RQCbW2Qrr0i4TnlFziOfR5xGiq2CplK1oHA3Dw3uDQBYv2EDioqKpB2MizAnj1ozRAqF6fXJ4COyjyGJYVTSJfyQuhNxavZBIU5dghXDt2JU2/MSjcwCP69o2lOPIVStsvMJQs6QMfIADc1V8jZ63NQGN3fqhNLSUny1dJnUw3EJYpNHo4LL0Sch3/6OMkapMOL9AUdqloXbTP++e9fPkhvdbZvW4fTZc2gWGoopkx91z0mUCvj1jkfA6Pbw6x0veZfnxgy56TyFs7lKrjg1f0XgRhC6FfjrwjIo5TrWTVeSa3F7VGZfZrbNmPQQJj3/ChZ98jGmPzACbcIsyb0d41jXy9k6Um/L9god69ITSr1ZebH7Kno7UpdNbgVF+a43exJshdIHd8VnMa45IUoFkKgpQUpbHQ7mm1ySfDccAPgGsYq2AHV47XJwaCCzTd2MXefLua1JuY1GI5Z8aKrM/dyEcYgwam1KuQFWzm1Lyg2YXHO+w9si6L93ISiOV30lWwfj7HSUbhY3M/T+ObLnoJkR4RYeGHU3EmKjkVtwFd+t3Sj1cBrMgaxoFJQG2N8R3lFQ1BYxKuu17PhEB5XY38lNbFi/zq0KOt/hbaH6YjgUMYL2JrFqRC1LhWpEW5efs6lDxohwC/7+fnj2sX8DAN7/fDkMBoOdT8gbI6fEMzt7geMAzkqQ2tFmd3Ilr1Rc7CW/TBrlmtFoxHvzTQq6ae5Q0CkVCPqvKWHbWpfniLdTyGXnYsgYEW7jsQfvR7OQEJy9cAm7tm6WejgNZt3Z1lh4rHO927ypoKg9DubEIUunttlhNqtEg8MFLevfwc1sWL8Op//5ByGhoXjWHXlF3WOhjLPd5dk3QYNAibo8N1YoZtQU4LWvMOTrUWajfQVfxiqUtBZXsR7w8GuW2EjReTZXKrDDPwgG8NS9gzHv6zVYuugDTBh/LxQKBTpGsk+yvwuk3sXXLW6isiI2vlRVWsysGyotY3B3F1gAmL3/ThzPbY5PBh9GVLAlhnatNBDP7OzZoGoG/Jwee0mpjsaBas8hKKdkrWzPrOPD8XX/VVZLCL32x/0ICE+ofd9fFco/TJ24EL/ET1gEG09qJ3CF8eXcQil3UOk1LJj7FgBg2hOTEFyUi6oik4TblpQbYOXctqTcPs1VYL+l+lFEqWDgOJJzuwgyRo0ca+0rCmalo8QDar4pY4fjw5WbcOLECezbtw8pKSluP6e7WXeuNaCAySCpTAYpKrgcCwYcAweFUwbJVltwKcr1bLpyEyb+/BDmdktDfLDlASC3rBle/e1ebMnpAl8JQmNrN27GP2fOolloKKY+/ihw+YTLz8EViIuZGRpR5RQ5QMaIjwcb4HkCc/sKIb6xasQtT0XOhDRUbnFvvkhkWCgeGdEfn63djoULFzYKYzS63SX8cE96nffNbbwdrfdmruzg6PGUCiP6xOcjVlOOPL0KB7JjXOoi3JzVGVuzO6FX5CVEB2lxtbo5jlxtC6NE3v3Kigq8+c5CAMCzTz6GZqGhbqnMbTyaA0OODsoY25VTyhpR5RQ5QMaohkbXAE9E+4qouf2Qte2C2w3uc/93D77YsAu7d+/Gr7/+CoR7rxLJXhtvIwcsHHAMGzNaiDIMzh5vVNIlvD/giKA6QjCeT++NjRdc1yPLyClxsKANgLpVFjzNl4s+wtmM84iKbG6aFbkLI4eSV/cj5Mu7rVZOufaKtJVTGiNkjGB7BhG/PNUrKyWIbV/h3zMOZbz8JzbPiPWrC3MxSnkxI92VAmZbxOXTtcvxAMbdczd+WLcJH77zFv67ZCWz702CvKOLvLbkJUXNmG0VukJmvZrXllxYKsgdeUdi2ngnhujRJyFfVB04scfr26oQP2ebAuaj2l7A9yN219k3Tq3HD6k78fBOFTZebF/7Pr99g48gZmQrP8hPsC1Q0Dk1SGM5lrCkTzNBrIefO8RvJwKwpaIAoDUv7yhW7QcAOHfuHD7/yJRX9P6sZxBh1AJFbG6RrbwigM0tqi+viE9JWgaqJ21G6Fv94Mv7HRlySnD1lXTordwPKK/Iebxb9uMK7MwgACB6bj+vk3GKbUvh46H2Fc8/NQkAsCZtO65cuuCRc7oDsQmtrt/PZLCUCiMW9DtQs8zuY16f33uP5NURXIler8fUqVNQUVGBwX164IHUwR45b/nm88jvtgy5o1aj4PGtyB21Gpm3L7VqiIiG0eSNkXkGYUvGaW6A502IbUvhqSDsrZ06YPiAvjAajVj66SceOac7EJvQ6vr9TLOH5LhcJGj0Vp+NlAogUa1D7xhpqn24Er2+BO8vXIhOnW7CwQMHEBgYiEVvvACFtQKB7sDIofxgFvRrz6D8YBa55txIk3fTNdYGeGLbV5QcymZKBBmsLAN1ywPptRZpszZTx2wrOnuFWY9KOosXxg3D1j37se7HFfjvnNcQFW1KDr0pSiD1jrR813UqegezLj1+VW++zBtwj9TbkTbeQN3uqHwUSh8cyktAli4Ycer6DYyRA7JL1Dh6ox18A5WIbybub2gR6Yug8hgArOtNKMEWut4Cg/1ql/lybADQhLBy7ZbNLe61NoL/w1ZhrOstkSf1jhG49GKC2dtQRdY/WLz8e3zw2Ve4XlgEAGibEIv3nn8c8dpMlP+ZWbsvX85tS8oNsHJu4bVsqzJ33SrdINxAk58ZNdoGeDXtKwBL0NWMeb3Aw+0r+tzWCT06d0BFRQUWL17ksfO6EnMbb9OycJvpX0cSX42cEs+n97Z5vJcO9Ks9Xl6puIei/PIQ+zvJDK1Wi/feexftegzEq/MW4nphEZIS4/DlmzPw59olSO3XQ+ohEm6kyRsj8wxCeMM2wxk5VGVpvbIBnq32FTkT0jySZ8RHoVDghX+PAQB89cUX0Gq1dj4hT1zdxntDRms8mDYYOSXs7CK7RI2Hto1g1HGH8hKQVWKnOkJpMxy51sahMUjJxYsXMef113Fzp5vw5htv4EZREdq1aYWlH72DP9Z8jn+PHARfXx/7ByK8mibvpvOGBngNQZeWAd2W86IrMLibkX27o337Djh79gyWfvUlpj83Q5JxNBRXt/HekNEamy+3Q3JcDmJUpcgv0+Bgblyd4xk5JV4+NBDfDt5gvTrCr6NkX5Koorwce3dux8pvl+FA+p7a99u1b49XnpmM8aNGwMfHB8iXvm8S4RkUHGet7KP0aLVahIaGYiIS4e/qSZwgwdUnPBDRcwV5Rlla5M/e53WybkcQfqv+vLubvyCIEe7PPp1GB1jWE2PZp/r47nHMeou7k2uXV+YAj02fiZioSJw9uheZgQnMvqv+zKtd3nmSnZHmXGCl3SX5ltYVZYV5zDZhl1hDJRtDcBZ7cSA+/PI7trYBgNLPsu4ryOkR5viMbH0W/+38I+KCimrfyykLx5tnH8be0hRm30CVJQ4ULIgDCcv2tODJrNsK4kAtwtgx8Ev1xAriQJEq9jk3qFKLyspK7N73M9b89AM27EiHtsTk+lYoFBjU/VZMHjUYqX3uAFdgiQnpLmYyx9EKS/5csXQb1maxcct84XpFde2ysLSVsDxQJYDAXvHwiQ5GVV4J8wAnjBk1Ht2ie6iEEcuQieLiYoSEWHcfN8mZkdUE19npMNwobzQVGOTKA/eOxBvvfoisnDysWL0eff81VeoheR1b827D9rwu6BFxDnGaChRUNMOxwo4wQokAaYpp14vRaMTBgwew/scVWLdxM24UWh4m4mOi8NDouzFxwB1oE2+pdF5d34E8SOCItogW5BdVZetwbbb1/CKi4TQ5Y2QzwXWZKcFVu/aMBCNrOvj7+2Pa44/ixTfmYuGnXyD5wadMLhnCIYxQ4vD1DvDTy8j6AOA4DidPnMCa1auwbu0a5OTk1G6LjorE/cP6Y+yIIejd7VYolUoYci9KOFqWwBFtEf7ViDrv+8aqEbMsFXkT06DdRAbJHTQtYySiRE703H7QbTlPMyI3M+lf4zD3w0XIuHgZu7amYWjqKKmHRDQAjuNw5u+/sGXDWqStX4PMy5dqt4WEhmJM6t0YN2Y0Uu5Khn9JnvUDSYlSgdC3+gGwfn9o/nY/aDfT/cEdNCljJLZEjqpXvGQtwqWGza9gtwnLA2mrLT9Y/XU2x6c4k1XKac9Z8o4i21+ABsDT40bg7SXf49vFH+GR8ffVJjPy847+aM5KmfntJQCgXGvZ7lPKxjSE5YH4eUf2cpAcadHAj/3YigPZK8XjE2CJ3wjzgfxVrHKPX35HpWGPqxLkAyXy4kAtBd9nG0EpHn5+UJzguM2D2NtFcLUOZ89l4Ke167FmzVr8k2GprKEKDEBq3+4YO6gPhvXuBmXBFQDZ4A78hKLsHOY4JdlXBeuWsj76fPb/u/SaYJ133QlbiWtttImoL68ooEc845oTYr4/BPWKZ0poEa6hSRmjxprg6q08/cAoLPx6NX49eRIHft6Pu/r2k3pIhAiys7Kwds0qrF/1I37748/a9wP8/TEsJRnjRg7D3be2QnCQxShW1XcgmSG2NBbdH9xDkzJGjTbB1UuJCm+GCaOG4rOfNuHD9xeSMZIx169exYbtm7BuzWocPnSw9n1fX18MTOmL8cP7457BKQgNMc0suILL1g4lW8SWxqL7g3toUsZIbIkcb0xwdQdCN53QtcF3e9yoZN1eamHF5EsWSW7ohb9ql5/pfyu+WLMFe3fvxpkje3F7l1vQMdLiouooqOidW8DKtfXFzWuXq/Ssa1DoiuO714Slg4TYkmTzq2ADrPtNKMG2VQU7QM26hPileIRVsIMFrrd4G663toJ1fimeBMFxIlXs36YxWtxgxVf+wLqtu7AqbTv2HjoGI8+V2ee2mzGuV2eM7t0VzUPUKMvKBA5sgvl/QOh641fULhHczIWut/JCS5mpcl0Fs00oyS7nXZN1u7dar8xd101nuj9UZ+vgY+f+oKf7g1toUsaosSe4eiOtoiMwbvRI/LBmPRZ8shjff/mp1ENq0uh0Jdi4eQtWrV2PXXvTUV1tEVrf0akdxg3pi/sG9UFiTCSqc+SjgnMJRg7XZ6cjapn1+4OnS2g1JZqWMYKlRI4wz6g6R9foE1zlygvPPIUf1qzH2k1bcPb8BaDFbVIPqUlRUVGB3Tt3YO3qVdi+dQvKyy3Jwbfc1B7jUodi7MhhaKNq/Dfh0s3nUTAxDeFz694fCmbv83gJraZEkzNGQN0SOZTgKi2dO3XE8MEDsHXnHnz46Rd4dj7NjtxNVVUVjvy8D3u3rMOWtE3QFhfXbmvfLgljx4zG+MF9cFM7S4077uqV+g7V6CjdfB66LecRVFOBoTJP2hJaTYUmaYwAAEauycq3+dQpZcJZXYGBY/3ofJ+83sCWyOF3gQWA4stFtcvNzl9itkW0P4+X/nUPtu7cg+9+XIXpr/0X0TXtJTrFsHGVvwTxEC1P6l1dHs1sE8qsq0otN9xqwTYhvvzuqDbiQAAbC/JXCbuj8uNAbCkedTM2fhPDK7dTJw4Uya634MWBEkOFcSD2Zx2iMEncDQYDDm1fgx83bsW6rTtr2zMAQFxkBMYP64f7urXHbW0ToVAoUJ5xBLqMI7X72IoD6QWxPOH/P39dGAcSxnr0vFikMO5jq/WDrTYQwu3CeGidNhFGoOQA3R88SdM1RoSsSL79FvTs0glHfv8bX362GK/MeUPqITUKOI7D0ePH8eOqNVi7fgPy8vNrt0U1D8d9A3pj7JC+6N21E5RKJapzLkk3WKJJQ8aIkAUKhQIvPPoA7p/2OpZ99QWefW4GNDaKKhK2+efvv7Bu9SqsXb0aV3jVEMJCQ3Dv8MEYN3IY+vW6Ez5FOdYPQhAehIwRIRtG9u+Njq1b4PTFK/h62VJMnTZd6iF5FRczzmHrxrXYtWkdzpw+Xft+cHAw7kkdgXH3jcGQ2zvA39/iOqQoCCEXyBgRohH65H14ISSh37+wwnrekbANQAgv7+i5e+7CEx+twJL/fYznH30QHZuHMfu2i2FjMsV6S8kfvwD2ci4pYuNN5dqi2uUKHduKgl+2BwD8VSG8ZetxIICNBQlbNEQxcSC29E6SoEVDYqhl3xaCOJCwFE8zX5Pk+vLly1jz8ddYtWkrfjv1j2XMfn4YlnwHHhjeH0PbxUAV6A+gCOV7V4FfJElvqxRPAduCQViah9/Wu0LLxoG0grwzd8WB+B+11x5cuN3WvnyoRYRnIGNEyIrxfe/AW6v3IjM7B9/9uBo9xk6Wekiy42pBPr7fuBo//rQax44fr33f19cXg+7qhbH9e2BU/94I1ZhED40uH4holLilHeSlS5cwadIktG7dGkFBQWjbti3mzJmDyspK+x8mmjT+fr6Y9vQTAICF/1sMg8Fg5xNNg6KiQqxc8S3Gj7kHXW9qh+dffBnHjh+HUqlE/+SeWPzOm8j8dT82frsE/75ncK0hItyMUgFVcgJCxnSAKjmBbb1LOIRbZkanT5+G0WjE559/jqSkJJw6dQqTJ0+GXq/HggUL3HFKwkUwLgmB68JH8DvjuzaE7hRhxWS+tJffnRMA9BfYJ/fJw4dj7rshuHDxEn5P34qRo8fUbhvUPpLZN5bXbfTkJdb1djmPdTMVX7O44kqKWHGE0PWm4rneVALXW6Sg4ynf/dYmknW98buhtmjGfq55EFuKJ9zf8h36FOdCV1KCjdt3Y9XGrdiZ/jOqeNUQ7uzYGuP798CYu7ohorwYQBVwfAvKwLraAFaSXZJbzGwTSrDLea43vhsOqOt647vX9DZK7wj3tSW5Nm2H1X1d5XoT4owrzmqTzlnplDzvBG4xRsOGDcOwYcNq19u0aYMzZ85g8eLFZIwIuwSrgvD0Q/fhrU+X4X8ffYDUUffWtpdo7JSWlmLrtu1Ys/J7bN2TjvJySyymc7s2GDcsBePvHoAWSosRqcwuru9QhBux2aRzualJJxkkx/BYzKi4uBjh4eE296moqEBFheXHp9VqbexNNGam/GsMFi79Hn/89isO7E/HXf36Sz0kt1FVVYWf0/diy7qfsCltM0pKLAmk7du2xth77sa4lG7o1LZV7fvV2eclGCkBgJp0ugmPGKOMjAx88skndmdF8+bNw5tvvumJIREyJzI8DBPHjMCn36/FC9OeweZde9G8eaT9D3oJBoMBhw4cwsZ1a5C2YR0Kb1hcly1atMC4kUMxflQqbu3UAQqFAopCqhQtF6hJp3tQcJwNp6uAmTNn4p133rG5zz///IOOHTvWrmdnZ6Nfv35ISUnBl19+afOz9c2MEhMTMRGJ8HeP1oKwgfAbF8aM/HlPhUE+7N6hfux6XKDluSe+JdvFNCG5Fbs+3DQLuqHTo88LH+BiZhZioyKx5L3/oP/9jzD7XtFa2radvsa2JvhV4L7640pR7fL1IjZWEtHMRhxIIMFuEcruy48LRQWzz3cRgZa4kKIwE0dP/IZVGzZjTdo25OYXWD4XEYb77rodY1N6oGentqjOYfsBORIHKrsu7I5q+VsrtKyISFdezazzJfrldeI+4lsyyCEOJMRVEu2QMR0Q/+XddvfLfmwLtGvPuOis3ksljFiGTBQXFyPERiK7QzOj559/HhMmTLC5T5s2lsKKOTk56N+/P3r37o0lS5bYPX5AQAACAgLs7kc0DcI1wVi/bBHGPTEdZ85fxMhHnsLEfccxb958qNVq+weQARzH4ffff8eq1aux+seVuMJrud0sRI17B/XF2OEDMKDHbeDyva8hXVOEmnS6B4eMUWRkJCIjxblKsrOz0b9/f3Tr1g3Lli2DUkkzG8JxOrVvi+NbV+HVdz7Cx199i2VLl2LP7t2YN38+Ro68R+rhWeVCxjmsX7MaaetW4+zZs7Xva9TBGDl0EMaNHoEht7RhqiF4Q2tugpp0ugu3xIyys7ORkpKCli1bYsGCBbh61eJSiImJcccpiUZMUGAgFs55GfcM6Y9HX3wDly9fxv89+CD69u2H5+bMRYdOnaUeIgAgJ/MKVu/YgE3r1uLP33+rfT8wMBDDhw/H+LsHYPjAFAQFmaorKAupLpxXQk063YJDMSOxLF++HBMnTqx3myOn02q1CA0NpZiRRFj9xpUKBPWKR2CsGoZ8PcoPZ0PYkEHty346MsASO2mhYV2xsd3Y1g+Rt7asXQ6/qRWzrTKhI977ejXe/3YtKiqroFQq8di/HsAbLz+HgMROzL6Xi9n4yCleeZurenabMAeoNW89UsXmIPFbdefk5GD9D99g1fpNOHri19r3fXx8MKj3HRib3BX39OmGkOAgVOdeYo6ju5LPrPPjQPrcImabXtDGnZ8DxG/TDVAcyFPUm2eUpaUmnQLExozcYoxcBRkjaanvG1enJiFK2CU3W4fiV/ehfLNFbuwuY+Tf3tQF9lJOPmZ9vAxrdh0AADQLDcFLs17Fo5Mfh5+fyXi4yxj5lBdj3bp1WL16Nfbv31/7gKVQKNCv+20YN3wA7h3SD5HhYajOtST0kjGqH281RgBMFRioSadN3CJgIJo26tQkxNWT6OcTq0b4VyNwY9JmxiC5k1Zx0fhh/kz8nKnDjNf+i99P/Y3ZM1/C8mVL8fa8+RgwaLBLz1ei02Hnti3YuHYV9u/djWpeNYRed3bD2NGpGDPybiT4U+SnSUFNOl0GzYwIcSgVSPp9ks2grSGnBDndlgJGzqbUmy/zBoBIQTVrTaxFKRfWhq3a3ax9IrMe0jEJBoMR3+w+ijd+2IZrhSaZ8/C+PfHOewvQvl1S7b7XYanXJnzKF1bF9tdfRWlpGbbt3oPVq1ZjS/pBlPGqIdya1BLjB/bG/QN6Ip6zzFpKMvOY4+gZCXYRu02gtirlSbKFEmx9KWvk+LMdvUGa2Q67Tfy+9pB8tkO4FJoZES5FTKKfb4IGAT3jUXHIs0+KPj5KTBzSCw/8+2H8d/HXWLRiLbbuP4KdySl4ctJEvPLy8whr1kzUsSorK7F79y6s/f5bbNq2E/pSi4Fo1yoR41OH4P47O6Jjq/ja96tzScJLEA2FjBEhCt9ocVWgfUTu5w6ahWiw8OWpeGL8KLz03qdI23sI//v8C6xcvQZzXpmJUQ8/Dh8fnzqfMxgM2Jd+AKtW/YSNGzagsNBScLVliwSMHZaCcXcPwm03m6ohVGdf8OSfRRBNAjJGhCjEJvAZZJDo175VItYvmodt/+Thxdmv4Z8zZ/HMjJfw2bLvMGHSZDQLC0Og2jTL2719KzavX4erBRYxQXR0NMaOGoHx996DO2/vCl9dnrVTEQThIihmRIhDZMwo83ZTzMhfsA9fXScsFRQiUN6F+1tmL+ooNp4UksD6nJu1jrB87qaWzLbgjp1QVV2NJZv24q1vNqCohC2TwydME4x7+/XAuEHJ6Nu1E4wFlmoIpYI4UImgO6o+zzKTKhEY47LrllI8wpYMjsSB6rZkMFrdJozX8Lc3JA5Ud7vNzQwUB2q6UMyIcC1GDgWz0hFnI9Hv+ivpspO1+vn6Ysq9gzF+QE98uOMX/HXmPLQleuhK9CgtK0eP2zpjXOpgDGwbA38/y8+Bbp4E4VnIGBGiKUnLQM6EtLp5Rjk63HhlH0o9JOt2huahGrwzc5rlDY41NwZqzd04oLwfr4WMEeEQJWkZKNlyHkG8H3xZPRUYCMLTUOdV74aMESGa2rmEkYP+YBYTxTPYaEkOsDEOYSyiTLAzP14Skl3CbBNWG+Dn6ghbKYQJKhyE32RRwVVq2fhR3TiQpb+QPl/YkoFd58eCyvRsHKi4ytKqu271A4oDuQrqvOr9kCrAkygVUCUnIGRMB6iSE4B6hAAEQTiInc6rABA9tx/93mQOzYw8BLkQCMI9UOfVxgEZIw/QFFwIttxIwu119zUI1i07CEvb6AXrYbyioHWk04LioiXZ12uX+d1PTeviXW98CbZwTELXm2OleKzv2xRdb2IRm5Atdj9CGshN5268wYVA7kPCi6HOq40Dmhm5Gbm7EMh9SHg71Hm1cUAzIzcjZxeC2X3oy6uSDVjch5rUJCufFIFSgaDkBKjHdEAQzbYId1LTeRWwJGCboc6r3gPNjNyMbF0IdtyHnJFD9Nx+0G05b/VHzI8v8J9q6mvAV5Wtw7XZ6dCnZaBSEJjwqSML50uc2Y11y+JY1oWxnHBBrIcv0S7XsRLx4irn4kDCdVtxIHsN52y1bxDS2ONAjqJLy0D2hLQ6s/zqHB11XvUSyBi5Gbm6ENzlPrTWgM83Vo2YZanIm5jmsQZ8RNNCl5YB3ZbzVIHBSyE3nbuRqQvBLe5DpQJRdsQazd+mfA/CjdR0XtWuPWN6iCJD5DWQMfIAZhdCdS5bTaA6RyeZrNsd7sOgmtlWfTNAwDLbCuwVX+92giCaLuSm8xBycyG42n1ohPjGelykiomtCGNG/PW6cRXrMSR7OUlBlQar+zqSH+RIrIfiQAQhDjJGnqTGhSALatyH8TZaQjjqPpStWIMgCNlDbromjKvdh+bZljA2ZoYzcqjK0qKM8j0IghBAM6Mmjkvdh07OtmxJnuvKvtl1vgtN2F1W6F7zUdiqiu2c662+7bb2tQW53oimDBkjwqXuQzH5HjQdJwhCCBkjwuXITaxBEIT8IWNEuAc5iTUIgpA9ZIwIj2MvNsJ0kK0zmRLfmsLWZykORBDygtz3BEEQhOSQMSIIgiAkh9x0hOMoFSROIAjCpZAxIhzCE834bMZZbNo8YUkfdqur4kBCKC5EEA2H3HSEaNzajI8giCYNGSNCHHaa8QFA9FxqD0EQhHOQm44Qhbua8TmKIy48e1WynT4PQRAuh2ZGhCjc0oyPIAiiBpoZEaKg9hAEqSgJd0LGiBCFq5vxEd6FJ1SURNOG3HSEOGraQwCo06/I2WZ8rsYoeNnbbutFWPBqFaVSAVVyAkLGdIAqOYEENjKGZkaEaMS0hyAaGXZUlJyRQ/TcftBtOS87lx3N5rwLMkaEQ1B7iKaFXFSUjmKezQkxz+ac6WRMuBcyRoTjUHuIJoNXqii9eDbXlKGYEdFooThQw/FGFaV5Nlef0AZgZ3OEfCBjRBCEVcwqSqFoxQxn5FCVpZWVitIrZ3MEGSOCIGzgBSpKId44myPIGBEEYQezirI6t4R533C9DDc+OwlDYbmsJNPeOJsjyBgRBCECXVoGMrp8hcsjV+H6pydQfbUUvpEqRDzdDS03jUXS75Pkk2/khbM5gowRQRBiMXLwCQtE+JO3wyciiNkktwRYa7O56hwdybplCkm7CYIQh5dJpiknzrsgY0QQhCi8MgGWcuK8BnLTEQQhCpJME+6EjBFBEKIgyTThTsgYEQQhCpJME+6EjBFBEOIgyTThRsgYEQQhGpJME+6C1HQEQTgESaYJd0DGiCAIxyHJNOFiyE1HEARBSA7NjIjGg1JBriOC8FLIGBGNAk1qEqLnpTAVAqqydciflU5BdYLwAshNR3g9mtQkxC9PhW+smnlfbsU7CYKwDhkjwruxU7wTAKLn9pNVvx1CJigVUCUnIGRMB6iSE+gakRhy0xFejVcW7yQkh9y68sPtM6OKigp07doVCoUCv/32m7tPRzQxqHgn4Sjk1pUnbjdGL730EuLi4tx9GqKJQsU7CYcgt65scasx2rp1K3bs2IEFCxa48zREE4aKdzpIE4+TmN26QkNkhu/WJTyL22JG+fn5mDx5MtavXw+VSiXqMxUVFaioqKhd12q17hoe0VioKd4ZvzwVnJFjbjJUvJOF4iTk1pUzbpkZcRyHCRMm4Mknn8Qdd9wh+nPz5s1DaGho7SsxMdEdwyMaGVS80z4UJzFBbl354tDMaObMmXjnnXds7vPPP/9gx44d0Ol0mDVrlkODmTVrFmbMmFG7rtVqySARoqDinTawEyfhjByi5/aDbsv5Rv99md26vrHqel11nJFDdY6O3LoSoOA4TvTVd/XqVVy/ft3mPm3atMG4ceOwadMmKBSW/2yDwQAfHx889NBD+Prrr0WdT6vVIjQ0FBORCH9KiSIIp4h4oQeiZve2u9/lkauahPzdPEsEUK9bl2bTrqUSRixDJoqLixESEmJ1P4eMkViuXLnCxHtycnIwdOhQrF69Gj169EBCQoKo45AxIoiGoUlNQvzXqcyDoTWyH9sC7dozHhiV9NQbP8vSIn/2PjJELkasMXKLgKFFixbMulpt8lO3bdtWtCEiCKKB8NxzYmhKcRJy68oPqsBAEI0Ue9UpzDTZOAn1ZJIVHjFGrVq1ghu8gQQhD2TausIReTLJ3wmpoZkRQTQAOefuiHW7XZt/WPKxEgSpAgjCSeSeuyOuOoUO194/5uGREURdyBgRhDN4Q42zmuoUAOoYJEt1inRyzxGygIwRQTiBt9Q4o+oUhLdAMSOCcAJvqnFGMmbCGyBjRBBO4HU1zkjGTMgcctMRhBNQ6wqCcC1kjAjCGUSJAyh3hyDEQsaIIJyExAEE4TooZkQQDYDEAQThGsgYEURDIXEAQTQYctMRBEEQkkPGiCAIgpAcMkYEQRCE5JAxIgiCICSHjBFBEAQhOWSMCIIgCMkhY0QQBEFIDhkjgiAIQnLIGBEEQRCSQ8aIIAiCkBwyRgRBEITkkDEiCIIgJIeMEUEQBCE5ZIwIgiAIySFjRBAEQUgOGSOCIAhCcsgYEQRBEJJDxoggCIKQHFm3Hec4DgBQCaPEIyEIgiCcwXz/Nt/PrSFrY6TT6QAAK5At8UgIgiCIhqDT6RAaGmp1u4KzZ64kxGg0IicnBxqNBgqFQurhAAC0Wi0SExORmZmJkJAQqYcjW+h7Egd9T+Kg70kccvyeOI6DTqdDXFwclErrkSFZz4yUSiUSEhKkHka9hISEyOY/W87Q9yQO+p7EQd+TOOT2PdmaEZkhAQNBEAQhOWSMCIIgCMkhY+QgAQEBmDNnDgICAqQeiqyh70kc9D2Jg74ncXjz9yRrAQNBEATRNKCZEUEQBCE5ZIwIgiAIySFjRBAEQUgOGSOCIAhCcsgYuYCKigp07doVCoUCv/32m9TDkRWXLl3CpEmT0Lp1awQFBaFt27aYM2cOKisrpR6a5CxatAitWrVCYGAgevTogWPHjkk9JFkxb9483HnnndBoNIiKisLo0aNx5swZqYcle+bPnw+FQoHp06dLPRSHIGPkAl566SXExcVJPQxZcvr0aRiNRnz++ef466+/8MEHH+Czzz7D7NmzpR6apPz444+YMWMG5syZg5MnT6JLly4YOnQoCgoKpB6abNi3bx+mTJmCI0eOYOfOnaiqqsKQIUOg1+ulHppsOX78OD7//HPceuutUg/FcTiiQWzZsoXr2LEj99dff3EAuF9//VXqIcmed999l2vdurXUw5CU7t27c1OmTKldNxgMXFxcHDdv3jwJRyVvCgoKOADcvn37pB6KLNHpdFy7du24nTt3cv369eOmTZsm9ZAcgmZGDSA/Px+TJ0/Gt99+C5VKJfVwvIbi4mKEh4dLPQzJqKysxIkTJzBo0KDa95RKJQYNGoTDhw9LODJ5U1xcDABN+tqxxZQpUzBixAjmuvImZF0oVc5wHIcJEybgySefxB133IFLly5JPSSvICMjA5988gkWLFgg9VAk49q1azAYDIiOjmbej46OxunTpyUalbwxGo2YPn06kpOT0blzZ6mHIztWrlyJkydP4vjx41IPxWloZiRg5syZUCgUNl+nT5/GJ598Ap1Oh1mzZkk9ZEkQ+z3xyc7OxrBhwzB27FhMnjxZopET3siUKVNw6tQprFy5UuqhyI7MzExMmzYNK1asQGBgoNTDcRoqByTg6tWruH79us192rRpg3HjxmHTpk1MnyWDwQAfHx889NBD+Prrr909VEkR+z35+/sDAHJycpCSkoKePXti+fLlNvuaNHYqKyuhUqmwevVqjB49uvb9Rx55BEVFRdiwYYN0g5MhU6dOxYYNG7B//360bt1a6uHIjvXr1+Pee++Fj49P7XsGgwEKhQJKpRIVFRXMNrlCxshJrly5Aq1WW7uek5ODoUOHYvXq1ejRo4ds+zBJQXZ2Nvr3749u3brhu+++84ofhrvp0aMHunfvjk8++QSAyQ3VokULTJ06FTNnzpR4dPKA4zg888wzWLduHdLT09GuXTuphyRLdDodLl++zLw3ceJEdOzYES+//LLXuDUpZuQkLVq0YNbVajUAoG3btmSIeGRnZyMlJQUtW7bEggULcPXq1dptMTExEo5MWmbMmIFHHnkEd9xxB7p3744PP/wQer0eEydOlHposmHKlCn4/vvvsWHDBmg0GuTl5QEwNWoLCgqSeHTyQaPR1DE4wcHBiIiI8BpDBJAxItzMzp07kZGRgYyMjDpGuilPysePH4+rV6/i9ddfR15eHrp27Ypt27bVETU0ZRYvXgwASElJYd5ftmwZJkyY4PkBEW6F3HQEQRCE5DTdKDJBEAQhG8gYEQRBEJJDxoggCIKQHDJGBEEQhOSQMSIIgiAkh4wRQRAEITlkjAiCIAjJIWNEEARBSA4ZI4IgCEJyyBgRBEEQkkPGiCAIgpAcMkYEQRCE5Pw/JOKo5VuXB74AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(train_data[0], train_data[1], glorot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9383e-c967-4227-ab3b-5dab7d7dcbba",
   "metadata": {},
   "source": [
    "With glorot initialization the sequence converge much faster (near the epoch 60)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bbba2c-b8aa-422b-90e1-d8222effec1e",
   "metadata": {},
   "source": [
    "Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "903f4997-9a3a-4c18-a27e-fe9a9f0a3a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:00:14.094398Z",
     "iopub.status.busy": "2023-04-19T20:00:14.093579Z",
     "iopub.status.idle": "2023-04-19T20:00:14.099688Z",
     "shell.execute_reply": "2023-04-19T20:00:14.099072Z",
     "shell.execute_reply.started": "2023-04-19T20:00:14.094367Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def scale(data, factor):\n",
    "    new_data = deepcopy(data)\n",
    "    for i in range(len(data[0])):\n",
    "        new_data[0][i] *= factor\n",
    "    return new_data\n",
    "\n",
    "def scale_and_train(factor):\n",
    "    scaled_train_data = scale(train_data, factor)\n",
    "    train_loader = torch.utils.data.DataLoader(list(zip(scaled_train_data[0], scaled_train_data[1])), batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    scaled_val_data = scale(val_data, factor)\n",
    "    val_loader = torch.utils.data.DataLoader(list(zip(scaled_val_data[0], scaled_val_data[1])), batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    net = Glorot().to(dev)\n",
    "    train(net, train_loader, val_loader, epochs=epochs, verbose=True);\n",
    "    \n",
    "    # plot_decision_boundary(scaled_train_data[0], scaled_train_data[1], net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "69dbb895-15b3-4aab-b553-6992b537944a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:00:18.420131Z",
     "iopub.status.busy": "2023-04-19T20:00:18.419291Z",
     "iopub.status.idle": "2023-04-19T20:00:20.696911Z",
     "shell.execute_reply": "2023-04-19T20:00:20.696290Z",
     "shell.execute_reply.started": "2023-04-19T20:00:18.420102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.550/0.712 / 0.500/0.711\n",
      "1: Training / validation acc/loss: 0.520/0.711 / 0.480/0.710\n",
      "2: Training / validation acc/loss: 0.510/0.710 / 0.470/0.710\n",
      "3: Training / validation acc/loss: 0.480/0.710 / 0.460/0.709\n",
      "4: Training / validation acc/loss: 0.470/0.709 / 0.430/0.709\n",
      "5: Training / validation acc/loss: 0.420/0.709 / 0.440/0.708\n",
      "6: Training / validation acc/loss: 0.420/0.708 / 0.410/0.707\n",
      "7: Training / validation acc/loss: 0.370/0.707 / 0.390/0.706\n",
      "8: Training / validation acc/loss: 0.330/0.705 / 0.350/0.704\n",
      "9: Training / validation acc/loss: 0.310/0.703 / 0.330/0.701\n",
      "10: Training / validation acc/loss: 0.290/0.700 / 0.330/0.699\n",
      "11: Training / validation acc/loss: 0.300/0.697 / 0.360/0.696\n",
      "12: Training / validation acc/loss: 0.340/0.694 / 0.380/0.693\n",
      "13: Training / validation acc/loss: 0.390/0.691 / 0.410/0.691\n",
      "14: Training / validation acc/loss: 0.420/0.690 / 0.410/0.689\n",
      "15: Training / validation acc/loss: 0.420/0.688 / 0.430/0.689\n",
      "16: Training / validation acc/loss: 0.440/0.687 / 0.430/0.688\n",
      "17: Training / validation acc/loss: 0.440/0.687 / 0.440/0.687\n",
      "18: Training / validation acc/loss: 0.450/0.686 / 0.450/0.687\n",
      "19: Training / validation acc/loss: 0.460/0.686 / 0.460/0.687\n",
      "20: Training / validation acc/loss: 0.460/0.686 / 0.460/0.686\n",
      "21: Training / validation acc/loss: 0.460/0.685 / 0.580/0.686\n",
      "22: Training / validation acc/loss: 0.550/0.685 / 0.580/0.686\n",
      "23: Training / validation acc/loss: 0.580/0.685 / 0.580/0.686\n",
      "24: Training / validation acc/loss: 0.600/0.685 / 0.590/0.686\n",
      "25: Training / validation acc/loss: 0.610/0.684 / 0.600/0.685\n",
      "26: Training / validation acc/loss: 0.610/0.684 / 0.620/0.685\n",
      "27: Training / validation acc/loss: 0.610/0.684 / 0.620/0.685\n",
      "28: Training / validation acc/loss: 0.620/0.684 / 0.630/0.685\n",
      "29: Training / validation acc/loss: 0.620/0.684 / 0.650/0.685\n",
      "30: Training / validation acc/loss: 0.620/0.684 / 0.660/0.685\n",
      "31: Training / validation acc/loss: 0.640/0.684 / 0.690/0.685\n",
      "32: Training / validation acc/loss: 0.670/0.683 / 0.690/0.685\n",
      "33: Training / validation acc/loss: 0.680/0.683 / 0.690/0.684\n",
      "34: Training / validation acc/loss: 0.680/0.683 / 0.690/0.684\n",
      "35: Training / validation acc/loss: 0.690/0.683 / 0.690/0.684\n",
      "36: Training / validation acc/loss: 0.690/0.683 / 0.690/0.684\n",
      "37: Training / validation acc/loss: 0.690/0.683 / 0.690/0.684\n",
      "38: Training / validation acc/loss: 0.690/0.682 / 0.680/0.684\n",
      "39: Training / validation acc/loss: 0.690/0.682 / 0.680/0.684\n",
      "40: Training / validation acc/loss: 0.690/0.682 / 0.690/0.684\n",
      "41: Training / validation acc/loss: 0.690/0.682 / 0.690/0.683\n",
      "42: Training / validation acc/loss: 0.700/0.682 / 0.690/0.683\n",
      "43: Training / validation acc/loss: 0.700/0.682 / 0.690/0.683\n",
      "44: Training / validation acc/loss: 0.700/0.681 / 0.690/0.683\n",
      "45: Training / validation acc/loss: 0.700/0.681 / 0.680/0.683\n",
      "46: Training / validation acc/loss: 0.700/0.681 / 0.680/0.683\n",
      "47: Training / validation acc/loss: 0.700/0.681 / 0.690/0.683\n",
      "48: Training / validation acc/loss: 0.700/0.681 / 0.700/0.682\n",
      "49: Training / validation acc/loss: 0.700/0.681 / 0.700/0.682\n",
      "50: Training / validation acc/loss: 0.700/0.680 / 0.700/0.682\n",
      "51: Training / validation acc/loss: 0.700/0.680 / 0.700/0.682\n",
      "52: Training / validation acc/loss: 0.700/0.680 / 0.690/0.682\n",
      "53: Training / validation acc/loss: 0.700/0.680 / 0.700/0.682\n",
      "54: Training / validation acc/loss: 0.700/0.680 / 0.690/0.682\n",
      "55: Training / validation acc/loss: 0.700/0.680 / 0.690/0.681\n",
      "56: Training / validation acc/loss: 0.700/0.679 / 0.700/0.681\n",
      "57: Training / validation acc/loss: 0.700/0.679 / 0.700/0.681\n",
      "58: Training / validation acc/loss: 0.700/0.679 / 0.710/0.681\n",
      "59: Training / validation acc/loss: 0.700/0.679 / 0.710/0.681\n",
      "60: Training / validation acc/loss: 0.700/0.679 / 0.710/0.681\n",
      "61: Training / validation acc/loss: 0.700/0.679 / 0.710/0.681\n",
      "62: Training / validation acc/loss: 0.700/0.678 / 0.710/0.681\n",
      "63: Training / validation acc/loss: 0.700/0.678 / 0.710/0.680\n",
      "64: Training / validation acc/loss: 0.690/0.678 / 0.710/0.680\n",
      "65: Training / validation acc/loss: 0.700/0.678 / 0.710/0.680\n",
      "66: Training / validation acc/loss: 0.690/0.678 / 0.710/0.680\n",
      "67: Training / validation acc/loss: 0.690/0.678 / 0.710/0.680\n",
      "68: Training / validation acc/loss: 0.690/0.677 / 0.720/0.680\n",
      "69: Training / validation acc/loss: 0.700/0.677 / 0.710/0.680\n",
      "70: Training / validation acc/loss: 0.700/0.677 / 0.720/0.679\n",
      "71: Training / validation acc/loss: 0.700/0.677 / 0.720/0.679\n",
      "72: Training / validation acc/loss: 0.700/0.677 / 0.720/0.679\n",
      "73: Training / validation acc/loss: 0.710/0.676 / 0.720/0.679\n",
      "74: Training / validation acc/loss: 0.700/0.676 / 0.720/0.679\n",
      "75: Training / validation acc/loss: 0.700/0.676 / 0.720/0.679\n",
      "76: Training / validation acc/loss: 0.700/0.676 / 0.720/0.679\n",
      "77: Training / validation acc/loss: 0.710/0.676 / 0.730/0.678\n",
      "78: Training / validation acc/loss: 0.710/0.676 / 0.730/0.678\n",
      "79: Training / validation acc/loss: 0.710/0.675 / 0.730/0.678\n",
      "80: Training / validation acc/loss: 0.700/0.675 / 0.730/0.678\n",
      "81: Training / validation acc/loss: 0.700/0.675 / 0.730/0.678\n",
      "82: Training / validation acc/loss: 0.700/0.675 / 0.730/0.678\n",
      "83: Training / validation acc/loss: 0.710/0.675 / 0.730/0.678\n",
      "84: Training / validation acc/loss: 0.720/0.674 / 0.730/0.677\n",
      "85: Training / validation acc/loss: 0.720/0.674 / 0.730/0.677\n",
      "86: Training / validation acc/loss: 0.720/0.674 / 0.730/0.677\n",
      "87: Training / validation acc/loss: 0.720/0.674 / 0.730/0.677\n",
      "88: Training / validation acc/loss: 0.720/0.674 / 0.730/0.677\n",
      "89: Training / validation acc/loss: 0.720/0.674 / 0.730/0.677\n",
      "90: Training / validation acc/loss: 0.720/0.673 / 0.730/0.677\n",
      "91: Training / validation acc/loss: 0.720/0.673 / 0.730/0.676\n",
      "92: Training / validation acc/loss: 0.720/0.673 / 0.730/0.676\n",
      "93: Training / validation acc/loss: 0.720/0.673 / 0.730/0.676\n",
      "94: Training / validation acc/loss: 0.720/0.673 / 0.730/0.676\n",
      "95: Training / validation acc/loss: 0.720/0.672 / 0.730/0.676\n",
      "96: Training / validation acc/loss: 0.720/0.672 / 0.730/0.676\n",
      "97: Training / validation acc/loss: 0.720/0.672 / 0.730/0.675\n",
      "98: Training / validation acc/loss: 0.720/0.672 / 0.730/0.675\n",
      "99: Training / validation acc/loss: 0.720/0.672 / 0.730/0.675\n",
      "100: Training / validation acc/loss: 0.720/0.671 / 0.730/0.675\n",
      "101: Training / validation acc/loss: 0.720/0.671 / 0.730/0.675\n",
      "102: Training / validation acc/loss: 0.720/0.671 / 0.730/0.675\n",
      "103: Training / validation acc/loss: 0.720/0.671 / 0.740/0.674\n",
      "104: Training / validation acc/loss: 0.720/0.671 / 0.740/0.674\n",
      "105: Training / validation acc/loss: 0.720/0.670 / 0.730/0.674\n",
      "106: Training / validation acc/loss: 0.720/0.670 / 0.730/0.674\n",
      "107: Training / validation acc/loss: 0.720/0.670 / 0.740/0.674\n",
      "108: Training / validation acc/loss: 0.720/0.670 / 0.740/0.674\n",
      "109: Training / validation acc/loss: 0.720/0.669 / 0.740/0.673\n",
      "110: Training / validation acc/loss: 0.720/0.669 / 0.730/0.673\n",
      "111: Training / validation acc/loss: 0.720/0.669 / 0.740/0.673\n",
      "112: Training / validation acc/loss: 0.720/0.669 / 0.740/0.673\n",
      "113: Training / validation acc/loss: 0.720/0.669 / 0.730/0.673\n",
      "114: Training / validation acc/loss: 0.720/0.668 / 0.740/0.673\n",
      "115: Training / validation acc/loss: 0.720/0.668 / 0.740/0.672\n",
      "116: Training / validation acc/loss: 0.720/0.668 / 0.740/0.672\n",
      "117: Training / validation acc/loss: 0.720/0.668 / 0.740/0.672\n",
      "118: Training / validation acc/loss: 0.720/0.667 / 0.730/0.672\n",
      "119: Training / validation acc/loss: 0.720/0.667 / 0.740/0.672\n",
      "120: Training / validation acc/loss: 0.720/0.667 / 0.730/0.671\n",
      "121: Training / validation acc/loss: 0.720/0.667 / 0.740/0.671\n",
      "122: Training / validation acc/loss: 0.720/0.666 / 0.740/0.671\n",
      "123: Training / validation acc/loss: 0.720/0.666 / 0.740/0.671\n",
      "124: Training / validation acc/loss: 0.720/0.666 / 0.730/0.671\n",
      "125: Training / validation acc/loss: 0.720/0.666 / 0.740/0.670\n",
      "126: Training / validation acc/loss: 0.720/0.665 / 0.740/0.670\n",
      "127: Training / validation acc/loss: 0.720/0.665 / 0.740/0.670\n",
      "128: Training / validation acc/loss: 0.720/0.665 / 0.740/0.670\n",
      "129: Training / validation acc/loss: 0.720/0.665 / 0.740/0.670\n",
      "130: Training / validation acc/loss: 0.720/0.664 / 0.740/0.669\n",
      "131: Training / validation acc/loss: 0.720/0.664 / 0.740/0.669\n",
      "132: Training / validation acc/loss: 0.720/0.664 / 0.750/0.669\n",
      "133: Training / validation acc/loss: 0.720/0.664 / 0.740/0.669\n",
      "134: Training / validation acc/loss: 0.720/0.663 / 0.740/0.668\n",
      "135: Training / validation acc/loss: 0.720/0.663 / 0.740/0.668\n",
      "136: Training / validation acc/loss: 0.720/0.663 / 0.750/0.668\n",
      "137: Training / validation acc/loss: 0.720/0.663 / 0.740/0.668\n",
      "138: Training / validation acc/loss: 0.720/0.662 / 0.750/0.668\n",
      "139: Training / validation acc/loss: 0.720/0.662 / 0.740/0.667\n",
      "140: Training / validation acc/loss: 0.720/0.662 / 0.750/0.667\n",
      "141: Training / validation acc/loss: 0.720/0.661 / 0.740/0.667\n",
      "142: Training / validation acc/loss: 0.720/0.661 / 0.750/0.667\n",
      "143: Training / validation acc/loss: 0.720/0.661 / 0.750/0.666\n",
      "144: Training / validation acc/loss: 0.720/0.661 / 0.750/0.666\n",
      "145: Training / validation acc/loss: 0.720/0.660 / 0.750/0.666\n",
      "146: Training / validation acc/loss: 0.720/0.660 / 0.750/0.666\n",
      "147: Training / validation acc/loss: 0.720/0.660 / 0.750/0.665\n",
      "148: Training / validation acc/loss: 0.720/0.659 / 0.750/0.665\n",
      "149: Training / validation acc/loss: 0.720/0.659 / 0.740/0.665\n",
      "150: Training / validation acc/loss: 0.720/0.659 / 0.750/0.665\n",
      "151: Training / validation acc/loss: 0.720/0.658 / 0.740/0.664\n",
      "152: Training / validation acc/loss: 0.720/0.658 / 0.750/0.664\n",
      "153: Training / validation acc/loss: 0.720/0.658 / 0.750/0.664\n",
      "154: Training / validation acc/loss: 0.720/0.657 / 0.750/0.664\n",
      "155: Training / validation acc/loss: 0.720/0.657 / 0.750/0.663\n",
      "156: Training / validation acc/loss: 0.720/0.657 / 0.740/0.663\n",
      "157: Training / validation acc/loss: 0.720/0.656 / 0.740/0.663\n",
      "158: Training / validation acc/loss: 0.720/0.656 / 0.750/0.663\n",
      "159: Training / validation acc/loss: 0.720/0.656 / 0.740/0.662\n",
      "160: Training / validation acc/loss: 0.720/0.655 / 0.750/0.662\n",
      "161: Training / validation acc/loss: 0.720/0.655 / 0.740/0.662\n",
      "162: Training / validation acc/loss: 0.720/0.655 / 0.740/0.661\n",
      "163: Training / validation acc/loss: 0.720/0.654 / 0.740/0.661\n",
      "164: Training / validation acc/loss: 0.720/0.654 / 0.750/0.661\n",
      "165: Training / validation acc/loss: 0.720/0.654 / 0.740/0.660\n",
      "166: Training / validation acc/loss: 0.720/0.653 / 0.750/0.660\n",
      "167: Training / validation acc/loss: 0.720/0.653 / 0.740/0.660\n",
      "168: Training / validation acc/loss: 0.720/0.653 / 0.750/0.660\n",
      "169: Training / validation acc/loss: 0.720/0.652 / 0.740/0.659\n",
      "170: Training / validation acc/loss: 0.720/0.652 / 0.750/0.659\n",
      "171: Training / validation acc/loss: 0.720/0.652 / 0.740/0.659\n",
      "172: Training / validation acc/loss: 0.720/0.651 / 0.750/0.658\n",
      "173: Training / validation acc/loss: 0.720/0.651 / 0.750/0.658\n",
      "174: Training / validation acc/loss: 0.720/0.650 / 0.740/0.658\n",
      "175: Training / validation acc/loss: 0.720/0.650 / 0.740/0.657\n",
      "176: Training / validation acc/loss: 0.720/0.650 / 0.750/0.657\n",
      "177: Training / validation acc/loss: 0.720/0.649 / 0.750/0.657\n",
      "178: Training / validation acc/loss: 0.720/0.649 / 0.750/0.656\n",
      "179: Training / validation acc/loss: 0.720/0.648 / 0.750/0.656\n",
      "180: Training / validation acc/loss: 0.720/0.648 / 0.750/0.656\n",
      "181: Training / validation acc/loss: 0.720/0.648 / 0.750/0.655\n",
      "182: Training / validation acc/loss: 0.720/0.647 / 0.750/0.655\n",
      "183: Training / validation acc/loss: 0.720/0.647 / 0.750/0.655\n",
      "184: Training / validation acc/loss: 0.720/0.646 / 0.750/0.654\n",
      "185: Training / validation acc/loss: 0.720/0.646 / 0.750/0.654\n",
      "186: Training / validation acc/loss: 0.720/0.646 / 0.750/0.654\n",
      "187: Training / validation acc/loss: 0.720/0.645 / 0.750/0.653\n",
      "188: Training / validation acc/loss: 0.720/0.645 / 0.750/0.653\n",
      "189: Training / validation acc/loss: 0.720/0.644 / 0.750/0.653\n",
      "190: Training / validation acc/loss: 0.720/0.644 / 0.750/0.652\n",
      "191: Training / validation acc/loss: 0.720/0.643 / 0.750/0.652\n",
      "192: Training / validation acc/loss: 0.720/0.643 / 0.750/0.652\n",
      "193: Training / validation acc/loss: 0.720/0.642 / 0.750/0.651\n",
      "194: Training / validation acc/loss: 0.720/0.642 / 0.750/0.651\n",
      "195: Training / validation acc/loss: 0.720/0.642 / 0.750/0.650\n",
      "196: Training / validation acc/loss: 0.720/0.641 / 0.750/0.650\n",
      "197: Training / validation acc/loss: 0.720/0.641 / 0.750/0.650\n",
      "198: Training / validation acc/loss: 0.720/0.640 / 0.750/0.649\n",
      "199: Training / validation acc/loss: 0.720/0.640 / 0.750/0.649\n",
      "200: Training / validation acc/loss: 0.720/0.639 / 0.750/0.648\n",
      "201: Training / validation acc/loss: 0.720/0.639 / 0.750/0.648\n",
      "202: Training / validation acc/loss: 0.720/0.638 / 0.750/0.648\n",
      "203: Training / validation acc/loss: 0.720/0.638 / 0.750/0.647\n",
      "204: Training / validation acc/loss: 0.720/0.637 / 0.750/0.647\n",
      "205: Training / validation acc/loss: 0.720/0.637 / 0.750/0.647\n",
      "206: Training / validation acc/loss: 0.720/0.636 / 0.750/0.646\n",
      "207: Training / validation acc/loss: 0.720/0.636 / 0.750/0.646\n",
      "208: Training / validation acc/loss: 0.720/0.635 / 0.750/0.645\n",
      "209: Training / validation acc/loss: 0.720/0.635 / 0.750/0.645\n",
      "210: Training / validation acc/loss: 0.720/0.634 / 0.750/0.644\n",
      "211: Training / validation acc/loss: 0.720/0.634 / 0.750/0.644\n",
      "212: Training / validation acc/loss: 0.720/0.633 / 0.750/0.644\n",
      "213: Training / validation acc/loss: 0.720/0.633 / 0.750/0.643\n",
      "214: Training / validation acc/loss: 0.720/0.632 / 0.750/0.643\n",
      "215: Training / validation acc/loss: 0.720/0.632 / 0.750/0.642\n",
      "216: Training / validation acc/loss: 0.720/0.631 / 0.750/0.642\n",
      "217: Training / validation acc/loss: 0.720/0.631 / 0.750/0.641\n",
      "218: Training / validation acc/loss: 0.720/0.630 / 0.750/0.641\n",
      "219: Training / validation acc/loss: 0.720/0.630 / 0.750/0.641\n",
      "220: Training / validation acc/loss: 0.720/0.629 / 0.750/0.640\n",
      "221: Training / validation acc/loss: 0.720/0.629 / 0.750/0.640\n",
      "222: Training / validation acc/loss: 0.720/0.628 / 0.750/0.639\n",
      "223: Training / validation acc/loss: 0.720/0.628 / 0.750/0.639\n",
      "224: Training / validation acc/loss: 0.720/0.627 / 0.750/0.638\n",
      "225: Training / validation acc/loss: 0.720/0.627 / 0.750/0.638\n",
      "226: Training / validation acc/loss: 0.720/0.626 / 0.750/0.637\n",
      "227: Training / validation acc/loss: 0.720/0.626 / 0.750/0.637\n",
      "228: Training / validation acc/loss: 0.720/0.625 / 0.750/0.637\n",
      "229: Training / validation acc/loss: 0.720/0.624 / 0.750/0.636\n",
      "230: Training / validation acc/loss: 0.720/0.624 / 0.750/0.636\n",
      "231: Training / validation acc/loss: 0.720/0.623 / 0.750/0.635\n",
      "232: Training / validation acc/loss: 0.720/0.623 / 0.750/0.635\n",
      "233: Training / validation acc/loss: 0.720/0.622 / 0.750/0.634\n",
      "234: Training / validation acc/loss: 0.720/0.622 / 0.750/0.634\n",
      "235: Training / validation acc/loss: 0.720/0.621 / 0.750/0.633\n",
      "236: Training / validation acc/loss: 0.720/0.620 / 0.750/0.633\n",
      "237: Training / validation acc/loss: 0.720/0.620 / 0.750/0.632\n",
      "238: Training / validation acc/loss: 0.720/0.619 / 0.750/0.632\n",
      "239: Training / validation acc/loss: 0.720/0.619 / 0.750/0.631\n",
      "240: Training / validation acc/loss: 0.720/0.618 / 0.750/0.631\n",
      "241: Training / validation acc/loss: 0.720/0.618 / 0.750/0.630\n",
      "242: Training / validation acc/loss: 0.720/0.617 / 0.750/0.630\n",
      "243: Training / validation acc/loss: 0.720/0.616 / 0.750/0.629\n",
      "244: Training / validation acc/loss: 0.720/0.616 / 0.750/0.629\n",
      "245: Training / validation acc/loss: 0.720/0.615 / 0.750/0.628\n",
      "246: Training / validation acc/loss: 0.720/0.615 / 0.750/0.628\n",
      "247: Training / validation acc/loss: 0.720/0.614 / 0.750/0.627\n",
      "248: Training / validation acc/loss: 0.720/0.613 / 0.750/0.627\n",
      "249: Training / validation acc/loss: 0.720/0.613 / 0.750/0.626\n",
      "250: Training / validation acc/loss: 0.720/0.612 / 0.750/0.626\n",
      "251: Training / validation acc/loss: 0.720/0.612 / 0.750/0.625\n",
      "252: Training / validation acc/loss: 0.720/0.611 / 0.750/0.625\n",
      "253: Training / validation acc/loss: 0.720/0.610 / 0.750/0.624\n",
      "254: Training / validation acc/loss: 0.720/0.610 / 0.750/0.624\n",
      "255: Training / validation acc/loss: 0.720/0.609 / 0.750/0.623\n",
      "256: Training / validation acc/loss: 0.720/0.609 / 0.750/0.623\n",
      "257: Training / validation acc/loss: 0.720/0.608 / 0.750/0.622\n",
      "258: Training / validation acc/loss: 0.720/0.607 / 0.750/0.622\n",
      "259: Training / validation acc/loss: 0.720/0.607 / 0.750/0.621\n",
      "260: Training / validation acc/loss: 0.720/0.606 / 0.750/0.621\n",
      "261: Training / validation acc/loss: 0.720/0.606 / 0.750/0.620\n",
      "262: Training / validation acc/loss: 0.720/0.605 / 0.750/0.619\n",
      "263: Training / validation acc/loss: 0.720/0.604 / 0.750/0.619\n",
      "264: Training / validation acc/loss: 0.720/0.604 / 0.750/0.618\n",
      "265: Training / validation acc/loss: 0.720/0.603 / 0.750/0.618\n",
      "266: Training / validation acc/loss: 0.720/0.602 / 0.750/0.617\n",
      "267: Training / validation acc/loss: 0.720/0.602 / 0.750/0.617\n",
      "268: Training / validation acc/loss: 0.720/0.601 / 0.750/0.616\n",
      "269: Training / validation acc/loss: 0.720/0.600 / 0.750/0.615\n",
      "270: Training / validation acc/loss: 0.720/0.600 / 0.750/0.615\n",
      "271: Training / validation acc/loss: 0.720/0.599 / 0.750/0.614\n",
      "272: Training / validation acc/loss: 0.720/0.598 / 0.750/0.614\n",
      "273: Training / validation acc/loss: 0.720/0.598 / 0.750/0.613\n",
      "274: Training / validation acc/loss: 0.720/0.597 / 0.750/0.613\n",
      "275: Training / validation acc/loss: 0.720/0.596 / 0.750/0.612\n",
      "276: Training / validation acc/loss: 0.720/0.596 / 0.750/0.612\n",
      "277: Training / validation acc/loss: 0.720/0.595 / 0.750/0.611\n",
      "278: Training / validation acc/loss: 0.740/0.594 / 0.750/0.610\n",
      "279: Training / validation acc/loss: 0.720/0.594 / 0.750/0.610\n",
      "280: Training / validation acc/loss: 0.740/0.593 / 0.750/0.609\n",
      "281: Training / validation acc/loss: 0.720/0.593 / 0.750/0.609\n",
      "282: Training / validation acc/loss: 0.720/0.592 / 0.750/0.608\n",
      "283: Training / validation acc/loss: 0.720/0.591 / 0.750/0.607\n",
      "284: Training / validation acc/loss: 0.720/0.591 / 0.750/0.607\n",
      "285: Training / validation acc/loss: 0.740/0.590 / 0.750/0.606\n",
      "286: Training / validation acc/loss: 0.720/0.589 / 0.750/0.606\n",
      "287: Training / validation acc/loss: 0.740/0.589 / 0.750/0.605\n",
      "288: Training / validation acc/loss: 0.720/0.588 / 0.750/0.605\n",
      "289: Training / validation acc/loss: 0.720/0.587 / 0.750/0.604\n",
      "290: Training / validation acc/loss: 0.720/0.587 / 0.750/0.604\n",
      "291: Training / validation acc/loss: 0.720/0.586 / 0.750/0.603\n",
      "292: Training / validation acc/loss: 0.720/0.585 / 0.750/0.602\n",
      "293: Training / validation acc/loss: 0.720/0.585 / 0.750/0.602\n",
      "294: Training / validation acc/loss: 0.720/0.584 / 0.750/0.602\n",
      "295: Training / validation acc/loss: 0.740/0.584 / 0.750/0.601\n",
      "296: Training / validation acc/loss: 0.730/0.583 / 0.750/0.600\n",
      "297: Training / validation acc/loss: 0.720/0.582 / 0.750/0.600\n",
      "298: Training / validation acc/loss: 0.730/0.582 / 0.750/0.599\n",
      "299: Training / validation acc/loss: 0.720/0.581 / 0.750/0.598\n",
      "300: Training / validation acc/loss: 0.740/0.580 / 0.750/0.598\n",
      "301: Training / validation acc/loss: 0.720/0.580 / 0.750/0.597\n",
      "302: Training / validation acc/loss: 0.720/0.579 / 0.750/0.597\n",
      "303: Training / validation acc/loss: 0.720/0.578 / 0.750/0.596\n",
      "304: Training / validation acc/loss: 0.720/0.578 / 0.750/0.596\n",
      "305: Training / validation acc/loss: 0.720/0.577 / 0.750/0.595\n",
      "306: Training / validation acc/loss: 0.720/0.576 / 0.750/0.594\n",
      "307: Training / validation acc/loss: 0.720/0.576 / 0.750/0.594\n",
      "308: Training / validation acc/loss: 0.720/0.575 / 0.750/0.593\n",
      "309: Training / validation acc/loss: 0.730/0.575 / 0.750/0.593\n",
      "310: Training / validation acc/loss: 0.730/0.574 / 0.750/0.592\n",
      "311: Training / validation acc/loss: 0.720/0.573 / 0.750/0.592\n",
      "312: Training / validation acc/loss: 0.720/0.573 / 0.750/0.591\n",
      "313: Training / validation acc/loss: 0.720/0.572 / 0.750/0.590\n",
      "314: Training / validation acc/loss: 0.720/0.571 / 0.750/0.590\n",
      "315: Training / validation acc/loss: 0.730/0.571 / 0.750/0.589\n",
      "316: Training / validation acc/loss: 0.730/0.570 / 0.750/0.589\n",
      "317: Training / validation acc/loss: 0.730/0.570 / 0.750/0.588\n",
      "318: Training / validation acc/loss: 0.740/0.569 / 0.750/0.588\n",
      "319: Training / validation acc/loss: 0.740/0.568 / 0.750/0.587\n",
      "320: Training / validation acc/loss: 0.740/0.568 / 0.750/0.587\n",
      "321: Training / validation acc/loss: 0.740/0.567 / 0.750/0.586\n",
      "322: Training / validation acc/loss: 0.740/0.566 / 0.750/0.586\n",
      "323: Training / validation acc/loss: 0.740/0.566 / 0.750/0.585\n",
      "324: Training / validation acc/loss: 0.740/0.565 / 0.750/0.585\n",
      "325: Training / validation acc/loss: 0.740/0.565 / 0.750/0.584\n",
      "326: Training / validation acc/loss: 0.740/0.564 / 0.750/0.583\n",
      "327: Training / validation acc/loss: 0.740/0.563 / 0.750/0.583\n",
      "328: Training / validation acc/loss: 0.740/0.563 / 0.750/0.582\n",
      "329: Training / validation acc/loss: 0.740/0.562 / 0.750/0.582\n",
      "330: Training / validation acc/loss: 0.740/0.562 / 0.750/0.581\n",
      "331: Training / validation acc/loss: 0.740/0.561 / 0.750/0.581\n",
      "332: Training / validation acc/loss: 0.740/0.560 / 0.750/0.580\n",
      "333: Training / validation acc/loss: 0.740/0.560 / 0.750/0.579\n",
      "334: Training / validation acc/loss: 0.740/0.559 / 0.750/0.579\n",
      "335: Training / validation acc/loss: 0.740/0.559 / 0.750/0.578\n",
      "336: Training / validation acc/loss: 0.740/0.558 / 0.750/0.578\n",
      "337: Training / validation acc/loss: 0.740/0.558 / 0.750/0.577\n",
      "338: Training / validation acc/loss: 0.740/0.557 / 0.750/0.577\n",
      "339: Training / validation acc/loss: 0.740/0.556 / 0.750/0.576\n",
      "340: Training / validation acc/loss: 0.740/0.556 / 0.750/0.576\n",
      "341: Training / validation acc/loss: 0.740/0.555 / 0.750/0.575\n",
      "342: Training / validation acc/loss: 0.740/0.555 / 0.750/0.574\n",
      "343: Training / validation acc/loss: 0.740/0.554 / 0.750/0.574\n",
      "344: Training / validation acc/loss: 0.740/0.553 / 0.750/0.573\n",
      "345: Training / validation acc/loss: 0.740/0.553 / 0.750/0.573\n",
      "346: Training / validation acc/loss: 0.740/0.552 / 0.750/0.572\n",
      "347: Training / validation acc/loss: 0.740/0.552 / 0.750/0.571\n",
      "348: Training / validation acc/loss: 0.740/0.551 / 0.750/0.571\n",
      "349: Training / validation acc/loss: 0.740/0.550 / 0.750/0.570\n",
      "350: Training / validation acc/loss: 0.740/0.550 / 0.750/0.570\n",
      "351: Training / validation acc/loss: 0.740/0.549 / 0.750/0.569\n",
      "352: Training / validation acc/loss: 0.740/0.549 / 0.750/0.569\n",
      "353: Training / validation acc/loss: 0.740/0.548 / 0.750/0.568\n",
      "354: Training / validation acc/loss: 0.740/0.548 / 0.750/0.567\n",
      "355: Training / validation acc/loss: 0.740/0.547 / 0.750/0.567\n",
      "356: Training / validation acc/loss: 0.740/0.546 / 0.750/0.566\n",
      "357: Training / validation acc/loss: 0.750/0.546 / 0.750/0.566\n",
      "358: Training / validation acc/loss: 0.750/0.545 / 0.750/0.565\n",
      "359: Training / validation acc/loss: 0.750/0.545 / 0.750/0.565\n",
      "360: Training / validation acc/loss: 0.750/0.544 / 0.750/0.564\n",
      "361: Training / validation acc/loss: 0.750/0.544 / 0.750/0.564\n",
      "362: Training / validation acc/loss: 0.750/0.543 / 0.750/0.563\n",
      "363: Training / validation acc/loss: 0.750/0.542 / 0.750/0.562\n",
      "364: Training / validation acc/loss: 0.750/0.542 / 0.750/0.562\n",
      "365: Training / validation acc/loss: 0.750/0.541 / 0.750/0.561\n",
      "366: Training / validation acc/loss: 0.750/0.541 / 0.750/0.561\n",
      "367: Training / validation acc/loss: 0.750/0.540 / 0.760/0.560\n",
      "368: Training / validation acc/loss: 0.750/0.539 / 0.760/0.560\n",
      "369: Training / validation acc/loss: 0.750/0.539 / 0.760/0.559\n",
      "370: Training / validation acc/loss: 0.750/0.538 / 0.760/0.558\n",
      "371: Training / validation acc/loss: 0.750/0.538 / 0.760/0.557\n",
      "372: Training / validation acc/loss: 0.750/0.537 / 0.770/0.556\n",
      "373: Training / validation acc/loss: 0.750/0.536 / 0.770/0.556\n",
      "374: Training / validation acc/loss: 0.750/0.535 / 0.770/0.555\n",
      "375: Training / validation acc/loss: 0.750/0.534 / 0.770/0.554\n",
      "376: Training / validation acc/loss: 0.750/0.534 / 0.770/0.554\n",
      "377: Training / validation acc/loss: 0.760/0.533 / 0.770/0.553\n",
      "378: Training / validation acc/loss: 0.760/0.532 / 0.770/0.553\n",
      "379: Training / validation acc/loss: 0.760/0.531 / 0.770/0.552\n",
      "380: Training / validation acc/loss: 0.760/0.531 / 0.770/0.551\n",
      "381: Training / validation acc/loss: 0.760/0.530 / 0.770/0.551\n",
      "382: Training / validation acc/loss: 0.760/0.529 / 0.770/0.550\n",
      "383: Training / validation acc/loss: 0.760/0.529 / 0.770/0.550\n",
      "384: Training / validation acc/loss: 0.760/0.528 / 0.770/0.549\n",
      "385: Training / validation acc/loss: 0.760/0.527 / 0.770/0.549\n",
      "386: Training / validation acc/loss: 0.760/0.526 / 0.770/0.548\n",
      "387: Training / validation acc/loss: 0.760/0.526 / 0.770/0.547\n",
      "388: Training / validation acc/loss: 0.760/0.525 / 0.770/0.547\n",
      "389: Training / validation acc/loss: 0.760/0.524 / 0.770/0.546\n",
      "390: Training / validation acc/loss: 0.770/0.523 / 0.770/0.546\n",
      "391: Training / validation acc/loss: 0.770/0.522 / 0.770/0.545\n",
      "392: Training / validation acc/loss: 0.770/0.522 / 0.770/0.544\n",
      "393: Training / validation acc/loss: 0.770/0.521 / 0.770/0.544\n",
      "394: Training / validation acc/loss: 0.770/0.520 / 0.770/0.543\n",
      "395: Training / validation acc/loss: 0.770/0.519 / 0.770/0.543\n",
      "396: Training / validation acc/loss: 0.780/0.518 / 0.770/0.542\n",
      "397: Training / validation acc/loss: 0.780/0.518 / 0.770/0.541\n",
      "398: Training / validation acc/loss: 0.780/0.517 / 0.770/0.541\n",
      "399: Training / validation acc/loss: 0.780/0.516 / 0.770/0.540\n",
      "400: Training / validation acc/loss: 0.780/0.515 / 0.770/0.539\n",
      "401: Training / validation acc/loss: 0.780/0.514 / 0.770/0.539\n",
      "402: Training / validation acc/loss: 0.770/0.514 / 0.770/0.538\n",
      "403: Training / validation acc/loss: 0.770/0.513 / 0.770/0.537\n",
      "404: Training / validation acc/loss: 0.770/0.512 / 0.770/0.537\n",
      "405: Training / validation acc/loss: 0.770/0.511 / 0.780/0.536\n",
      "406: Training / validation acc/loss: 0.770/0.511 / 0.780/0.535\n",
      "407: Training / validation acc/loss: 0.770/0.510 / 0.780/0.535\n",
      "408: Training / validation acc/loss: 0.770/0.509 / 0.780/0.534\n",
      "409: Training / validation acc/loss: 0.770/0.508 / 0.780/0.533\n",
      "410: Training / validation acc/loss: 0.770/0.508 / 0.780/0.533\n",
      "411: Training / validation acc/loss: 0.780/0.507 / 0.780/0.532\n",
      "412: Training / validation acc/loss: 0.780/0.506 / 0.780/0.531\n",
      "413: Training / validation acc/loss: 0.770/0.505 / 0.780/0.530\n",
      "414: Training / validation acc/loss: 0.770/0.504 / 0.780/0.530\n",
      "415: Training / validation acc/loss: 0.770/0.504 / 0.780/0.529\n",
      "416: Training / validation acc/loss: 0.770/0.503 / 0.780/0.528\n",
      "417: Training / validation acc/loss: 0.770/0.502 / 0.780/0.528\n",
      "418: Training / validation acc/loss: 0.780/0.501 / 0.780/0.527\n",
      "419: Training / validation acc/loss: 0.780/0.500 / 0.780/0.526\n",
      "420: Training / validation acc/loss: 0.780/0.499 / 0.780/0.526\n",
      "421: Training / validation acc/loss: 0.780/0.499 / 0.780/0.525\n",
      "422: Training / validation acc/loss: 0.780/0.498 / 0.780/0.524\n",
      "423: Training / validation acc/loss: 0.780/0.497 / 0.780/0.524\n",
      "424: Training / validation acc/loss: 0.780/0.496 / 0.780/0.523\n",
      "425: Training / validation acc/loss: 0.780/0.495 / 0.780/0.522\n",
      "426: Training / validation acc/loss: 0.780/0.494 / 0.780/0.521\n",
      "427: Training / validation acc/loss: 0.780/0.493 / 0.780/0.520\n",
      "428: Training / validation acc/loss: 0.780/0.492 / 0.780/0.519\n",
      "429: Training / validation acc/loss: 0.790/0.491 / 0.780/0.518\n",
      "430: Training / validation acc/loss: 0.790/0.490 / 0.780/0.517\n",
      "431: Training / validation acc/loss: 0.790/0.489 / 0.780/0.516\n",
      "432: Training / validation acc/loss: 0.800/0.488 / 0.780/0.515\n",
      "433: Training / validation acc/loss: 0.800/0.487 / 0.780/0.514\n",
      "434: Training / validation acc/loss: 0.800/0.486 / 0.780/0.513\n",
      "435: Training / validation acc/loss: 0.800/0.485 / 0.780/0.512\n",
      "436: Training / validation acc/loss: 0.800/0.485 / 0.780/0.511\n",
      "437: Training / validation acc/loss: 0.800/0.484 / 0.780/0.510\n",
      "438: Training / validation acc/loss: 0.800/0.483 / 0.780/0.509\n",
      "439: Training / validation acc/loss: 0.800/0.482 / 0.780/0.508\n",
      "440: Training / validation acc/loss: 0.800/0.481 / 0.780/0.507\n",
      "441: Training / validation acc/loss: 0.800/0.480 / 0.780/0.506\n",
      "442: Training / validation acc/loss: 0.810/0.479 / 0.780/0.504\n",
      "443: Training / validation acc/loss: 0.810/0.477 / 0.780/0.503\n",
      "444: Training / validation acc/loss: 0.810/0.476 / 0.780/0.502\n",
      "445: Training / validation acc/loss: 0.810/0.475 / 0.780/0.501\n",
      "446: Training / validation acc/loss: 0.820/0.474 / 0.780/0.500\n",
      "447: Training / validation acc/loss: 0.820/0.473 / 0.780/0.499\n",
      "448: Training / validation acc/loss: 0.820/0.472 / 0.780/0.498\n",
      "449: Training / validation acc/loss: 0.820/0.471 / 0.780/0.497\n",
      "450: Training / validation acc/loss: 0.820/0.470 / 0.780/0.496\n",
      "451: Training / validation acc/loss: 0.820/0.469 / 0.780/0.495\n",
      "452: Training / validation acc/loss: 0.820/0.468 / 0.780/0.494\n",
      "453: Training / validation acc/loss: 0.830/0.467 / 0.780/0.493\n",
      "454: Training / validation acc/loss: 0.830/0.466 / 0.780/0.492\n",
      "455: Training / validation acc/loss: 0.830/0.465 / 0.780/0.491\n",
      "456: Training / validation acc/loss: 0.830/0.464 / 0.780/0.490\n",
      "457: Training / validation acc/loss: 0.830/0.463 / 0.780/0.490\n",
      "458: Training / validation acc/loss: 0.830/0.462 / 0.770/0.488\n",
      "459: Training / validation acc/loss: 0.830/0.461 / 0.790/0.488\n",
      "460: Training / validation acc/loss: 0.830/0.460 / 0.780/0.486\n",
      "461: Training / validation acc/loss: 0.830/0.459 / 0.780/0.485\n",
      "462: Training / validation acc/loss: 0.830/0.458 / 0.780/0.484\n",
      "463: Training / validation acc/loss: 0.840/0.457 / 0.790/0.483\n",
      "464: Training / validation acc/loss: 0.840/0.455 / 0.790/0.481\n",
      "465: Training / validation acc/loss: 0.840/0.454 / 0.800/0.480\n",
      "466: Training / validation acc/loss: 0.840/0.453 / 0.800/0.479\n",
      "467: Training / validation acc/loss: 0.840/0.452 / 0.800/0.478\n",
      "468: Training / validation acc/loss: 0.840/0.451 / 0.800/0.477\n",
      "469: Training / validation acc/loss: 0.840/0.449 / 0.800/0.476\n",
      "470: Training / validation acc/loss: 0.840/0.448 / 0.800/0.475\n",
      "471: Training / validation acc/loss: 0.840/0.447 / 0.800/0.474\n",
      "472: Training / validation acc/loss: 0.840/0.446 / 0.800/0.473\n",
      "473: Training / validation acc/loss: 0.840/0.445 / 0.800/0.472\n",
      "474: Training / validation acc/loss: 0.840/0.444 / 0.800/0.471\n",
      "475: Training / validation acc/loss: 0.840/0.443 / 0.800/0.470\n",
      "476: Training / validation acc/loss: 0.840/0.441 / 0.800/0.469\n",
      "477: Training / validation acc/loss: 0.840/0.440 / 0.800/0.468\n",
      "478: Training / validation acc/loss: 0.840/0.439 / 0.800/0.467\n",
      "479: Training / validation acc/loss: 0.840/0.437 / 0.800/0.466\n",
      "480: Training / validation acc/loss: 0.840/0.436 / 0.800/0.465\n",
      "481: Training / validation acc/loss: 0.840/0.435 / 0.800/0.464\n",
      "482: Training / validation acc/loss: 0.860/0.434 / 0.800/0.463\n",
      "483: Training / validation acc/loss: 0.860/0.432 / 0.800/0.462\n",
      "484: Training / validation acc/loss: 0.860/0.431 / 0.800/0.461\n",
      "485: Training / validation acc/loss: 0.860/0.430 / 0.800/0.461\n",
      "486: Training / validation acc/loss: 0.860/0.429 / 0.800/0.460\n",
      "487: Training / validation acc/loss: 0.860/0.427 / 0.800/0.459\n",
      "488: Training / validation acc/loss: 0.860/0.426 / 0.800/0.458\n",
      "489: Training / validation acc/loss: 0.860/0.425 / 0.800/0.457\n",
      "490: Training / validation acc/loss: 0.860/0.424 / 0.800/0.456\n",
      "491: Training / validation acc/loss: 0.860/0.423 / 0.800/0.455\n",
      "492: Training / validation acc/loss: 0.860/0.422 / 0.800/0.454\n",
      "493: Training / validation acc/loss: 0.860/0.421 / 0.800/0.453\n",
      "494: Training / validation acc/loss: 0.860/0.420 / 0.810/0.452\n",
      "495: Training / validation acc/loss: 0.860/0.418 / 0.810/0.451\n",
      "496: Training / validation acc/loss: 0.860/0.417 / 0.810/0.450\n",
      "497: Training / validation acc/loss: 0.860/0.416 / 0.810/0.449\n",
      "498: Training / validation acc/loss: 0.860/0.415 / 0.810/0.448\n",
      "499: Training / validation acc/loss: 0.870/0.414 / 0.810/0.447\n",
      "500: Training / validation acc/loss: 0.870/0.413 / 0.810/0.446\n",
      "501: Training / validation acc/loss: 0.870/0.412 / 0.810/0.445\n",
      "502: Training / validation acc/loss: 0.870/0.411 / 0.810/0.444\n",
      "503: Training / validation acc/loss: 0.870/0.410 / 0.810/0.443\n",
      "504: Training / validation acc/loss: 0.880/0.409 / 0.810/0.442\n",
      "505: Training / validation acc/loss: 0.880/0.408 / 0.800/0.441\n",
      "506: Training / validation acc/loss: 0.890/0.406 / 0.810/0.440\n",
      "507: Training / validation acc/loss: 0.890/0.405 / 0.820/0.439\n",
      "508: Training / validation acc/loss: 0.880/0.403 / 0.820/0.438\n",
      "509: Training / validation acc/loss: 0.880/0.402 / 0.820/0.437\n",
      "510: Training / validation acc/loss: 0.880/0.401 / 0.830/0.436\n",
      "511: Training / validation acc/loss: 0.880/0.399 / 0.820/0.435\n",
      "512: Training / validation acc/loss: 0.880/0.398 / 0.820/0.434\n",
      "513: Training / validation acc/loss: 0.880/0.397 / 0.820/0.433\n",
      "514: Training / validation acc/loss: 0.880/0.396 / 0.820/0.431\n",
      "515: Training / validation acc/loss: 0.880/0.394 / 0.820/0.430\n",
      "516: Training / validation acc/loss: 0.880/0.393 / 0.820/0.429\n",
      "517: Training / validation acc/loss: 0.880/0.392 / 0.820/0.428\n",
      "518: Training / validation acc/loss: 0.880/0.390 / 0.830/0.427\n",
      "519: Training / validation acc/loss: 0.880/0.389 / 0.830/0.425\n",
      "520: Training / validation acc/loss: 0.880/0.388 / 0.830/0.424\n",
      "521: Training / validation acc/loss: 0.880/0.386 / 0.830/0.423\n",
      "522: Training / validation acc/loss: 0.880/0.385 / 0.830/0.422\n",
      "523: Training / validation acc/loss: 0.880/0.384 / 0.830/0.421\n",
      "524: Training / validation acc/loss: 0.880/0.383 / 0.830/0.420\n",
      "525: Training / validation acc/loss: 0.880/0.382 / 0.830/0.419\n",
      "526: Training / validation acc/loss: 0.880/0.380 / 0.830/0.417\n",
      "527: Training / validation acc/loss: 0.890/0.379 / 0.830/0.416\n",
      "528: Training / validation acc/loss: 0.880/0.378 / 0.830/0.415\n",
      "529: Training / validation acc/loss: 0.890/0.377 / 0.830/0.414\n",
      "530: Training / validation acc/loss: 0.880/0.376 / 0.830/0.413\n",
      "531: Training / validation acc/loss: 0.890/0.375 / 0.830/0.412\n",
      "532: Training / validation acc/loss: 0.890/0.374 / 0.830/0.411\n",
      "533: Training / validation acc/loss: 0.890/0.373 / 0.830/0.410\n",
      "534: Training / validation acc/loss: 0.900/0.372 / 0.830/0.409\n",
      "535: Training / validation acc/loss: 0.900/0.370 / 0.830/0.408\n",
      "536: Training / validation acc/loss: 0.900/0.369 / 0.830/0.407\n",
      "537: Training / validation acc/loss: 0.900/0.368 / 0.830/0.406\n",
      "538: Training / validation acc/loss: 0.900/0.367 / 0.830/0.405\n",
      "539: Training / validation acc/loss: 0.900/0.366 / 0.830/0.404\n",
      "540: Training / validation acc/loss: 0.900/0.365 / 0.830/0.403\n",
      "541: Training / validation acc/loss: 0.900/0.364 / 0.830/0.402\n",
      "542: Training / validation acc/loss: 0.900/0.363 / 0.830/0.401\n",
      "543: Training / validation acc/loss: 0.900/0.363 / 0.840/0.400\n",
      "544: Training / validation acc/loss: 0.900/0.362 / 0.840/0.399\n",
      "545: Training / validation acc/loss: 0.910/0.361 / 0.840/0.398\n",
      "546: Training / validation acc/loss: 0.910/0.360 / 0.840/0.397\n",
      "547: Training / validation acc/loss: 0.900/0.359 / 0.840/0.396\n",
      "548: Training / validation acc/loss: 0.910/0.358 / 0.840/0.395\n",
      "549: Training / validation acc/loss: 0.910/0.357 / 0.840/0.394\n",
      "550: Training / validation acc/loss: 0.910/0.356 / 0.840/0.393\n",
      "551: Training / validation acc/loss: 0.900/0.355 / 0.840/0.392\n",
      "552: Training / validation acc/loss: 0.910/0.354 / 0.840/0.391\n",
      "553: Training / validation acc/loss: 0.910/0.353 / 0.840/0.391\n",
      "554: Training / validation acc/loss: 0.910/0.352 / 0.840/0.390\n",
      "555: Training / validation acc/loss: 0.910/0.351 / 0.830/0.390\n",
      "556: Training / validation acc/loss: 0.910/0.350 / 0.840/0.389\n",
      "557: Training / validation acc/loss: 0.910/0.349 / 0.840/0.388\n",
      "558: Training / validation acc/loss: 0.910/0.347 / 0.850/0.387\n",
      "559: Training / validation acc/loss: 0.910/0.346 / 0.850/0.386\n",
      "560: Training / validation acc/loss: 0.920/0.345 / 0.850/0.385\n",
      "561: Training / validation acc/loss: 0.920/0.344 / 0.860/0.384\n",
      "562: Training / validation acc/loss: 0.920/0.343 / 0.850/0.383\n",
      "563: Training / validation acc/loss: 0.920/0.342 / 0.860/0.382\n",
      "564: Training / validation acc/loss: 0.920/0.341 / 0.850/0.381\n",
      "565: Training / validation acc/loss: 0.920/0.340 / 0.860/0.380\n",
      "566: Training / validation acc/loss: 0.920/0.339 / 0.850/0.379\n",
      "567: Training / validation acc/loss: 0.920/0.338 / 0.850/0.378\n",
      "568: Training / validation acc/loss: 0.930/0.337 / 0.850/0.377\n",
      "569: Training / validation acc/loss: 0.930/0.335 / 0.850/0.377\n",
      "570: Training / validation acc/loss: 0.930/0.334 / 0.860/0.376\n",
      "571: Training / validation acc/loss: 0.930/0.333 / 0.850/0.375\n",
      "572: Training / validation acc/loss: 0.930/0.332 / 0.850/0.374\n",
      "573: Training / validation acc/loss: 0.930/0.331 / 0.850/0.373\n",
      "574: Training / validation acc/loss: 0.930/0.329 / 0.850/0.372\n",
      "575: Training / validation acc/loss: 0.930/0.328 / 0.860/0.371\n",
      "576: Training / validation acc/loss: 0.930/0.327 / 0.860/0.370\n",
      "577: Training / validation acc/loss: 0.930/0.326 / 0.860/0.369\n",
      "578: Training / validation acc/loss: 0.930/0.325 / 0.860/0.368\n",
      "579: Training / validation acc/loss: 0.930/0.324 / 0.870/0.367\n",
      "580: Training / validation acc/loss: 0.930/0.323 / 0.860/0.366\n",
      "581: Training / validation acc/loss: 0.930/0.322 / 0.870/0.365\n",
      "582: Training / validation acc/loss: 0.930/0.321 / 0.860/0.364\n",
      "583: Training / validation acc/loss: 0.930/0.320 / 0.870/0.363\n",
      "584: Training / validation acc/loss: 0.930/0.319 / 0.860/0.362\n",
      "585: Training / validation acc/loss: 0.930/0.318 / 0.870/0.361\n",
      "586: Training / validation acc/loss: 0.930/0.317 / 0.860/0.360\n",
      "587: Training / validation acc/loss: 0.930/0.316 / 0.870/0.359\n",
      "588: Training / validation acc/loss: 0.930/0.315 / 0.860/0.358\n",
      "589: Training / validation acc/loss: 0.930/0.314 / 0.860/0.357\n",
      "590: Training / validation acc/loss: 0.930/0.313 / 0.870/0.356\n",
      "591: Training / validation acc/loss: 0.930/0.312 / 0.860/0.354\n",
      "592: Training / validation acc/loss: 0.930/0.311 / 0.870/0.354\n",
      "593: Training / validation acc/loss: 0.930/0.310 / 0.870/0.352\n",
      "594: Training / validation acc/loss: 0.930/0.309 / 0.880/0.351\n",
      "595: Training / validation acc/loss: 0.930/0.308 / 0.870/0.350\n",
      "596: Training / validation acc/loss: 0.930/0.307 / 0.870/0.349\n",
      "597: Training / validation acc/loss: 0.930/0.306 / 0.870/0.349\n",
      "598: Training / validation acc/loss: 0.930/0.306 / 0.880/0.348\n",
      "599: Training / validation acc/loss: 0.930/0.305 / 0.870/0.347\n",
      "600: Training / validation acc/loss: 0.940/0.304 / 0.870/0.346\n",
      "601: Training / validation acc/loss: 0.940/0.303 / 0.880/0.345\n",
      "602: Training / validation acc/loss: 0.940/0.302 / 0.870/0.344\n",
      "603: Training / validation acc/loss: 0.940/0.301 / 0.880/0.343\n",
      "604: Training / validation acc/loss: 0.940/0.301 / 0.880/0.342\n",
      "605: Training / validation acc/loss: 0.940/0.300 / 0.890/0.341\n",
      "606: Training / validation acc/loss: 0.940/0.299 / 0.880/0.340\n",
      "607: Training / validation acc/loss: 0.940/0.298 / 0.880/0.339\n",
      "608: Training / validation acc/loss: 0.940/0.297 / 0.880/0.340\n",
      "609: Training / validation acc/loss: 0.940/0.296 / 0.880/0.339\n",
      "610: Training / validation acc/loss: 0.940/0.295 / 0.870/0.338\n",
      "611: Training / validation acc/loss: 0.940/0.294 / 0.880/0.338\n",
      "612: Training / validation acc/loss: 0.940/0.293 / 0.870/0.337\n",
      "613: Training / validation acc/loss: 0.940/0.292 / 0.880/0.336\n",
      "614: Training / validation acc/loss: 0.940/0.291 / 0.870/0.335\n",
      "615: Training / validation acc/loss: 0.940/0.290 / 0.890/0.334\n",
      "616: Training / validation acc/loss: 0.940/0.289 / 0.880/0.333\n",
      "617: Training / validation acc/loss: 0.940/0.288 / 0.880/0.332\n",
      "618: Training / validation acc/loss: 0.940/0.286 / 0.880/0.330\n",
      "619: Training / validation acc/loss: 0.940/0.285 / 0.880/0.329\n",
      "620: Training / validation acc/loss: 0.940/0.284 / 0.880/0.328\n",
      "621: Training / validation acc/loss: 0.940/0.283 / 0.880/0.327\n",
      "622: Training / validation acc/loss: 0.940/0.282 / 0.880/0.325\n",
      "623: Training / validation acc/loss: 0.940/0.281 / 0.880/0.325\n",
      "624: Training / validation acc/loss: 0.950/0.280 / 0.880/0.324\n",
      "625: Training / validation acc/loss: 0.950/0.279 / 0.880/0.323\n",
      "626: Training / validation acc/loss: 0.950/0.278 / 0.880/0.322\n",
      "627: Training / validation acc/loss: 0.950/0.277 / 0.880/0.321\n",
      "628: Training / validation acc/loss: 0.950/0.276 / 0.880/0.320\n",
      "629: Training / validation acc/loss: 0.950/0.275 / 0.880/0.319\n",
      "630: Training / validation acc/loss: 0.960/0.274 / 0.870/0.317\n",
      "631: Training / validation acc/loss: 0.950/0.273 / 0.880/0.316\n",
      "632: Training / validation acc/loss: 0.960/0.272 / 0.870/0.315\n",
      "633: Training / validation acc/loss: 0.960/0.272 / 0.880/0.314\n",
      "634: Training / validation acc/loss: 0.960/0.271 / 0.870/0.313\n",
      "635: Training / validation acc/loss: 0.960/0.270 / 0.870/0.312\n",
      "636: Training / validation acc/loss: 0.960/0.269 / 0.880/0.311\n",
      "637: Training / validation acc/loss: 0.960/0.268 / 0.880/0.310\n",
      "638: Training / validation acc/loss: 0.960/0.267 / 0.880/0.309\n",
      "639: Training / validation acc/loss: 0.960/0.266 / 0.880/0.308\n",
      "640: Training / validation acc/loss: 0.960/0.265 / 0.880/0.307\n",
      "641: Training / validation acc/loss: 0.960/0.264 / 0.890/0.305\n",
      "642: Training / validation acc/loss: 0.960/0.264 / 0.880/0.304\n",
      "643: Training / validation acc/loss: 0.960/0.263 / 0.890/0.303\n",
      "644: Training / validation acc/loss: 0.960/0.262 / 0.890/0.302\n",
      "645: Training / validation acc/loss: 0.960/0.261 / 0.890/0.301\n",
      "646: Training / validation acc/loss: 0.960/0.260 / 0.890/0.300\n",
      "647: Training / validation acc/loss: 0.960/0.259 / 0.900/0.299\n",
      "648: Training / validation acc/loss: 0.960/0.258 / 0.900/0.298\n",
      "649: Training / validation acc/loss: 0.960/0.258 / 0.900/0.297\n",
      "650: Training / validation acc/loss: 0.960/0.257 / 0.890/0.295\n",
      "651: Training / validation acc/loss: 0.960/0.256 / 0.900/0.295\n",
      "652: Training / validation acc/loss: 0.960/0.255 / 0.890/0.293\n",
      "653: Training / validation acc/loss: 0.960/0.254 / 0.900/0.293\n",
      "654: Training / validation acc/loss: 0.960/0.253 / 0.890/0.291\n",
      "655: Training / validation acc/loss: 0.960/0.253 / 0.900/0.291\n",
      "656: Training / validation acc/loss: 0.960/0.252 / 0.890/0.289\n",
      "657: Training / validation acc/loss: 0.960/0.251 / 0.900/0.289\n",
      "658: Training / validation acc/loss: 0.960/0.250 / 0.890/0.287\n",
      "659: Training / validation acc/loss: 0.950/0.249 / 0.900/0.287\n",
      "660: Training / validation acc/loss: 0.960/0.249 / 0.890/0.285\n",
      "661: Training / validation acc/loss: 0.960/0.248 / 0.900/0.285\n",
      "662: Training / validation acc/loss: 0.960/0.247 / 0.890/0.284\n",
      "663: Training / validation acc/loss: 0.960/0.246 / 0.890/0.282\n",
      "664: Training / validation acc/loss: 0.960/0.245 / 0.890/0.281\n",
      "665: Training / validation acc/loss: 0.960/0.243 / 0.890/0.280\n",
      "666: Training / validation acc/loss: 0.960/0.242 / 0.880/0.279\n",
      "667: Training / validation acc/loss: 0.960/0.241 / 0.880/0.279\n",
      "668: Training / validation acc/loss: 0.960/0.239 / 0.890/0.277\n",
      "669: Training / validation acc/loss: 0.960/0.238 / 0.900/0.275\n",
      "670: Training / validation acc/loss: 0.960/0.236 / 0.900/0.274\n",
      "671: Training / validation acc/loss: 0.960/0.235 / 0.900/0.272\n",
      "672: Training / validation acc/loss: 0.950/0.234 / 0.900/0.271\n",
      "673: Training / validation acc/loss: 0.960/0.232 / 0.900/0.270\n",
      "674: Training / validation acc/loss: 0.950/0.231 / 0.900/0.269\n",
      "675: Training / validation acc/loss: 0.960/0.230 / 0.900/0.267\n",
      "676: Training / validation acc/loss: 0.950/0.228 / 0.910/0.266\n",
      "677: Training / validation acc/loss: 0.940/0.227 / 0.910/0.265\n",
      "678: Training / validation acc/loss: 0.940/0.226 / 0.920/0.264\n",
      "679: Training / validation acc/loss: 0.950/0.224 / 0.920/0.262\n",
      "680: Training / validation acc/loss: 0.940/0.223 / 0.920/0.261\n",
      "681: Training / validation acc/loss: 0.940/0.222 / 0.920/0.260\n",
      "682: Training / validation acc/loss: 0.950/0.221 / 0.930/0.258\n",
      "683: Training / validation acc/loss: 0.940/0.219 / 0.920/0.258\n",
      "684: Training / validation acc/loss: 0.940/0.218 / 0.930/0.255\n",
      "685: Training / validation acc/loss: 0.940/0.217 / 0.920/0.255\n",
      "686: Training / validation acc/loss: 0.940/0.216 / 0.930/0.253\n",
      "687: Training / validation acc/loss: 0.940/0.214 / 0.920/0.252\n",
      "688: Training / validation acc/loss: 0.940/0.213 / 0.930/0.250\n",
      "689: Training / validation acc/loss: 0.940/0.212 / 0.930/0.250\n",
      "690: Training / validation acc/loss: 0.940/0.211 / 0.930/0.248\n",
      "691: Training / validation acc/loss: 0.940/0.210 / 0.930/0.248\n",
      "692: Training / validation acc/loss: 0.940/0.209 / 0.930/0.247\n",
      "693: Training / validation acc/loss: 0.940/0.208 / 0.930/0.245\n",
      "694: Training / validation acc/loss: 0.940/0.206 / 0.930/0.244\n",
      "695: Training / validation acc/loss: 0.940/0.205 / 0.940/0.243\n",
      "696: Training / validation acc/loss: 0.940/0.204 / 0.940/0.242\n",
      "697: Training / validation acc/loss: 0.940/0.203 / 0.940/0.240\n",
      "698: Training / validation acc/loss: 0.940/0.202 / 0.940/0.240\n",
      "699: Training / validation acc/loss: 0.940/0.201 / 0.940/0.238\n",
      "700: Training / validation acc/loss: 0.940/0.200 / 0.940/0.237\n",
      "701: Training / validation acc/loss: 0.940/0.199 / 0.940/0.236\n",
      "702: Training / validation acc/loss: 0.940/0.197 / 0.950/0.234\n",
      "703: Training / validation acc/loss: 0.940/0.196 / 0.940/0.234\n",
      "704: Training / validation acc/loss: 0.940/0.195 / 0.950/0.232\n",
      "705: Training / validation acc/loss: 0.940/0.194 / 0.940/0.232\n",
      "706: Training / validation acc/loss: 0.940/0.193 / 0.950/0.229\n",
      "707: Training / validation acc/loss: 0.940/0.192 / 0.950/0.230\n",
      "708: Training / validation acc/loss: 0.950/0.191 / 0.950/0.228\n",
      "709: Training / validation acc/loss: 0.940/0.190 / 0.950/0.227\n",
      "710: Training / validation acc/loss: 0.950/0.189 / 0.950/0.225\n",
      "711: Training / validation acc/loss: 0.940/0.188 / 0.950/0.225\n",
      "712: Training / validation acc/loss: 0.950/0.187 / 0.950/0.223\n",
      "713: Training / validation acc/loss: 0.940/0.186 / 0.950/0.223\n",
      "714: Training / validation acc/loss: 0.950/0.185 / 0.950/0.221\n",
      "715: Training / validation acc/loss: 0.940/0.184 / 0.950/0.221\n",
      "716: Training / validation acc/loss: 0.950/0.183 / 0.950/0.219\n",
      "717: Training / validation acc/loss: 0.950/0.182 / 0.950/0.218\n",
      "718: Training / validation acc/loss: 0.950/0.181 / 0.950/0.217\n",
      "719: Training / validation acc/loss: 0.950/0.180 / 0.950/0.216\n",
      "720: Training / validation acc/loss: 0.960/0.179 / 0.960/0.214\n",
      "721: Training / validation acc/loss: 0.950/0.178 / 0.960/0.213\n",
      "722: Training / validation acc/loss: 0.950/0.177 / 0.960/0.212\n",
      "723: Training / validation acc/loss: 0.950/0.176 / 0.960/0.212\n",
      "724: Training / validation acc/loss: 0.970/0.175 / 0.960/0.210\n",
      "725: Training / validation acc/loss: 0.960/0.174 / 0.970/0.211\n",
      "726: Training / validation acc/loss: 0.970/0.174 / 0.970/0.207\n",
      "727: Training / validation acc/loss: 0.960/0.173 / 0.970/0.208\n",
      "728: Training / validation acc/loss: 0.970/0.172 / 0.980/0.205\n",
      "729: Training / validation acc/loss: 0.960/0.171 / 0.970/0.206\n",
      "730: Training / validation acc/loss: 0.970/0.170 / 0.980/0.204\n",
      "731: Training / validation acc/loss: 0.970/0.169 / 0.970/0.205\n",
      "732: Training / validation acc/loss: 0.970/0.168 / 0.980/0.202\n",
      "733: Training / validation acc/loss: 0.970/0.167 / 0.970/0.203\n",
      "734: Training / validation acc/loss: 0.970/0.166 / 0.980/0.200\n",
      "735: Training / validation acc/loss: 0.970/0.165 / 0.970/0.201\n",
      "736: Training / validation acc/loss: 0.970/0.164 / 0.980/0.198\n",
      "737: Training / validation acc/loss: 0.970/0.164 / 0.970/0.200\n",
      "738: Training / validation acc/loss: 0.970/0.163 / 0.980/0.197\n",
      "739: Training / validation acc/loss: 0.970/0.162 / 0.980/0.198\n",
      "740: Training / validation acc/loss: 0.970/0.161 / 0.990/0.195\n",
      "741: Training / validation acc/loss: 0.970/0.160 / 0.980/0.196\n",
      "742: Training / validation acc/loss: 0.970/0.159 / 0.990/0.194\n",
      "743: Training / validation acc/loss: 0.970/0.159 / 0.990/0.195\n",
      "744: Training / validation acc/loss: 0.970/0.158 / 0.990/0.192\n",
      "745: Training / validation acc/loss: 0.970/0.157 / 0.990/0.193\n",
      "746: Training / validation acc/loss: 0.980/0.156 / 0.990/0.190\n",
      "747: Training / validation acc/loss: 0.970/0.155 / 0.990/0.191\n",
      "748: Training / validation acc/loss: 0.980/0.155 / 0.990/0.189\n",
      "749: Training / validation acc/loss: 0.980/0.154 / 0.990/0.189\n",
      "750: Training / validation acc/loss: 0.980/0.153 / 0.990/0.187\n",
      "751: Training / validation acc/loss: 0.980/0.152 / 0.990/0.187\n",
      "752: Training / validation acc/loss: 0.990/0.151 / 0.990/0.185\n",
      "753: Training / validation acc/loss: 0.980/0.151 / 0.990/0.186\n",
      "754: Training / validation acc/loss: 0.990/0.150 / 0.990/0.183\n",
      "755: Training / validation acc/loss: 0.990/0.149 / 0.990/0.184\n",
      "756: Training / validation acc/loss: 0.990/0.148 / 0.990/0.182\n",
      "757: Training / validation acc/loss: 0.990/0.148 / 0.990/0.182\n",
      "758: Training / validation acc/loss: 0.990/0.147 / 0.990/0.180\n",
      "759: Training / validation acc/loss: 0.990/0.146 / 0.990/0.180\n",
      "760: Training / validation acc/loss: 0.990/0.145 / 0.990/0.178\n",
      "761: Training / validation acc/loss: 0.990/0.145 / 1.000/0.179\n",
      "762: Training / validation acc/loss: 1.000/0.144 / 0.990/0.176\n",
      "763: Training / validation acc/loss: 0.990/0.143 / 1.000/0.177\n",
      "764: Training / validation acc/loss: 1.000/0.142 / 1.000/0.175\n",
      "765: Training / validation acc/loss: 1.000/0.142 / 1.000/0.175\n",
      "766: Training / validation acc/loss: 1.000/0.141 / 1.000/0.173\n",
      "767: Training / validation acc/loss: 1.000/0.140 / 1.000/0.173\n",
      "768: Training / validation acc/loss: 1.000/0.140 / 1.000/0.171\n",
      "769: Training / validation acc/loss: 1.000/0.139 / 1.000/0.171\n",
      "770: Training / validation acc/loss: 1.000/0.138 / 1.000/0.170\n",
      "771: Training / validation acc/loss: 1.000/0.137 / 1.000/0.169\n",
      "772: Training / validation acc/loss: 1.000/0.137 / 1.000/0.169\n",
      "773: Training / validation acc/loss: 1.000/0.136 / 1.000/0.168\n",
      "774: Training / validation acc/loss: 1.000/0.135 / 1.000/0.166\n",
      "775: Training / validation acc/loss: 1.000/0.135 / 1.000/0.166\n",
      "776: Training / validation acc/loss: 1.000/0.134 / 1.000/0.165\n",
      "777: Training / validation acc/loss: 1.000/0.133 / 1.000/0.164\n",
      "778: Training / validation acc/loss: 1.000/0.132 / 1.000/0.163\n",
      "779: Training / validation acc/loss: 1.000/0.132 / 1.000/0.163\n",
      "780: Training / validation acc/loss: 1.000/0.131 / 1.000/0.162\n",
      "781: Training / validation acc/loss: 1.000/0.130 / 1.000/0.161\n",
      "782: Training / validation acc/loss: 1.000/0.130 / 1.000/0.160\n",
      "783: Training / validation acc/loss: 1.000/0.129 / 1.000/0.160\n",
      "784: Training / validation acc/loss: 1.000/0.128 / 1.000/0.159\n",
      "785: Training / validation acc/loss: 1.000/0.128 / 1.000/0.158\n",
      "786: Training / validation acc/loss: 1.000/0.127 / 1.000/0.157\n",
      "787: Training / validation acc/loss: 1.000/0.127 / 1.000/0.156\n",
      "788: Training / validation acc/loss: 1.000/0.126 / 1.000/0.156\n",
      "789: Training / validation acc/loss: 1.000/0.125 / 1.000/0.155\n",
      "790: Training / validation acc/loss: 1.000/0.125 / 1.000/0.155\n",
      "791: Training / validation acc/loss: 1.000/0.124 / 1.000/0.153\n",
      "792: Training / validation acc/loss: 1.000/0.123 / 1.000/0.153\n",
      "793: Training / validation acc/loss: 1.000/0.123 / 1.000/0.152\n",
      "794: Training / validation acc/loss: 1.000/0.122 / 1.000/0.152\n",
      "795: Training / validation acc/loss: 1.000/0.122 / 1.000/0.151\n",
      "796: Training / validation acc/loss: 1.000/0.121 / 1.000/0.151\n",
      "797: Training / validation acc/loss: 1.000/0.120 / 1.000/0.149\n",
      "798: Training / validation acc/loss: 1.000/0.120 / 1.000/0.149\n",
      "799: Training / validation acc/loss: 1.000/0.119 / 1.000/0.148\n",
      "800: Training / validation acc/loss: 1.000/0.119 / 1.000/0.148\n",
      "801: Training / validation acc/loss: 1.000/0.118 / 1.000/0.147\n",
      "802: Training / validation acc/loss: 1.000/0.117 / 1.000/0.146\n",
      "803: Training / validation acc/loss: 1.000/0.117 / 1.000/0.145\n",
      "804: Training / validation acc/loss: 1.000/0.116 / 1.000/0.145\n",
      "805: Training / validation acc/loss: 1.000/0.116 / 1.000/0.144\n",
      "806: Training / validation acc/loss: 1.000/0.115 / 1.000/0.144\n",
      "807: Training / validation acc/loss: 1.000/0.115 / 1.000/0.143\n",
      "808: Training / validation acc/loss: 1.000/0.114 / 1.000/0.142\n",
      "809: Training / validation acc/loss: 1.000/0.113 / 1.000/0.142\n",
      "810: Training / validation acc/loss: 1.000/0.113 / 1.000/0.141\n",
      "811: Training / validation acc/loss: 1.000/0.112 / 1.000/0.140\n",
      "812: Training / validation acc/loss: 1.000/0.112 / 1.000/0.140\n",
      "813: Training / validation acc/loss: 1.000/0.111 / 1.000/0.139\n",
      "814: Training / validation acc/loss: 1.000/0.111 / 1.000/0.138\n",
      "815: Training / validation acc/loss: 1.000/0.110 / 1.000/0.138\n",
      "816: Training / validation acc/loss: 1.000/0.110 / 1.000/0.137\n",
      "817: Training / validation acc/loss: 1.000/0.109 / 1.000/0.137\n",
      "818: Training / validation acc/loss: 1.000/0.108 / 1.000/0.136\n",
      "819: Training / validation acc/loss: 1.000/0.108 / 1.000/0.135\n",
      "820: Training / validation acc/loss: 1.000/0.107 / 1.000/0.135\n",
      "821: Training / validation acc/loss: 1.000/0.107 / 1.000/0.134\n",
      "822: Training / validation acc/loss: 1.000/0.106 / 1.000/0.133\n",
      "823: Training / validation acc/loss: 1.000/0.106 / 1.000/0.133\n",
      "824: Training / validation acc/loss: 1.000/0.105 / 1.000/0.133\n",
      "825: Training / validation acc/loss: 1.000/0.105 / 1.000/0.132\n",
      "826: Training / validation acc/loss: 1.000/0.104 / 1.000/0.132\n",
      "827: Training / validation acc/loss: 1.000/0.104 / 1.000/0.131\n",
      "828: Training / validation acc/loss: 1.000/0.103 / 1.000/0.130\n",
      "829: Training / validation acc/loss: 1.000/0.103 / 1.000/0.130\n",
      "830: Training / validation acc/loss: 1.000/0.102 / 1.000/0.129\n",
      "831: Training / validation acc/loss: 1.000/0.102 / 1.000/0.129\n",
      "832: Training / validation acc/loss: 1.000/0.101 / 1.000/0.128\n",
      "833: Training / validation acc/loss: 1.000/0.101 / 1.000/0.128\n",
      "834: Training / validation acc/loss: 1.000/0.100 / 1.000/0.127\n",
      "835: Training / validation acc/loss: 1.000/0.100 / 1.000/0.127\n",
      "836: Training / validation acc/loss: 1.000/0.099 / 1.000/0.126\n",
      "837: Training / validation acc/loss: 1.000/0.099 / 1.000/0.126\n",
      "838: Training / validation acc/loss: 1.000/0.099 / 1.000/0.125\n",
      "839: Training / validation acc/loss: 1.000/0.098 / 1.000/0.125\n",
      "840: Training / validation acc/loss: 1.000/0.098 / 1.000/0.124\n",
      "841: Training / validation acc/loss: 1.000/0.097 / 1.000/0.124\n",
      "842: Training / validation acc/loss: 1.000/0.097 / 1.000/0.123\n",
      "843: Training / validation acc/loss: 1.000/0.096 / 1.000/0.123\n",
      "844: Training / validation acc/loss: 1.000/0.096 / 1.000/0.122\n",
      "845: Training / validation acc/loss: 1.000/0.095 / 1.000/0.121\n",
      "846: Training / validation acc/loss: 1.000/0.095 / 1.000/0.121\n",
      "847: Training / validation acc/loss: 1.000/0.095 / 1.000/0.120\n",
      "848: Training / validation acc/loss: 1.000/0.094 / 1.000/0.120\n",
      "849: Training / validation acc/loss: 1.000/0.094 / 1.000/0.119\n",
      "850: Training / validation acc/loss: 1.000/0.093 / 1.000/0.119\n",
      "851: Training / validation acc/loss: 1.000/0.093 / 1.000/0.118\n",
      "852: Training / validation acc/loss: 1.000/0.093 / 1.000/0.118\n",
      "853: Training / validation acc/loss: 1.000/0.092 / 1.000/0.118\n",
      "854: Training / validation acc/loss: 1.000/0.092 / 1.000/0.117\n",
      "855: Training / validation acc/loss: 1.000/0.091 / 1.000/0.117\n",
      "856: Training / validation acc/loss: 1.000/0.091 / 1.000/0.116\n",
      "857: Training / validation acc/loss: 1.000/0.090 / 1.000/0.116\n",
      "858: Training / validation acc/loss: 1.000/0.090 / 1.000/0.115\n",
      "859: Training / validation acc/loss: 1.000/0.090 / 1.000/0.115\n",
      "860: Training / validation acc/loss: 1.000/0.089 / 1.000/0.114\n",
      "861: Training / validation acc/loss: 1.000/0.089 / 1.000/0.114\n",
      "862: Training / validation acc/loss: 1.000/0.089 / 1.000/0.114\n",
      "863: Training / validation acc/loss: 1.000/0.088 / 1.000/0.113\n",
      "864: Training / validation acc/loss: 1.000/0.088 / 1.000/0.113\n",
      "865: Training / validation acc/loss: 1.000/0.087 / 1.000/0.112\n",
      "866: Training / validation acc/loss: 1.000/0.087 / 1.000/0.112\n",
      "867: Training / validation acc/loss: 1.000/0.087 / 1.000/0.111\n",
      "868: Training / validation acc/loss: 1.000/0.086 / 1.000/0.111\n",
      "869: Training / validation acc/loss: 1.000/0.086 / 1.000/0.111\n",
      "870: Training / validation acc/loss: 1.000/0.086 / 1.000/0.110\n",
      "871: Training / validation acc/loss: 1.000/0.085 / 1.000/0.110\n",
      "872: Training / validation acc/loss: 1.000/0.085 / 1.000/0.109\n",
      "873: Training / validation acc/loss: 1.000/0.084 / 1.000/0.109\n",
      "874: Training / validation acc/loss: 1.000/0.084 / 1.000/0.108\n",
      "875: Training / validation acc/loss: 1.000/0.084 / 1.000/0.108\n",
      "876: Training / validation acc/loss: 1.000/0.083 / 1.000/0.107\n",
      "877: Training / validation acc/loss: 1.000/0.083 / 1.000/0.107\n",
      "878: Training / validation acc/loss: 1.000/0.083 / 1.000/0.107\n",
      "879: Training / validation acc/loss: 1.000/0.082 / 1.000/0.106\n",
      "880: Training / validation acc/loss: 1.000/0.082 / 1.000/0.106\n",
      "881: Training / validation acc/loss: 1.000/0.082 / 1.000/0.105\n",
      "882: Training / validation acc/loss: 1.000/0.081 / 1.000/0.105\n",
      "883: Training / validation acc/loss: 1.000/0.081 / 1.000/0.105\n",
      "884: Training / validation acc/loss: 1.000/0.081 / 1.000/0.104\n",
      "885: Training / validation acc/loss: 1.000/0.080 / 1.000/0.104\n",
      "886: Training / validation acc/loss: 1.000/0.080 / 1.000/0.103\n",
      "887: Training / validation acc/loss: 1.000/0.080 / 1.000/0.103\n",
      "888: Training / validation acc/loss: 1.000/0.079 / 1.000/0.102\n",
      "889: Training / validation acc/loss: 1.000/0.079 / 1.000/0.102\n",
      "890: Training / validation acc/loss: 1.000/0.079 / 1.000/0.102\n",
      "891: Training / validation acc/loss: 1.000/0.078 / 1.000/0.101\n",
      "892: Training / validation acc/loss: 1.000/0.078 / 1.000/0.101\n",
      "893: Training / validation acc/loss: 1.000/0.078 / 1.000/0.101\n",
      "894: Training / validation acc/loss: 1.000/0.077 / 1.000/0.100\n",
      "895: Training / validation acc/loss: 1.000/0.077 / 1.000/0.100\n",
      "896: Training / validation acc/loss: 1.000/0.077 / 1.000/0.099\n",
      "897: Training / validation acc/loss: 1.000/0.077 / 1.000/0.099\n",
      "898: Training / validation acc/loss: 1.000/0.076 / 1.000/0.099\n",
      "899: Training / validation acc/loss: 1.000/0.076 / 1.000/0.098\n",
      "900: Training / validation acc/loss: 1.000/0.076 / 1.000/0.098\n",
      "901: Training / validation acc/loss: 1.000/0.075 / 1.000/0.098\n",
      "902: Training / validation acc/loss: 1.000/0.075 / 1.000/0.098\n",
      "903: Training / validation acc/loss: 1.000/0.075 / 1.000/0.097\n",
      "904: Training / validation acc/loss: 1.000/0.074 / 1.000/0.097\n",
      "905: Training / validation acc/loss: 1.000/0.074 / 1.000/0.097\n",
      "906: Training / validation acc/loss: 1.000/0.074 / 1.000/0.097\n",
      "907: Training / validation acc/loss: 1.000/0.074 / 1.000/0.096\n",
      "908: Training / validation acc/loss: 1.000/0.073 / 1.000/0.096\n",
      "909: Training / validation acc/loss: 1.000/0.073 / 1.000/0.096\n",
      "910: Training / validation acc/loss: 1.000/0.073 / 1.000/0.095\n",
      "911: Training / validation acc/loss: 1.000/0.073 / 1.000/0.095\n",
      "912: Training / validation acc/loss: 1.000/0.072 / 1.000/0.095\n",
      "913: Training / validation acc/loss: 1.000/0.072 / 1.000/0.094\n",
      "914: Training / validation acc/loss: 1.000/0.072 / 1.000/0.094\n",
      "915: Training / validation acc/loss: 1.000/0.072 / 1.000/0.094\n",
      "916: Training / validation acc/loss: 1.000/0.071 / 1.000/0.093\n",
      "917: Training / validation acc/loss: 1.000/0.071 / 1.000/0.093\n",
      "918: Training / validation acc/loss: 1.000/0.071 / 1.000/0.093\n",
      "919: Training / validation acc/loss: 1.000/0.070 / 1.000/0.092\n",
      "920: Training / validation acc/loss: 1.000/0.070 / 1.000/0.092\n",
      "921: Training / validation acc/loss: 1.000/0.070 / 1.000/0.092\n",
      "922: Training / validation acc/loss: 1.000/0.070 / 1.000/0.092\n",
      "923: Training / validation acc/loss: 1.000/0.069 / 1.000/0.091\n",
      "924: Training / validation acc/loss: 1.000/0.069 / 1.000/0.091\n",
      "925: Training / validation acc/loss: 1.000/0.069 / 1.000/0.090\n",
      "926: Training / validation acc/loss: 1.000/0.069 / 1.000/0.090\n",
      "927: Training / validation acc/loss: 1.000/0.068 / 1.000/0.090\n",
      "928: Training / validation acc/loss: 1.000/0.068 / 1.000/0.090\n",
      "929: Training / validation acc/loss: 1.000/0.068 / 1.000/0.090\n",
      "930: Training / validation acc/loss: 1.000/0.068 / 1.000/0.089\n",
      "931: Training / validation acc/loss: 1.000/0.067 / 1.000/0.089\n",
      "932: Training / validation acc/loss: 1.000/0.067 / 1.000/0.089\n",
      "933: Training / validation acc/loss: 1.000/0.067 / 1.000/0.088\n",
      "934: Training / validation acc/loss: 1.000/0.067 / 1.000/0.088\n",
      "935: Training / validation acc/loss: 1.000/0.067 / 1.000/0.088\n",
      "936: Training / validation acc/loss: 1.000/0.066 / 1.000/0.087\n",
      "937: Training / validation acc/loss: 1.000/0.066 / 1.000/0.087\n",
      "938: Training / validation acc/loss: 1.000/0.066 / 1.000/0.087\n",
      "939: Training / validation acc/loss: 1.000/0.066 / 1.000/0.087\n",
      "940: Training / validation acc/loss: 1.000/0.065 / 1.000/0.086\n",
      "941: Training / validation acc/loss: 1.000/0.065 / 1.000/0.086\n",
      "942: Training / validation acc/loss: 1.000/0.065 / 1.000/0.086\n",
      "943: Training / validation acc/loss: 1.000/0.065 / 1.000/0.086\n",
      "944: Training / validation acc/loss: 1.000/0.064 / 1.000/0.085\n",
      "945: Training / validation acc/loss: 1.000/0.064 / 1.000/0.085\n",
      "946: Training / validation acc/loss: 1.000/0.064 / 1.000/0.085\n",
      "947: Training / validation acc/loss: 1.000/0.064 / 1.000/0.085\n",
      "948: Training / validation acc/loss: 1.000/0.064 / 1.000/0.084\n",
      "949: Training / validation acc/loss: 1.000/0.063 / 1.000/0.084\n",
      "950: Training / validation acc/loss: 1.000/0.063 / 1.000/0.084\n",
      "951: Training / validation acc/loss: 1.000/0.063 / 1.000/0.083\n",
      "952: Training / validation acc/loss: 1.000/0.063 / 1.000/0.083\n",
      "953: Training / validation acc/loss: 1.000/0.062 / 1.000/0.083\n",
      "954: Training / validation acc/loss: 1.000/0.062 / 1.000/0.082\n",
      "955: Training / validation acc/loss: 1.000/0.062 / 1.000/0.083\n",
      "956: Training / validation acc/loss: 1.000/0.062 / 1.000/0.082\n",
      "957: Training / validation acc/loss: 1.000/0.062 / 1.000/0.082\n",
      "958: Training / validation acc/loss: 1.000/0.061 / 1.000/0.082\n",
      "959: Training / validation acc/loss: 1.000/0.061 / 1.000/0.082\n",
      "960: Training / validation acc/loss: 1.000/0.061 / 1.000/0.081\n",
      "961: Training / validation acc/loss: 1.000/0.061 / 1.000/0.081\n",
      "962: Training / validation acc/loss: 1.000/0.061 / 1.000/0.081\n",
      "963: Training / validation acc/loss: 1.000/0.060 / 1.000/0.081\n",
      "964: Training / validation acc/loss: 1.000/0.060 / 1.000/0.080\n",
      "965: Training / validation acc/loss: 1.000/0.060 / 1.000/0.081\n",
      "966: Training / validation acc/loss: 1.000/0.060 / 1.000/0.080\n",
      "967: Training / validation acc/loss: 1.000/0.060 / 1.000/0.080\n",
      "968: Training / validation acc/loss: 1.000/0.059 / 1.000/0.080\n",
      "969: Training / validation acc/loss: 1.000/0.059 / 1.000/0.080\n",
      "970: Training / validation acc/loss: 1.000/0.059 / 1.000/0.079\n",
      "971: Training / validation acc/loss: 1.000/0.059 / 1.000/0.079\n",
      "972: Training / validation acc/loss: 1.000/0.059 / 1.000/0.079\n",
      "973: Training / validation acc/loss: 1.000/0.058 / 1.000/0.079\n",
      "974: Training / validation acc/loss: 1.000/0.058 / 1.000/0.079\n",
      "975: Training / validation acc/loss: 1.000/0.058 / 1.000/0.079\n",
      "976: Training / validation acc/loss: 1.000/0.058 / 1.000/0.078\n",
      "977: Training / validation acc/loss: 1.000/0.058 / 1.000/0.078\n",
      "978: Training / validation acc/loss: 1.000/0.058 / 1.000/0.078\n",
      "979: Training / validation acc/loss: 1.000/0.057 / 1.000/0.078\n",
      "980: Training / validation acc/loss: 1.000/0.057 / 1.000/0.077\n",
      "981: Training / validation acc/loss: 1.000/0.057 / 1.000/0.077\n",
      "982: Training / validation acc/loss: 1.000/0.057 / 1.000/0.077\n",
      "983: Training / validation acc/loss: 1.000/0.057 / 1.000/0.077\n",
      "984: Training / validation acc/loss: 1.000/0.056 / 1.000/0.076\n",
      "985: Training / validation acc/loss: 1.000/0.056 / 1.000/0.076\n",
      "986: Training / validation acc/loss: 1.000/0.056 / 1.000/0.076\n",
      "987: Training / validation acc/loss: 1.000/0.056 / 1.000/0.076\n",
      "988: Training / validation acc/loss: 1.000/0.056 / 1.000/0.076\n",
      "989: Training / validation acc/loss: 1.000/0.056 / 1.000/0.075\n",
      "990: Training / validation acc/loss: 1.000/0.055 / 1.000/0.075\n",
      "991: Training / validation acc/loss: 1.000/0.055 / 1.000/0.075\n",
      "992: Training / validation acc/loss: 1.000/0.055 / 1.000/0.075\n",
      "993: Training / validation acc/loss: 1.000/0.055 / 1.000/0.074\n",
      "994: Training / validation acc/loss: 1.000/0.055 / 1.000/0.074\n",
      "995: Training / validation acc/loss: 1.000/0.055 / 1.000/0.074\n",
      "996: Training / validation acc/loss: 1.000/0.054 / 1.000/0.074\n",
      "997: Training / validation acc/loss: 1.000/0.054 / 1.000/0.074\n",
      "998: Training / validation acc/loss: 1.000/0.054 / 1.000/0.073\n",
      "999: Training / validation acc/loss: 1.000/0.054 / 1.000/0.073\n"
     ]
    }
   ],
   "source": [
    "scale_and_train(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cbda37-3a52-48b9-8d58-d12bf2a6f142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:02:01.116304Z",
     "iopub.status.busy": "2023-04-19T20:02:01.115067Z",
     "iopub.status.idle": "2023-04-19T20:02:01.121245Z",
     "shell.execute_reply": "2023-04-19T20:02:01.120669Z",
     "shell.execute_reply.started": "2023-04-19T20:02:01.116304Z"
    }
   },
   "source": [
    "By scaling the data by factor of 0.1 we've moved the convergence moment by about 700 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2d2c45a3-eabf-47d3-9c23-9e88eef9db5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:02:30.346880Z",
     "iopub.status.busy": "2023-04-19T20:02:30.346132Z",
     "iopub.status.idle": "2023-04-19T20:02:32.543123Z",
     "shell.execute_reply": "2023-04-19T20:02:32.542292Z",
     "shell.execute_reply.started": "2023-04-19T20:02:30.346853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.500/25.619 / 0.500/152.772\n",
      "1: Training / validation acc/loss: 0.500/160.012 / 0.500/4.484\n",
      "2: Training / validation acc/loss: 0.500/4.760 / 0.500/0.693\n",
      "3: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "4: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "5: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "6: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "7: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "8: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "9: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "10: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "11: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "12: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "13: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "14: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "15: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "16: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "17: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "18: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "19: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "20: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "21: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "22: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "23: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "24: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "25: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "26: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "27: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "28: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "29: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "30: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "31: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "32: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "33: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "34: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "35: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "36: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "37: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "38: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "39: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "40: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "41: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "42: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "43: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "44: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "45: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "46: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "47: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "48: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "49: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "50: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "51: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "52: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "53: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "54: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "55: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "56: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "57: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "58: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "59: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "60: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "61: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "62: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "63: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "64: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "65: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "66: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "67: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "68: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "69: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "70: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "71: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "72: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "73: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "74: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "75: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "76: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "77: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "78: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "79: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "80: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "81: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "82: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "83: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "84: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "85: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "86: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "87: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "88: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "89: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "90: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "91: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "92: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "93: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "94: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "95: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "96: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "97: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "98: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "99: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "100: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "101: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "102: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "103: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "104: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "105: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "106: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "107: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "108: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "109: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "110: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "111: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "112: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "113: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "114: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "115: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "116: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "117: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "118: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "119: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "120: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "121: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "122: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "123: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "124: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "125: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "126: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "127: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "128: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "129: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "130: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "131: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "132: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "133: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "134: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "135: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "136: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "137: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "138: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "139: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "140: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "141: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "142: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "143: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "144: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "145: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "146: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "147: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "148: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "149: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "150: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "151: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "152: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "153: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "154: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "155: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "156: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "157: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "158: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "159: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "160: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "161: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "162: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "163: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "164: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "165: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "166: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "167: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "168: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "169: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "170: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "171: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "172: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "173: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "174: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "175: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "176: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "177: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "178: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "179: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "180: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "181: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "182: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "183: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "184: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "185: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "186: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "187: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "188: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "189: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "190: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "191: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "192: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "193: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "194: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "195: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "196: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "197: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "198: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "199: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "200: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "201: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "202: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "203: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "204: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "205: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "206: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "207: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "208: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "209: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "210: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "211: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "212: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "213: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "214: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "215: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "216: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "217: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "218: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "219: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "220: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "221: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "222: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "223: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "224: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "225: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "226: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "227: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "228: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "229: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "230: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "231: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "232: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "233: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "234: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "235: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "236: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "237: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "238: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "239: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "240: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "241: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "242: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "243: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "244: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "245: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "246: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "247: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "248: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "249: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "250: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "251: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "252: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "253: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "254: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "255: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "256: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "257: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "258: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "259: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "260: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "261: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "262: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "263: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "264: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "265: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "266: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "267: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "268: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "269: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "270: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "271: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "272: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "273: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "274: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "275: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "276: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "277: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "278: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "279: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "280: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "281: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "282: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "283: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "284: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "285: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "286: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "287: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "288: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "289: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "290: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "291: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "292: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "293: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "294: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "295: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "296: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "297: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "298: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "299: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "300: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "301: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "302: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "303: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "304: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "305: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "306: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "307: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "308: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "309: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "310: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "311: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "312: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "313: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "314: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "315: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "316: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "317: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "318: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "319: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "320: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "321: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "322: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "323: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "324: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "325: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "326: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "327: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "328: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "329: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "330: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "331: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "332: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "333: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "334: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "335: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "336: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "337: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "338: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "339: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "340: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "341: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "342: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "343: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "344: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "345: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "346: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "347: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "348: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "349: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "350: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "351: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "352: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "353: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "354: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "355: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "356: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "357: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "358: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "359: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "360: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "361: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "362: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "363: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "364: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "365: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "366: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "367: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "368: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "369: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "370: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "371: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "372: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "373: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "374: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "375: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "376: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "377: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "378: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "379: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "380: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "381: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "382: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "383: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "384: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "385: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "386: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "387: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "388: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "389: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "390: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "391: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "392: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "393: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "394: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "395: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "396: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "397: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "398: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "399: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "400: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "401: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "402: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "403: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "404: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "405: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "406: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "407: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "408: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "409: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "410: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "411: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "412: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "413: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "414: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "415: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "416: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "417: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "418: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "419: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "420: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "421: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "422: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "423: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "424: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "425: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "426: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "427: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "428: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "429: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "430: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "431: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "432: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "433: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "434: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "435: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "436: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "437: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "438: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "439: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "440: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "441: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "442: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "443: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "444: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "445: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "446: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "447: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "448: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "449: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "450: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "451: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "452: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "453: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "454: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "455: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "456: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "457: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "458: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "459: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "460: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "461: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "462: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "463: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "464: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "465: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "466: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "467: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "468: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "469: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "470: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "471: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "472: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "473: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "474: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "475: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "476: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "477: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "478: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "479: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "480: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "481: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "482: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "483: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "484: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "485: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "486: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "487: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "488: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "489: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "490: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "491: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "492: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "493: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "494: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "495: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "496: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "497: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "498: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "499: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "500: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "501: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "502: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "503: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "504: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "505: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "506: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "507: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "508: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "509: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "510: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "511: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "512: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "513: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "514: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "515: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "516: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "517: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "518: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "519: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "520: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "521: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "522: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "523: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "524: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "525: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "526: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "527: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "528: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "529: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "530: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "531: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "532: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "533: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "534: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "535: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "536: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "537: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "538: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "539: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "540: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "541: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "542: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "543: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "544: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "545: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "546: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "547: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "548: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "549: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "550: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "551: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "552: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "553: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "554: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "555: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "556: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "557: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "558: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "559: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "560: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "561: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "562: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "563: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "564: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "565: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "566: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "567: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "568: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "569: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "570: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "571: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "572: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "573: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "574: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "575: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "576: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "577: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "578: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "579: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "580: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "581: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "582: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "583: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "584: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "585: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "586: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "587: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "588: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "589: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "590: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "591: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "592: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "593: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "594: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "595: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "596: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "597: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "598: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "599: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "600: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "601: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "602: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "603: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "604: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "605: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "606: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "607: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "608: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "609: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "610: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "611: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "612: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "613: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "614: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "615: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "616: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "617: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "618: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "619: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "620: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "621: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "622: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "623: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "624: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "625: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "626: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "627: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "628: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "629: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "630: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "631: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "632: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "633: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "634: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "635: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "636: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "637: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "638: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "639: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "640: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "641: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "642: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "643: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "644: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "645: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "646: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "647: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "648: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "649: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "650: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "651: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "652: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "653: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "654: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "655: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "656: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "657: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "658: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "659: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "660: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "661: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "662: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "663: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "664: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "665: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "666: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "667: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "668: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "669: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "670: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "671: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "672: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "673: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "674: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "675: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "676: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "677: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "678: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "679: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "680: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "681: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "682: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "683: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "684: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "685: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "686: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "687: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "688: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "689: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "690: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "691: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "692: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "693: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "694: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "695: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "696: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "697: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "698: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "699: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "700: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "701: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "702: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "703: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "704: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "705: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "706: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "707: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "708: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "709: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "710: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "711: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "712: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "713: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "714: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "715: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "716: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "717: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "718: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "719: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "720: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "721: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "722: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "723: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "724: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "725: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "726: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "727: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "728: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "729: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "730: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "731: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "732: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "733: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "734: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "735: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "736: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "737: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "738: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "739: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "740: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "741: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "742: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "743: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "744: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "745: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "746: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "747: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "748: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "749: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "750: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "751: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "752: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "753: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "754: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "755: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "756: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "757: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "758: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "759: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "760: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "761: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "762: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "763: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "764: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "765: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "766: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "767: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "768: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "769: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "770: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "771: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "772: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "773: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "774: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "775: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "776: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "777: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "778: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "779: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "780: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "781: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "782: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "783: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "784: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "785: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "786: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "787: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "788: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "789: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "790: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "791: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "792: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "793: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "794: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "795: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "796: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "797: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "798: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "799: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "800: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "801: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "802: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "803: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "804: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "805: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "806: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "807: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "808: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "809: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "810: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "811: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "812: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "813: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "814: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "815: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "816: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "817: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "818: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "819: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "820: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "821: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "822: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "823: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "824: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "825: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "826: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "827: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "828: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "829: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "830: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "831: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "832: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "833: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "834: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "835: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "836: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "837: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "838: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "839: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "840: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "841: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "842: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "843: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "844: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "845: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "846: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "847: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "848: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "849: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "850: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "851: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "852: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "853: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "854: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "855: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "856: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "857: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "858: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "859: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "860: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "861: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "862: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "863: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "864: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "865: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "866: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "867: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "868: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "869: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "870: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "871: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "872: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "873: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "874: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "875: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "876: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "877: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "878: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "879: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "880: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "881: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "882: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "883: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "884: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "885: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "886: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "887: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "888: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "889: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "890: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "891: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "892: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "893: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "894: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "895: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "896: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "897: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "898: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "899: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "900: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "901: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "902: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "903: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "904: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "905: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "906: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "907: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "908: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "909: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "910: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "911: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "912: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "913: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "914: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "915: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "916: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "917: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "918: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "919: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "920: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "921: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "922: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "923: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "924: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "925: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "926: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "927: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "928: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "929: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "930: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "931: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "932: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "933: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "934: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "935: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "936: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "937: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "938: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "939: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "940: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "941: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "942: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "943: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "944: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "945: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "946: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "947: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "948: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "949: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "950: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "951: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "952: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "953: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "954: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "955: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "956: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "957: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "958: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "959: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "960: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "961: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "962: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "963: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "964: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "965: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "966: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "967: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "968: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "969: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "970: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "971: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "972: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "973: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "974: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "975: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "976: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "977: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "978: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "979: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "980: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "981: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "982: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "983: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "984: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "985: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "986: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "987: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "988: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "989: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "990: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "991: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "992: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "993: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "994: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "995: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "996: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "997: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "998: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n",
      "999: Training / validation acc/loss: 0.500/0.693 / 0.500/0.693\n"
     ]
    }
   ],
   "source": [
    "scale_and_train(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efcf949-566c-4ee8-a858-007129bc4b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:02:49.795241Z",
     "iopub.status.busy": "2023-04-19T20:02:49.794902Z",
     "iopub.status.idle": "2023-04-19T20:02:49.801499Z",
     "shell.execute_reply": "2023-04-19T20:02:49.800238Z",
     "shell.execute_reply.started": "2023-04-19T20:02:49.795216Z"
    }
   },
   "source": [
    "Using the scaling by factor of 50 the sequence diverge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d596e5-1c35-47c0-af22-809d600e809d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T18:55:50.004760Z",
     "iopub.status.busy": "2023-04-19T18:55:50.004057Z",
     "iopub.status.idle": "2023-04-19T18:55:50.008944Z",
     "shell.execute_reply": "2023-04-19T18:55:50.007973Z",
     "shell.execute_reply.started": "2023-04-19T18:55:50.004729Z"
    }
   },
   "source": [
    "# Part 2: Initialization - Deep Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b1e45-9df0-4e1d-be8a-8d3099946dc1",
   "metadata": {},
   "source": [
    "Initialize using N(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0943432f-7b16-45e4-b6e5-7b1c87c3156c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:27:48.750416Z",
     "iopub.status.busy": "2023-04-19T19:27:48.750041Z",
     "iopub.status.idle": "2023-04-19T19:27:48.803982Z",
     "shell.execute_reply": "2023-04-19T19:27:48.803032Z",
     "shell.execute_reply.started": "2023-04-19T19:27:48.750409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.02340043e+00  6.30205822e+00  5.45692291e+01  3.58305908e+02\n",
      "  2.46778149e+03  1.33914229e+04  8.39902109e+04  6.80035938e+05\n",
      "  4.39589450e+06  3.07863300e+07  2.60776800e+08  1.74525606e+09\n",
      "  1.46150021e+10  8.31007130e+10  6.35754775e+11  4.81339900e+12\n",
      "  2.73760167e+13  2.14284190e+14  1.35745797e+15 -7.93854804e+15]\n",
      "[1.93721962e+00 1.35830669e+01 1.01165390e+02 7.13236633e+02\n",
      " 4.76375732e+03 2.82326484e+04 1.87848219e+05 1.27132925e+06\n",
      " 9.01308100e+06 6.61449520e+07 4.42607488e+08 3.30139392e+09\n",
      " 2.41341256e+10 1.60421036e+11 1.18547205e+12 7.95759503e+12\n",
      " 5.48872032e+13 4.00462851e+14 2.66500788e+15 1.40564358e+16]\n"
     ]
    }
   ],
   "source": [
    "class Deep(nn.Module):\n",
    "    def __init__(self, sigma, neurons=100):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.mean = np.zeros(20)\n",
    "        self.std = np.zeros(20)\n",
    "        \n",
    "        first = nn.Sequential(\n",
    "            nn.Linear(2, neurons),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(18):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(neurons, neurons),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        last = nn.Sequential(\n",
    "            nn.Linear(neurons, 2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        self.net = nn.Sequential(*[first, *layers, last])\n",
    "        \n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight.data, 0, self.sigma)\n",
    "            nn.init.zeros_(m.bias.data)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i in range(20):\n",
    "            x = self.net[i](x)\n",
    "            a = x.detach().cpu().numpy()\n",
    "            self.mean[i] = np.average(a)\n",
    "            self.std[i] = np.std(a)\n",
    "        return x\n",
    "\n",
    "n = 1000\n",
    "new_data = cdg.generate_sample(n)\n",
    "loader = torch.utils.data.DataLoader(list(zip(new_data[0], new_data[1])), batch_size=n, shuffle=True, num_workers=0)\n",
    "net = Deep(1).to(dev)\n",
    "\n",
    "for x, t in loader:\n",
    "    x, t = x.to(dev), t.to(dev)\n",
    "    net(x)\n",
    "    \n",
    "print(net.mean)\n",
    "print(net.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d230665-3b79-4f46-aa9a-7475e510a764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:29:55.789015Z",
     "iopub.status.busy": "2023-04-19T19:29:55.788690Z",
     "iopub.status.idle": "2023-04-19T19:29:55.795403Z",
     "shell.execute_reply": "2023-04-19T19:29:55.794090Z",
     "shell.execute_reply.started": "2023-04-19T19:29:55.788990Z"
    }
   },
   "source": [
    "From the output above we can conclude that with given initialization mean activations are rapidly exploding and reaching std ~10^16 at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f44b06cb-0914-4a3a-9e35-c809dd567e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T19:38:08.607188Z",
     "iopub.status.busy": "2023-04-19T19:38:08.606760Z",
     "iopub.status.idle": "2023-04-19T19:38:08.653347Z",
     "shell.execute_reply": "2023-04-19T19:38:08.652495Z",
     "shell.execute_reply.started": "2023-04-19T19:38:08.607154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.51147604e-01  9.49673206e-02  6.57034367e-02  5.24935238e-02\n",
      "  4.24583107e-02  3.51425372e-02  2.46521384e-02  1.86332744e-02\n",
      "  1.14116305e-02  8.99655558e-03  6.45197462e-03  4.10100725e-03\n",
      "  2.64904276e-03  1.47272018e-03  1.33905397e-03  9.49021662e-04\n",
      "  8.46975308e-04  6.12025498e-04  4.78663191e-04 -6.93147242e-01]\n",
      "[2.60561556e-01 1.73813149e-01 1.22584157e-01 9.28085372e-02\n",
      " 8.06289464e-02 6.08070754e-02 4.56339195e-02 3.60786952e-02\n",
      " 2.50860974e-02 1.65917575e-02 1.15203243e-02 7.46552460e-03\n",
      " 5.10137854e-03 3.44709447e-03 2.77481577e-03 1.89852621e-03\n",
      " 1.47712731e-03 1.24885899e-03 8.91709409e-04 1.83684766e-04]\n"
     ]
    }
   ],
   "source": [
    "class DeepGlorot(nn.Module):\n",
    "    def __init__(self, neurons=100):\n",
    "        super().__init__()\n",
    "        self.mean = np.zeros(20)\n",
    "        self.std = np.zeros(20)\n",
    "        \n",
    "        first = nn.Sequential(\n",
    "            nn.Linear(2, neurons),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(18):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(neurons, neurons),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        last = nn.Sequential(\n",
    "            nn.Linear(neurons, 2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        self.net = nn.Sequential(*[first, *layers, last])\n",
    "        \n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight.data)\n",
    "            nn.init.zeros_(m.bias.data)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i in range(20):\n",
    "            x = self.net[i](x)\n",
    "            a = x.detach().cpu().numpy()\n",
    "            self.mean[i] = np.average(a)\n",
    "            self.std[i] = np.std(a)\n",
    "        return x\n",
    "\n",
    "deep_glorot = DeepGlorot().to(dev)\n",
    "\n",
    "for x, t in loader:\n",
    "    x, t = x.to(dev), t.to(dev)\n",
    "    deep_glorot(x)\n",
    "    \n",
    "print(deep_glorot.mean)\n",
    "print(deep_glorot.std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4484d404-24cd-431c-a420-eb83de8e8038",
   "metadata": {},
   "source": [
    "As we can see the Glorot initialization successfully solves this problem. The mean is normal. The std is still a bit big, but I can't call this \"explosion\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e34c43-cd90-4423-a71b-0e93fce8a17f",
   "metadata": {},
   "source": [
    "# Part 3: Regularization - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c934ea99-d676-4aee-bc57-29816741c701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:10:36.438091Z",
     "iopub.status.busy": "2023-04-19T20:10:36.437123Z",
     "iopub.status.idle": "2023-04-19T20:10:42.601230Z",
     "shell.execute_reply": "2023-04-19T20:10:42.600070Z",
     "shell.execute_reply.started": "2023-04-19T20:10:36.438061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce335b1af66c44c2bf6d37e5351734a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e57584089e44aa29f63c4a4a159d3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0e13ab5c7a410296181566324e19ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156d1f9c1d11472591584fe370441353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "mnist = MNISTData(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b4a85a99-aa17-4113-9672-d6939f48bf15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:22:50.013391Z",
     "iopub.status.busy": "2023-04-19T20:22:50.012243Z",
     "iopub.status.idle": "2023-04-19T20:22:50.019323Z",
     "shell.execute_reply": "2023-04-19T20:22:50.018701Z",
     "shell.execute_reply.started": "2023-04-19T20:22:50.013353Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_with_adam(net, train_loader, val_loader, lr=3e-4, epochs=1, verbose=True):\n",
    "    loss_fun = nn.NLLLoss()\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        for x, target in train_loader:\n",
    "            x = x.to(dev)\n",
    "            target = target.to(dev)\n",
    "            y = net.forward(x)\n",
    "            l = loss_fun(y, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.mean().backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_loss += l.mean().item()\n",
    "                train_acc += accuracy(y, target)\n",
    "\n",
    "        if verbose:\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                train_loss /= len(train_loader)\n",
    "                train_acc /= len(train_loader)\n",
    "            \n",
    "            val_loss, val_acc = evaluate(net, loss_fun, val_loader)\n",
    "            print(f\"{epoch}: Training / validation acc/loss: {train_acc:.3f}/{train_loss:.3f} / {val_acc:.3f}/{val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "80045ec5-6301-4c07-b8e8-72469547ef51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:23:14.896260Z",
     "iopub.status.busy": "2023-04-19T20:23:14.895466Z",
     "iopub.status.idle": "2023-04-19T20:23:14.901673Z",
     "shell.execute_reply": "2023-04-19T20:23:14.901109Z",
     "shell.execute_reply.started": "2023-04-19T20:23:14.896260Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self, sigma, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(784, 800),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(800, 800),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(800, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight.data, 0, self.sigma)\n",
    "            nn.init.zeros_(m.bias.data)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "22f26bd5-5cfc-480e-89d1-4e9a54579369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:24:31.964010Z",
     "iopub.status.busy": "2023-04-19T20:24:31.963328Z",
     "iopub.status.idle": "2023-04-19T20:24:48.529078Z",
     "shell.execute_reply": "2023-04-19T20:24:48.528500Z",
     "shell.execute_reply.started": "2023-04-19T20:24:31.963980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.812/0.691 / 0.894/0.369\n",
      "1: Training / validation acc/loss: 0.945/0.179 / 0.910/0.318\n",
      "2: Training / validation acc/loss: 0.982/0.065 / 0.913/0.301\n",
      "3: Training / validation acc/loss: 0.995/0.030 / 0.922/0.275\n",
      "4: Training / validation acc/loss: 0.999/0.014 / 0.920/0.298\n",
      "5: Training / validation acc/loss: 1.000/0.009 / 0.926/0.270\n",
      "6: Training / validation acc/loss: 1.000/0.005 / 0.928/0.272\n",
      "7: Training / validation acc/loss: 1.000/0.004 / 0.929/0.271\n",
      "8: Training / validation acc/loss: 1.000/0.003 / 0.929/0.276\n",
      "9: Training / validation acc/loss: 1.000/0.003 / 0.931/0.273\n"
     ]
    }
   ],
   "source": [
    "net1 = MNISTNet(0.1, dropout=0.0).to(dev)\n",
    "train_with_adam(net1, mnist.train_loader, mnist.val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1d7b7b3d-a4c4-4f78-80e8-267d1db339bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-19T20:26:40.704819Z",
     "iopub.status.busy": "2023-04-19T20:26:40.704050Z",
     "iopub.status.idle": "2023-04-19T20:28:06.177568Z",
     "shell.execute_reply": "2023-04-19T20:28:06.175631Z",
     "shell.execute_reply.started": "2023-04-19T20:26:40.704789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Training / validation acc/loss: 0.261/8.312 / 0.761/0.773\n",
      "1: Training / validation acc/loss: 0.439/3.938 / 0.806/0.608\n",
      "2: Training / validation acc/loss: 0.530/2.771 / 0.832/0.513\n",
      "3: Training / validation acc/loss: 0.588/2.175 / 0.848/0.472\n",
      "4: Training / validation acc/loss: 0.623/1.831 / 0.852/0.456\n",
      "5: Training / validation acc/loss: 0.639/1.583 / 0.863/0.438\n",
      "6: Training / validation acc/loss: 0.649/1.447 / 0.873/0.422\n",
      "7: Training / validation acc/loss: 0.676/1.273 / 0.881/0.405\n",
      "8: Training / validation acc/loss: 0.694/1.197 / 0.882/0.404\n",
      "9: Training / validation acc/loss: 0.702/1.123 / 0.883/0.405\n",
      "10: Training / validation acc/loss: 0.715/1.057 / 0.893/0.391\n",
      "11: Training / validation acc/loss: 0.711/1.017 / 0.895/0.393\n",
      "12: Training / validation acc/loss: 0.732/0.912 / 0.895/0.393\n",
      "13: Training / validation acc/loss: 0.749/0.846 / 0.894/0.384\n",
      "14: Training / validation acc/loss: 0.755/0.829 / 0.899/0.383\n",
      "15: Training / validation acc/loss: 0.762/0.801 / 0.901/0.376\n",
      "16: Training / validation acc/loss: 0.772/0.749 / 0.906/0.362\n",
      "17: Training / validation acc/loss: 0.783/0.724 / 0.906/0.358\n",
      "18: Training / validation acc/loss: 0.791/0.682 / 0.909/0.356\n",
      "19: Training / validation acc/loss: 0.795/0.672 / 0.913/0.341\n",
      "20: Training / validation acc/loss: 0.798/0.637 / 0.913/0.337\n",
      "21: Training / validation acc/loss: 0.808/0.629 / 0.916/0.332\n",
      "22: Training / validation acc/loss: 0.811/0.593 / 0.918/0.324\n",
      "23: Training / validation acc/loss: 0.813/0.593 / 0.919/0.323\n",
      "24: Training / validation acc/loss: 0.828/0.548 / 0.920/0.310\n",
      "25: Training / validation acc/loss: 0.825/0.558 / 0.922/0.307\n",
      "26: Training / validation acc/loss: 0.832/0.526 / 0.923/0.299\n",
      "27: Training / validation acc/loss: 0.831/0.531 / 0.922/0.300\n",
      "28: Training / validation acc/loss: 0.842/0.507 / 0.923/0.296\n",
      "29: Training / validation acc/loss: 0.844/0.486 / 0.927/0.286\n",
      "30: Training / validation acc/loss: 0.851/0.473 / 0.923/0.286\n",
      "31: Training / validation acc/loss: 0.850/0.467 / 0.928/0.276\n",
      "32: Training / validation acc/loss: 0.853/0.467 / 0.929/0.270\n",
      "33: Training / validation acc/loss: 0.854/0.451 / 0.927/0.267\n",
      "34: Training / validation acc/loss: 0.865/0.446 / 0.931/0.263\n",
      "35: Training / validation acc/loss: 0.859/0.456 / 0.932/0.258\n",
      "36: Training / validation acc/loss: 0.862/0.431 / 0.931/0.258\n",
      "37: Training / validation acc/loss: 0.866/0.413 / 0.930/0.258\n",
      "38: Training / validation acc/loss: 0.867/0.409 / 0.931/0.252\n",
      "39: Training / validation acc/loss: 0.871/0.409 / 0.931/0.249\n",
      "40: Training / validation acc/loss: 0.882/0.384 / 0.934/0.240\n",
      "41: Training / validation acc/loss: 0.874/0.400 / 0.933/0.242\n",
      "42: Training / validation acc/loss: 0.887/0.367 / 0.933/0.242\n",
      "43: Training / validation acc/loss: 0.886/0.357 / 0.932/0.239\n",
      "44: Training / validation acc/loss: 0.889/0.339 / 0.932/0.232\n",
      "45: Training / validation acc/loss: 0.899/0.335 / 0.934/0.226\n",
      "46: Training / validation acc/loss: 0.887/0.339 / 0.937/0.224\n",
      "47: Training / validation acc/loss: 0.888/0.336 / 0.937/0.226\n",
      "48: Training / validation acc/loss: 0.886/0.348 / 0.940/0.224\n",
      "49: Training / validation acc/loss: 0.897/0.324 / 0.939/0.221\n"
     ]
    }
   ],
   "source": [
    "net2 = MNISTNet(0.1, dropout=0.5).to(dev)\n",
    "train_with_adam(net2, mnist.train_loader, mnist.val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802cdc8-80ed-430d-bb02-2fe92cd285ce",
   "metadata": {},
   "source": [
    "So yep dropout had strong regularization effect. We had to train the network 5 times longer, but this is good prevention from overfitting as we can see on the training accuracy/loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
